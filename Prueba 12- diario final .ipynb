{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataProcessing(data, prev_per, forw_per,jump=1):\n",
    "    X,Y = [],[]\n",
    "    data_X=data[:,:-1]\n",
    "    data_Y=data[:,-1]\n",
    "    for i in range(0,len(data) -prev_per -forw_per +1, jump):\n",
    "        X.append(data_X[i:(i+prev_per)])\n",
    "        Y.append(data_Y[(i+prev_per):(i+prev_per+forw_per)])\n",
    "    return np.array(X),np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Guillermo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Guillermo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 2s 2ms/step - loss: 4.0392e-04 - val_loss: 7.6203e-05\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 48us/step - loss: 1.7439e-04 - val_loss: 1.0734e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.7162e-04 - val_loss: 8.0133e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6727e-04 - val_loss: 7.6861e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6646e-04 - val_loss: 8.0830e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6655e-04 - val_loss: 7.8784e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6635e-04 - val_loss: 7.9968e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6623e-04 - val_loss: 7.8720e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6595e-04 - val_loss: 7.8520e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 45us/step - loss: 1.6568e-04 - val_loss: 7.8813e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 45us/step - loss: 1.6541e-04 - val_loss: 7.8788e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 46us/step - loss: 1.6529e-04 - val_loss: 7.6727e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6493e-04 - val_loss: 7.8781e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6478e-04 - val_loss: 7.7992e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6440e-04 - val_loss: 7.6686e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6410e-04 - val_loss: 7.9348e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6364e-04 - val_loss: 7.7404e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6333e-04 - val_loss: 7.7915e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 45us/step - loss: 1.6286e-04 - val_loss: 7.7264e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6244e-04 - val_loss: 7.7739e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6219e-04 - val_loss: 8.0309e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6183e-04 - val_loss: 7.6315e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 43us/step - loss: 1.6078e-04 - val_loss: 7.6511e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.6042e-04 - val_loss: 7.9588e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 44us/step - loss: 1.5982e-04 - val_loss: 7.4752e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 3s 2ms/step - loss: 3.3037e-04 - val_loss: 9.1429e-05\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.8214e-04 - val_loss: 9.2014e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 69us/step - loss: 1.6766e-04 - val_loss: 7.3290e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.6507e-04 - val_loss: 8.1581e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.6432e-04 - val_loss: 7.5962e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6386e-04 - val_loss: 7.9469e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.6339e-04 - val_loss: 7.7946e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.6277e-04 - val_loss: 7.6762e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6236e-04 - val_loss: 7.6044e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.6138e-04 - val_loss: 7.8399e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6137e-04 - val_loss: 7.5417e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 51us/step - loss: 1.6052e-04 - val_loss: 7.7445e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.5921e-04 - val_loss: 7.2985e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - ETA: 0s - loss: 1.6186e-0 - 0s 50us/step - loss: 1.5890e-04 - val_loss: 7.4117e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5717e-04 - val_loss: 7.5875e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5598e-04 - val_loss: 7.4678e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5457e-04 - val_loss: 7.4442e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.5381e-04 - val_loss: 7.7455e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 82us/step - loss: 1.5187e-04 - val_loss: 7.3917e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.5006e-04 - val_loss: 7.1963e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 65us/step - loss: 1.4812e-04 - val_loss: 7.1493e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.4578e-04 - val_loss: 7.0487e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4403e-04 - val_loss: 6.7432e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.4134e-04 - val_loss: 6.7197e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.3899e-04 - val_loss: 7.0189e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 3s 2ms/step - loss: 2.9643e-04 - val_loss: 1.4433e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.8535e-04 - val_loss: 7.3201e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.6624e-04 - val_loss: 8.0668e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.6465e-04 - val_loss: 7.7091e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.6428e-04 - val_loss: 7.9900e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6315e-04 - val_loss: 7.8006e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.6256e-04 - val_loss: 7.5741e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.6112e-04 - val_loss: 7.8379e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.6041e-04 - val_loss: 7.3676e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.5957e-04 - val_loss: 7.5769e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.5752e-04 - val_loss: 7.5166e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.5590e-04 - val_loss: 7.3252e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.5407e-04 - val_loss: 7.7735e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.5223e-04 - val_loss: 7.3538e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.4934e-04 - val_loss: 6.9490e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 48us/step - loss: 1.4662e-04 - val_loss: 6.8280e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 48us/step - loss: 1.4492e-04 - val_loss: 6.4937e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.4084e-04 - val_loss: 6.6187e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.3806e-04 - val_loss: 6.5323e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 48us/step - loss: 1.3444e-04 - val_loss: 6.5520e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.3155e-04 - val_loss: 6.5193e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.2871e-04 - val_loss: 6.2779e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 47us/step - loss: 1.2629e-04 - val_loss: 6.1874e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.2416e-04 - val_loss: 6.0924e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.2286e-04 - val_loss: 5.9115e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 3s 2ms/step - loss: 2.9775e-04 - val_loss: 1.4536e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.7935e-04 - val_loss: 7.2596e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.6693e-04 - val_loss: 8.2381e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 67us/step - loss: 1.6510e-04 - val_loss: 7.5666e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 68us/step - loss: 1.6327e-04 - val_loss: 7.8089e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 67us/step - loss: 1.6269e-04 - val_loss: 7.9478e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6202e-04 - val_loss: 7.7619e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 84us/step - loss: 1.6079e-04 - val_loss: 7.7097e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 132us/step - loss: 1.5964e-04 - val_loss: 7.2366e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 90us/step - loss: 1.5917e-04 - val_loss: 7.9909e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 146us/step - loss: 1.5723e-04 - val_loss: 7.7642e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 80us/step - loss: 1.5507e-04 - val_loss: 7.3785e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 78us/step - loss: 1.5279e-04 - val_loss: 6.9585e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 113us/step - loss: 1.4997e-04 - val_loss: 7.7881e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 82us/step - loss: 1.4822e-04 - val_loss: 6.9131e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 81us/step - loss: 1.4404e-04 - val_loss: 6.8246e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 72us/step - loss: 1.4084e-04 - val_loss: 7.1086e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 110us/step - loss: 1.3849e-04 - val_loss: 6.6160e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 66us/step - loss: 1.3355e-04 - val_loss: 6.7757e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 75us/step - loss: 1.3050e-04 - val_loss: 6.2129e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 68us/step - loss: 1.2706e-04 - val_loss: 6.8130e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 97us/step - loss: 1.2557e-04 - val_loss: 6.4891e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 66us/step - loss: 1.2433e-04 - val_loss: 5.9662e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 68us/step - loss: 1.2552e-04 - val_loss: 6.2242e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 106us/step - loss: 1.2576e-04 - val_loss: 6.1963e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 4s 2ms/step - loss: 3.2880e-04 - val_loss: 9.3027e-05\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.8138e-04 - val_loss: 9.1393e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.6670e-04 - val_loss: 7.3488e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 72us/step - loss: 1.6457e-04 - val_loss: 8.0727e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 91us/step - loss: 1.6200e-04 - val_loss: 7.5019e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 64us/step - loss: 1.6148e-04 - val_loss: 7.7030e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6046e-04 - val_loss: 7.5874e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5929e-04 - val_loss: 7.5900e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5829e-04 - val_loss: 7.4383e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5761e-04 - val_loss: 7.2425e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5563e-04 - val_loss: 7.7610e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5486e-04 - val_loss: 7.3365e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5423e-04 - val_loss: 7.0738e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.5213e-04 - val_loss: 7.1922e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5066e-04 - val_loss: 7.1358e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.4892e-04 - val_loss: 7.3983e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.4703e-04 - val_loss: 6.8094e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 51us/step - loss: 1.4516e-04 - val_loss: 7.7853e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.4414e-04 - val_loss: 6.5505e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.4254e-04 - val_loss: 6.6269e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.4016e-04 - val_loss: 6.7461e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3767e-04 - val_loss: 6.5184e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.3572e-04 - val_loss: 7.1085e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.3443e-04 - val_loss: 6.4485e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.3224e-04 - val_loss: 6.3631e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 4s 2ms/step - loss: 3.3647e-04 - val_loss: 8.4605e-05\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.8003e-04 - val_loss: 9.7410e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 49us/step - loss: 1.6723e-04 - val_loss: 7.3444e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6442e-04 - val_loss: 8.1450e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6384e-04 - val_loss: 7.6963e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.6295e-04 - val_loss: 7.8329e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6239e-04 - val_loss: 7.7810e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6178e-04 - val_loss: 7.7229e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.6117e-04 - val_loss: 7.5433e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 51us/step - loss: 1.6027e-04 - val_loss: 7.6612e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5899e-04 - val_loss: 7.6908e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5782e-04 - val_loss: 7.5751e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.5661e-04 - val_loss: 7.2046e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.5527e-04 - val_loss: 7.4287e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5330e-04 - val_loss: 7.3948e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5133e-04 - val_loss: 7.0431e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4941e-04 - val_loss: 7.3678e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.4686e-04 - val_loss: 7.3565e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.4439e-04 - val_loss: 6.9689e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4126e-04 - val_loss: 6.8854e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.3826e-04 - val_loss: 6.3359e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3550e-04 - val_loss: 6.3266e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.3202e-04 - val_loss: 6.3830e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.2907e-04 - val_loss: 6.5817e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2674e-04 - val_loss: 7.1930e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 4s 3ms/step - loss: 2.9555e-04 - val_loss: 1.6016e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.8540e-04 - val_loss: 7.2990e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.6986e-04 - val_loss: 8.5403e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.6493e-04 - val_loss: 7.5484e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6357e-04 - val_loss: 7.8310e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.6195e-04 - val_loss: 7.8236e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6073e-04 - val_loss: 8.1074e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 51us/step - loss: 1.5922e-04 - val_loss: 7.5262e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5641e-04 - val_loss: 7.1686e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5479e-04 - val_loss: 7.0465e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 50us/step - loss: 1.5161e-04 - val_loss: 7.2260e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4892e-04 - val_loss: 7.4133e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.4497e-04 - val_loss: 6.9863e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.4146e-04 - val_loss: 6.8586e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3789e-04 - val_loss: 6.6688e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3403e-04 - val_loss: 6.9898e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.3088e-04 - val_loss: 6.1499e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2763e-04 - val_loss: 6.2861e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2543e-04 - val_loss: 6.1291e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2431e-04 - val_loss: 6.0718e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2302e-04 - val_loss: 5.9620e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.2469e-04 - val_loss: 6.0061e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2262e-04 - val_loss: 5.9460e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2229e-04 - val_loss: 6.2760e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.2195e-04 - val_loss: 5.9521e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 5s 3ms/step - loss: 2.8383e-04 - val_loss: 1.5926e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.7968e-04 - val_loss: 7.2997e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.6941e-04 - val_loss: 8.3392e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6377e-04 - val_loss: 7.8525e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6224e-04 - val_loss: 7.8009e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.6033e-04 - val_loss: 7.3621e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5869e-04 - val_loss: 8.0695e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.5680e-04 - val_loss: 7.9271e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5416e-04 - val_loss: 7.4355e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.5026e-04 - val_loss: 6.7722e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.4863e-04 - val_loss: 6.6558e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.4508e-04 - val_loss: 6.8793e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3900e-04 - val_loss: 6.4569e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3753e-04 - val_loss: 6.2399e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.3355e-04 - val_loss: 6.3097e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.2800e-04 - val_loss: 6.2194e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2691e-04 - val_loss: 6.1437e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.2609e-04 - val_loss: 6.1278e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2279e-04 - val_loss: 5.9682e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.2218e-04 - val_loss: 5.9664e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2158e-04 - val_loss: 5.9526e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2116e-04 - val_loss: 5.9745e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2159e-04 - val_loss: 5.9583e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2153e-04 - val_loss: 6.4149e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2138e-04 - val_loss: 6.0640e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 5s 3ms/step - loss: 3.6279e-04 - val_loss: 9.4708e-05\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.8656e-04 - val_loss: 9.3302e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6946e-04 - val_loss: 7.5892e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6818e-04 - val_loss: 8.1441e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6717e-04 - val_loss: 8.0084e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6600e-04 - val_loss: 7.7809e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.6547e-04 - val_loss: 8.0446e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6405e-04 - val_loss: 7.8922e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.6273e-04 - val_loss: 7.5368e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.6150e-04 - val_loss: 7.5105e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5973e-04 - val_loss: 7.8379e-05\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5888e-04 - val_loss: 7.4486e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5766e-04 - val_loss: 7.2935e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5521e-04 - val_loss: 7.4542e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5357e-04 - val_loss: 7.4173e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5241e-04 - val_loss: 7.2396e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5026e-04 - val_loss: 6.9774e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4855e-04 - val_loss: 7.1391e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.4643e-04 - val_loss: 7.6711e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4499e-04 - val_loss: 6.7977e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.4262e-04 - val_loss: 6.6244e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.4005e-04 - val_loss: 7.0278e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3793e-04 - val_loss: 6.4767e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3589e-04 - val_loss: 6.7163e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3446e-04 - val_loss: 7.0237e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 5s 3ms/step - loss: 3.1002e-04 - val_loss: 1.1447e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.8289e-04 - val_loss: 7.9334e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.6453e-04 - val_loss: 7.4625e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6264e-04 - val_loss: 7.9617e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 71us/step - loss: 1.6176e-04 - val_loss: 7.6080e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.6083e-04 - val_loss: 7.7527e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5973e-04 - val_loss: 7.6670e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5883e-04 - val_loss: 7.8217e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5740e-04 - val_loss: 7.5322e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.5565e-04 - val_loss: 7.4119e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5404e-04 - val_loss: 7.2847e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5223e-04 - val_loss: 7.1049e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.5056e-04 - val_loss: 6.9379e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.4876e-04 - val_loss: 7.7031e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.4603e-04 - val_loss: 6.9528e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.4370e-04 - val_loss: 6.5423e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.4100e-04 - val_loss: 6.6889e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3800e-04 - val_loss: 6.6123e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3493e-04 - val_loss: 6.5276e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3226e-04 - val_loss: 6.1378e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2978e-04 - val_loss: 6.6758e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - ETA: 0s - loss: 9.7864e-0 - 0s 56us/step - loss: 1.2761e-04 - val_loss: 6.5021e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.2709e-04 - val_loss: 6.1539e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2409e-04 - val_loss: 6.0196e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.2273e-04 - val_loss: 6.7179e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 5s 3ms/step - loss: 2.7244e-04 - val_loss: 1.5646e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.8088e-04 - val_loss: 7.1343e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.6329e-04 - val_loss: 8.2535e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.5986e-04 - val_loss: 7.4378e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - ETA: 0s - loss: 1.6464e-0 - 0s 57us/step - loss: 1.5866e-04 - val_loss: 7.4692e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.5735e-04 - val_loss: 7.6418e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.5549e-04 - val_loss: 7.5370e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.5319e-04 - val_loss: 7.3150e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.5075e-04 - val_loss: 7.3427e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 67us/step - loss: 1.4884e-04 - val_loss: 7.2660e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.4559e-04 - val_loss: 6.6703e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.4134e-04 - val_loss: 7.1302e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.3765e-04 - val_loss: 6.9577e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.3416e-04 - val_loss: 6.4200e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.3045e-04 - val_loss: 6.4305e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.2719e-04 - val_loss: 6.0384e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.2501e-04 - val_loss: 6.0173e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2349e-04 - val_loss: 6.6361e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.2373e-04 - val_loss: 6.4646e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2159e-04 - val_loss: 6.8733e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2263e-04 - val_loss: 6.0070e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.2183e-04 - val_loss: 6.2311e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2166e-04 - val_loss: 6.2463e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2191e-04 - val_loss: 6.2070e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - ETA: 0s - loss: 1.0582e-0 - 0s 56us/step - loss: 1.2144e-04 - val_loss: 6.1197e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 6s 3ms/step - loss: 2.7920e-04 - val_loss: 1.6362e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.7762e-04 - val_loss: 7.2541e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.6461e-04 - val_loss: 8.4031e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6177e-04 - val_loss: 7.4469e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5930e-04 - val_loss: 7.6846e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5742e-04 - val_loss: 7.8702e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.5612e-04 - val_loss: 7.5383e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5280e-04 - val_loss: 6.8753e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.4955e-04 - val_loss: 6.6816e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.4572e-04 - val_loss: 6.9816e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.4196e-04 - val_loss: 6.7353e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.3743e-04 - val_loss: 7.0123e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.3416e-04 - val_loss: 6.4132e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2932e-04 - val_loss: 6.2791e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2795e-04 - val_loss: 6.0506e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.2483e-04 - val_loss: 6.4649e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2457e-04 - val_loss: 6.9487e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2345e-04 - val_loss: 6.3033e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2255e-04 - val_loss: 6.1779e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2247e-04 - val_loss: 6.0558e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2325e-04 - val_loss: 6.0672e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.2190e-04 - val_loss: 6.0176e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.2278e-04 - val_loss: 6.0553e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.2309e-04 - val_loss: 6.4585e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2288e-04 - val_loss: 6.0114e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 6s 4ms/step - loss: 3.2107e-04 - val_loss: 1.1328e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.8372e-04 - val_loss: 8.0709e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.6550e-04 - val_loss: 7.3508e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.6319e-04 - val_loss: 7.9553e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.6097e-04 - val_loss: 7.5524e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.6059e-04 - val_loss: 7.8223e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.5888e-04 - val_loss: 7.6930e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.5703e-04 - val_loss: 7.5040e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.5490e-04 - val_loss: 7.3261e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 57us/step - loss: 1.5330e-04 - val_loss: 7.4092e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.5119e-04 - val_loss: 7.1914e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.4955e-04 - val_loss: 7.7538e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 56us/step - loss: 1.4809e-04 - val_loss: 6.6617e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.4643e-04 - val_loss: 6.9859e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.4349e-04 - val_loss: 7.7782e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 55us/step - loss: 1.4231e-04 - val_loss: 6.9748e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3867e-04 - val_loss: 6.5541e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.3671e-04 - val_loss: 6.3732e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3351e-04 - val_loss: 6.5508e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3242e-04 - val_loss: 7.1286e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.3135e-04 - val_loss: 6.5500e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 54us/step - loss: 1.2823e-04 - val_loss: 6.1031e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2682e-04 - val_loss: 6.0881e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 53us/step - loss: 1.2644e-04 - val_loss: 6.0112e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 52us/step - loss: 1.2458e-04 - val_loss: 6.2937e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 6s 4ms/step - loss: 2.8931e-04 - val_loss: 1.4584e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.7883e-04 - val_loss: 7.1471e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6484e-04 - val_loss: 8.0387e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.6092e-04 - val_loss: 7.3965e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.5837e-04 - val_loss: 7.8373e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.5654e-04 - val_loss: 7.3575e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5462e-04 - val_loss: 7.5324e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 66us/step - loss: 1.5274e-04 - val_loss: 7.3578e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5043e-04 - val_loss: 6.9354e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.4891e-04 - val_loss: 6.7581e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.4565e-04 - val_loss: 7.3142e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.4247e-04 - val_loss: 7.0077e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.3957e-04 - val_loss: 6.3802e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.3674e-04 - val_loss: 6.4408e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.3342e-04 - val_loss: 7.1116e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 58us/step - loss: 1.3035e-04 - val_loss: 6.4540e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2851e-04 - val_loss: 6.1217e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2577e-04 - val_loss: 6.0329e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 64us/step - loss: 1.2444e-04 - val_loss: 6.1049e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 64us/step - loss: 1.2587e-04 - val_loss: 6.3373e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2346e-04 - val_loss: 6.1935e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2177e-04 - val_loss: 6.4653e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2230e-04 - val_loss: 6.3879e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2503e-04 - val_loss: 5.9936e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2264e-04 - val_loss: 6.0985e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 6s 4ms/step - loss: 2.9669e-04 - val_loss: 1.5839e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.7622e-04 - val_loss: 7.2352e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6491e-04 - val_loss: 8.6869e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 64us/step - loss: 1.6199e-04 - val_loss: 7.3453e-05\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5998e-04 - val_loss: 7.6237e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.5761e-04 - val_loss: 7.5536e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.5489e-04 - val_loss: 7.6802e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5178e-04 - val_loss: 7.0688e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.4766e-04 - val_loss: 7.3206e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.4341e-04 - val_loss: 7.4330e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.3942e-04 - val_loss: 6.9095e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.3440e-04 - val_loss: 6.4007e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.3003e-04 - val_loss: 6.9301e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2815e-04 - val_loss: 6.9515e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2501e-04 - val_loss: 6.1014e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2319e-04 - val_loss: 6.0212e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 59us/step - loss: 1.2345e-04 - val_loss: 7.0131e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2145e-04 - val_loss: 5.9850e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2400e-04 - val_loss: 6.0017e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2194e-04 - val_loss: 6.1570e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2244e-04 - val_loss: 5.9774e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2347e-04 - val_loss: 7.2209e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2481e-04 - val_loss: 5.9719e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2183e-04 - val_loss: 6.0478e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 74us/step - loss: 1.2064e-04 - val_loss: 6.0207e-05\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 7s 4ms/step - loss: 2.7880e-04 - val_loss: 1.5568e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.7038e-04 - val_loss: 7.2039e-05\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.6365e-04 - val_loss: 8.8028e-05\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.6153e-04 - val_loss: 7.5884e-05\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.5833e-04 - val_loss: 7.2726e-05\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.5605e-04 - val_loss: 7.6575e-05\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.5283e-04 - val_loss: 7.1299e-05\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.4940e-04 - val_loss: 7.2406e-05\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 73us/step - loss: 1.4546e-04 - val_loss: 6.9037e-05\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.4105e-04 - val_loss: 6.7338e-05\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.3677e-04 - val_loss: 6.2704e-05\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.3219e-04 - val_loss: 6.1711e-05\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2894e-04 - val_loss: 6.3555e-05\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 62us/step - loss: 1.2573e-04 - val_loss: 6.0459e-05\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2462e-04 - val_loss: 6.1624e-05\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2339e-04 - val_loss: 6.0102e-05\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2260e-04 - val_loss: 6.0495e-05\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 60us/step - loss: 1.2227e-04 - val_loss: 5.9811e-05\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 65us/step - loss: 1.2177e-04 - val_loss: 6.1480e-05\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 74us/step - loss: 1.2360e-04 - val_loss: 6.1907e-05\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2185e-04 - val_loss: 5.9789e-05\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2172e-04 - val_loss: 6.4712e-05\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 63us/step - loss: 1.2276e-04 - val_loss: 5.9669e-05\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 65us/step - loss: 1.2218e-04 - val_loss: 6.1555e-05\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 61us/step - loss: 1.2082e-04 - val_loss: 6.4273e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 7s 5ms/step - loss: 3.3907e-04 - val_loss: 9.3495e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 79us/step - loss: 1.8368e-04 - val_loss: 9.2961e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6896e-04 - val_loss: 7.4259e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 75us/step - loss: 1.6638e-04 - val_loss: 8.1286e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 74us/step - loss: 1.6530e-04 - val_loss: 7.7400e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 78us/step - loss: 1.6462e-04 - val_loss: 8.0316e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6445e-04 - val_loss: 7.8780e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 77us/step - loss: 1.6244e-04 - val_loss: 7.8762e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6144e-04 - val_loss: 7.6708e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 77us/step - loss: 1.6069e-04 - val_loss: 7.4278e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 74us/step - loss: 1.5931e-04 - val_loss: 7.5710e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.5764e-04 - val_loss: 7.4195e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 77us/step - loss: 1.5693e-04 - val_loss: 7.8940e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 77us/step - loss: 1.5496e-04 - val_loss: 7.1343e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 78us/step - loss: 1.5366e-04 - val_loss: 7.4787e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.5245e-04 - val_loss: 7.5017e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.4994e-04 - val_loss: 6.9301e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.4911e-04 - val_loss: 7.4986e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 75us/step - loss: 1.4656e-04 - val_loss: 6.9867e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 78us/step - loss: 1.4449e-04 - val_loss: 6.7307e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 76us/step - loss: 1.4227e-04 - val_loss: 6.6967e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 76us/step - loss: 1.4038e-04 - val_loss: 6.5792e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 77us/step - loss: 1.3844e-04 - val_loss: 6.3533e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 76us/step - loss: 1.3553e-04 - val_loss: 6.7010e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 75us/step - loss: 1.3350e-04 - val_loss: 6.2923e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 8s 5ms/step - loss: 2.9273e-04 - val_loss: 1.4033e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 1.8344e-04 - val_loss: 7.3106e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 1.6719e-04 - val_loss: 8.0218e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 1.6298e-04 - val_loss: 7.4693e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 87us/step - loss: 1.6115e-04 - val_loss: 7.6898e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.5957e-04 - val_loss: 7.6681e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.5889e-04 - val_loss: 7.1767e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5670e-04 - val_loss: 7.9113e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5456e-04 - val_loss: 7.1473e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5256e-04 - val_loss: 7.3232e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5068e-04 - val_loss: 7.4798e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5037e-04 - val_loss: 6.7277e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.4725e-04 - val_loss: 6.8702e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.4549e-04 - val_loss: 7.5345e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 126us/step - loss: 1.4216e-04 - val_loss: 6.7104e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 121us/step - loss: 1.3951e-04 - val_loss: 6.9663e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.3752e-04 - val_loss: 7.0066e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3533e-04 - val_loss: 6.5280e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.3265e-04 - val_loss: 6.2579e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3057e-04 - val_loss: 6.1112e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.3038e-04 - val_loss: 6.2175e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2849e-04 - val_loss: 6.8854e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2673e-04 - val_loss: 6.6307e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2461e-04 - val_loss: 6.0989e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 106us/step - loss: 1.2403e-04 - val_loss: 6.2964e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 8s 5ms/step - loss: 2.5955e-04 - val_loss: 1.5009e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6705e-04 - val_loss: 7.0113e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 1.5725e-04 - val_loss: 8.1254e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5426e-04 - val_loss: 7.0703e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.5277e-04 - val_loss: 8.2054e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.5386e-04 - val_loss: 6.9048e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.5014e-04 - val_loss: 6.9683e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.4753e-04 - val_loss: 7.3433e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.4522e-04 - val_loss: 6.8709e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.4340e-04 - val_loss: 7.8245e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.4060e-04 - val_loss: 6.5820e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 78us/step - loss: 1.3757e-04 - val_loss: 6.4082e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.3490e-04 - val_loss: 6.8073e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 111us/step - loss: 1.3234e-04 - val_loss: 6.4155e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.3209e-04 - val_loss: 6.1423e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.3153e-04 - val_loss: 6.0972e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.2824e-04 - val_loss: 6.0984e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2685e-04 - val_loss: 6.0440e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2734e-04 - val_loss: 6.0226e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 123us/step - loss: 1.2512e-04 - val_loss: 6.0480e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 1.2380e-04 - val_loss: 7.0115e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 113us/step - loss: 1.2597e-04 - val_loss: 6.0923e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 115us/step - loss: 1.2539e-04 - val_loss: 6.2849e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2555e-04 - val_loss: 6.0024e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2314e-04 - val_loss: 6.0296e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 8s 5ms/step - loss: 2.7103e-04 - val_loss: 9.4479e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.6714e-04 - val_loss: 7.9589e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 78us/step - loss: 1.6373e-04 - val_loss: 7.0494e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5941e-04 - val_loss: 7.5451e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5647e-04 - val_loss: 7.5082e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.5402e-04 - val_loss: 7.5067e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.5105e-04 - val_loss: 7.7897e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.4911e-04 - val_loss: 8.0262e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.4604e-04 - val_loss: 7.4072e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.4222e-04 - val_loss: 6.8543e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.3871e-04 - val_loss: 6.5776e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.3387e-04 - val_loss: 6.1935e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.3096e-04 - val_loss: 6.6471e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.2846e-04 - val_loss: 6.2862e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.2552e-04 - val_loss: 6.1005e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.2442e-04 - val_loss: 6.4942e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2613e-04 - val_loss: 5.9846e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2429e-04 - val_loss: 6.7108e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2372e-04 - val_loss: 5.9777e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2248e-04 - val_loss: 6.2218e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.2284e-04 - val_loss: 6.0419e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2427e-04 - val_loss: 6.5468e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2245e-04 - val_loss: 6.1164e-05\n",
      "Epoch 24/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.2284e-04 - val_loss: 5.9786e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2285e-04 - val_loss: 6.0501e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 9s 5ms/step - loss: 4.0050e-04 - val_loss: 7.8688e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.7193e-04 - val_loss: 1.0552e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 1.7156e-04 - val_loss: 8.0644e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.6600e-04 - val_loss: 7.5914e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.6586e-04 - val_loss: 7.8970e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.6549e-04 - val_loss: 7.8681e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 79us/step - loss: 1.6556e-04 - val_loss: 7.9801e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6498e-04 - val_loss: 7.7743e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.6468e-04 - val_loss: 7.8300e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.6450e-04 - val_loss: 7.9019e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.6412e-04 - val_loss: 7.7723e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.6359e-04 - val_loss: 7.8797e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.6340e-04 - val_loss: 7.8636e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.6278e-04 - val_loss: 7.6741e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.6231e-04 - val_loss: 7.7426e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6190e-04 - val_loss: 7.7792e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.6095e-04 - val_loss: 7.6508e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.6018e-04 - val_loss: 7.6699e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5941e-04 - val_loss: 7.6377e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.5855e-04 - val_loss: 7.4170e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.5695e-04 - val_loss: 7.5226e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5599e-04 - val_loss: 7.9618e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.5391e-04 - val_loss: 7.1295e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 79us/step - loss: 1.5127e-04 - val_loss: 7.5708e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 79us/step - loss: 1.4907e-04 - val_loss: 6.9221e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 9s 6ms/step - loss: 2.3929e-04 - val_loss: 9.2710e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.5709e-04 - val_loss: 7.4953e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.4826e-04 - val_loss: 6.6616e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.4643e-04 - val_loss: 6.8628e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.4226e-04 - val_loss: 6.8165e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3991e-04 - val_loss: 7.2014e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.3733e-04 - val_loss: 6.8509e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3498e-04 - val_loss: 6.3857e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3344e-04 - val_loss: 6.1278e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.3028e-04 - val_loss: 6.0690e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2783e-04 - val_loss: 6.1150e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2738e-04 - val_loss: 6.0051e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2460e-04 - val_loss: 6.2989e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2364e-04 - val_loss: 6.1844e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2302e-04 - val_loss: 6.2724e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2320e-04 - val_loss: 5.9530e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2289e-04 - val_loss: 6.0105e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2224e-04 - val_loss: 5.9589e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2292e-04 - val_loss: 5.9880e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2234e-04 - val_loss: 6.0843e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2206e-04 - val_loss: 6.0043e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2385e-04 - val_loss: 6.0408e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2321e-04 - val_loss: 6.6203e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 87us/step - loss: 1.2348e-04 - val_loss: 5.9517e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2298e-04 - val_loss: 6.1888e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 9s 6ms/step - loss: 2.4848e-04 - val_loss: 8.4281e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 87us/step - loss: 1.6172e-04 - val_loss: 8.4737e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - ETA: 0s - loss: 1.4728e-0 - 0s 90us/step - loss: 1.5412e-04 - val_loss: 6.7710e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.4942e-04 - val_loss: 7.2774e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.4656e-04 - val_loss: 6.8271e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.4325e-04 - val_loss: 6.6481e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.4022e-04 - val_loss: 6.6936e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.3726e-04 - val_loss: 6.7157e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.3227e-04 - val_loss: 6.5242e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2917e-04 - val_loss: 6.0375e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2718e-04 - val_loss: 6.0332e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2445e-04 - val_loss: 6.3238e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.2475e-04 - val_loss: 6.3000e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2624e-04 - val_loss: 6.2251e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2421e-04 - val_loss: 6.5568e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2398e-04 - val_loss: 6.0997e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2189e-04 - val_loss: 5.9292e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2213e-04 - val_loss: 6.7819e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2514e-04 - val_loss: 5.9873e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.2271e-04 - val_loss: 6.3901e-05\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2435e-04 - val_loss: 5.9601e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.2172e-04 - val_loss: 5.9136e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2253e-04 - val_loss: 6.0243e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2216e-04 - val_loss: 5.9803e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2135e-04 - val_loss: 5.9270e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 9s 5ms/step - loss: 2.8061e-04 - val_loss: 1.2297e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.7413e-04 - val_loss: 7.4587e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.6401e-04 - val_loss: 7.5013e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.6157e-04 - val_loss: 8.0480e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5943e-04 - val_loss: 8.2745e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.5575e-04 - val_loss: 7.0556e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5213e-04 - val_loss: 7.9174e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.4979e-04 - val_loss: 7.7246e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.4843e-04 - val_loss: 7.3635e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.4107e-04 - val_loss: 6.4174e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.3545e-04 - val_loss: 6.5311e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.3172e-04 - val_loss: 7.2567e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2847e-04 - val_loss: 6.6924e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2654e-04 - val_loss: 6.1974e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2358e-04 - val_loss: 5.9976e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2354e-04 - val_loss: 6.0387e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2223e-04 - val_loss: 6.1797e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 122us/step - loss: 1.2370e-04 - val_loss: 6.3405e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.2260e-04 - val_loss: 5.9886e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2219e-04 - val_loss: 6.0006e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2386e-04 - val_loss: 6.2023e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2589e-04 - val_loss: 6.8855e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2623e-04 - val_loss: 5.9822e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2379e-04 - val_loss: 6.0188e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2186e-04 - val_loss: 5.9897e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 9s 6ms/step - loss: 2.6699e-04 - val_loss: 1.5891e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.7712e-04 - val_loss: 7.0791e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.6084e-04 - val_loss: 8.3859e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.5593e-04 - val_loss: 7.2645e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.5263e-04 - val_loss: 7.2691e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.5074e-04 - val_loss: 7.0272e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.4811e-04 - val_loss: 6.9992e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.4555e-04 - val_loss: 6.9020e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.4327e-04 - val_loss: 6.8579e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.4077e-04 - val_loss: 6.5540e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 79us/step - loss: 1.3862e-04 - val_loss: 6.3662e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.3613e-04 - val_loss: 7.3138e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.3434e-04 - val_loss: 6.1970e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.3288e-04 - val_loss: 6.1747e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2952e-04 - val_loss: 6.2059e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2784e-04 - val_loss: 6.0596e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2667e-04 - val_loss: 6.1183e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2530e-04 - val_loss: 6.2038e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.2652e-04 - val_loss: 6.0959e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2477e-04 - val_loss: 6.3277e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 80us/step - loss: 1.2305e-04 - val_loss: 5.9682e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2398e-04 - val_loss: 6.0170e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.2456e-04 - val_loss: 5.9730e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2241e-04 - val_loss: 6.0544e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 81us/step - loss: 1.2346e-04 - val_loss: 5.9930e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 3.0024e-04 - val_loss: 1.6082e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.7904e-04 - val_loss: 7.1877e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.6359e-04 - val_loss: 8.2373e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 82us/step - loss: 1.5952e-04 - val_loss: 7.3696e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5680e-04 - val_loss: 7.4478e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.5419e-04 - val_loss: 7.7080e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.5158e-04 - val_loss: 6.9748e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.4851e-04 - val_loss: 6.9575e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.4539e-04 - val_loss: 6.8002e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.4256e-04 - val_loss: 6.5034e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.3896e-04 - val_loss: 6.3778e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.3567e-04 - val_loss: 6.2557e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.3211e-04 - val_loss: 6.2809e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2924e-04 - val_loss: 6.0838e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2736e-04 - val_loss: 6.0394e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2534e-04 - val_loss: 6.5915e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2524e-04 - val_loss: 6.3422e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2396e-04 - val_loss: 6.1251e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2337e-04 - val_loss: 6.0058e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2304e-04 - val_loss: 6.0088e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2311e-04 - val_loss: 6.0086e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2358e-04 - val_loss: 6.0403e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2382e-04 - val_loss: 5.9924e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2275e-04 - val_loss: 6.1774e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2631e-04 - val_loss: 6.4595e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 10s 6ms/step - loss: 2.6814e-04 - val_loss: 1.2288e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.7243e-04 - val_loss: 7.4160e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.5952e-04 - val_loss: 7.2474e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.5523e-04 - val_loss: 7.5098e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 1.5242e-04 - val_loss: 7.5896e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.4864e-04 - val_loss: 7.2637e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 87us/step - loss: 1.4440e-04 - val_loss: 6.8358e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.4041e-04 - val_loss: 6.4714e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.3545e-04 - val_loss: 6.4757e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.3241e-04 - val_loss: 7.9474e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.3113e-04 - val_loss: 6.9290e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2717e-04 - val_loss: 6.3308e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 1.2441e-04 - val_loss: 5.9473e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.2286e-04 - val_loss: 6.1051e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 90us/step - loss: 1.2392e-04 - val_loss: 6.1818e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2237e-04 - val_loss: 5.9527e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2409e-04 - val_loss: 5.9559e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 83us/step - loss: 1.2302e-04 - val_loss: 5.9552e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.2386e-04 - val_loss: 6.1993e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.2290e-04 - val_loss: 5.9362e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.2177e-04 - val_loss: 6.1950e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 84us/step - loss: 1.2291e-04 - val_loss: 6.2012e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2390e-04 - val_loss: 6.0985e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.2323e-04 - val_loss: 6.7143e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.2301e-04 - val_loss: 5.9262e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 11s 6ms/step - loss: 2.6109e-04 - val_loss: 7.3758e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.6614e-04 - val_loss: 9.1270e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5893e-04 - val_loss: 7.3115e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 1.5282e-04 - val_loss: 7.0547e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.4832e-04 - val_loss: 7.0544e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.4304e-04 - val_loss: 6.9287e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.3806e-04 - val_loss: 6.4123e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.3249e-04 - val_loss: 6.1472e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.2790e-04 - val_loss: 6.0083e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2516e-04 - val_loss: 5.9438e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2279e-04 - val_loss: 5.9713e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.2188e-04 - val_loss: 6.1239e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2767e-04 - val_loss: 7.0339e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 85us/step - loss: 1.2192e-04 - val_loss: 5.9350e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2314e-04 - val_loss: 6.0316e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.2281e-04 - val_loss: 6.1919e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.2248e-04 - val_loss: 6.1496e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 1.2227e-04 - val_loss: 5.9522e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2216e-04 - val_loss: 5.9236e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2259e-04 - val_loss: 5.9107e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2223e-04 - val_loss: 5.9113e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 1.2247e-04 - val_loss: 6.4633e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2195e-04 - val_loss: 6.0176e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.2130e-04 - val_loss: 6.0243e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.2283e-04 - val_loss: 5.9367e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 11s 7ms/step - loss: 3.1225e-04 - val_loss: 9.7351e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.7695e-04 - val_loss: 8.2816e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.6290e-04 - val_loss: 7.2092e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 86us/step - loss: 1.5884e-04 - val_loss: 7.8983e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 88us/step - loss: 1.5839e-04 - val_loss: 7.2480e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5690e-04 - val_loss: 7.6523e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.5589e-04 - val_loss: 7.5998e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5483e-04 - val_loss: 7.1860e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5231e-04 - val_loss: 7.4624e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.5134e-04 - val_loss: 7.3724e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.4931e-04 - val_loss: 6.9961e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.4742e-04 - val_loss: 7.1953e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 106us/step - loss: 1.4449e-04 - val_loss: 6.9130e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.4207e-04 - val_loss: 6.9748e-05\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.3936e-04 - val_loss: 6.8307e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.3722e-04 - val_loss: 7.0664e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.3467e-04 - val_loss: 6.2775e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 107us/step - loss: 1.3125e-04 - val_loss: 6.2412e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.3038e-04 - val_loss: 6.1662e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2701e-04 - val_loss: 6.0484e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2572e-04 - val_loss: 5.9970e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2453e-04 - val_loss: 6.0362e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2395e-04 - val_loss: 5.9568e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 91us/step - loss: 1.2467e-04 - val_loss: 5.9726e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2283e-04 - val_loss: 5.9632e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 11s 7ms/step - loss: 2.6630e-04 - val_loss: 8.6542e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 1.6107e-04 - val_loss: 7.7307e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.5299e-04 - val_loss: 7.1117e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.4853e-04 - val_loss: 7.2031e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.4460e-04 - val_loss: 7.0580e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.4020e-04 - val_loss: 6.9141e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.3661e-04 - val_loss: 7.1008e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.3253e-04 - val_loss: 6.8072e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 1.3098e-04 - val_loss: 7.4672e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2812e-04 - val_loss: 6.0141e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 89us/step - loss: 1.2590e-04 - val_loss: 6.0368e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 92us/step - loss: 1.2359e-04 - val_loss: 6.0478e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 1.2292e-04 - val_loss: 6.0365e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 140us/step - loss: 1.2255e-04 - val_loss: 6.1842e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 101us/step - loss: 1.2396e-04 - val_loss: 6.3741e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 114us/step - loss: 1.2237e-04 - val_loss: 5.9586e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 111us/step - loss: 1.2208e-04 - val_loss: 5.9634e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 111us/step - loss: 1.2222e-04 - val_loss: 5.9551e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 123us/step - loss: 1.2338e-04 - val_loss: 6.2055e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 1.2894e-04 - val_loss: 6.3123e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.2370e-04 - val_loss: 5.9743e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 125us/step - loss: 1.2201e-04 - val_loss: 6.0310e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 132us/step - loss: 1.2323e-04 - val_loss: 6.3061e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 104us/step - loss: 1.2434e-04 - val_loss: 5.9699e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.2483e-04 - val_loss: 6.0871e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 12s 7ms/step - loss: 2.6018e-04 - val_loss: 8.6957e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 1.6629e-04 - val_loss: 8.7042e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.5850e-04 - val_loss: 6.8817e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.5151e-04 - val_loss: 7.5726e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 96us/step - loss: 1.4848e-04 - val_loss: 7.1866e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.4593e-04 - val_loss: 7.1915e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.4126e-04 - val_loss: 7.7460e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 1.3671e-04 - val_loss: 7.0494e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 93us/step - loss: 1.3260e-04 - val_loss: 6.3313e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2816e-04 - val_loss: 6.0239e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 94us/step - loss: 1.2536e-04 - val_loss: 6.0952e-05\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2327e-04 - val_loss: 5.9758e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2400e-04 - val_loss: 5.9802e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 106us/step - loss: 1.2192e-04 - val_loss: 5.9929e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 109us/step - loss: 1.2304e-04 - val_loss: 6.0435e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2151e-04 - val_loss: 6.4286e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2207e-04 - val_loss: 6.0036e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2248e-04 - val_loss: 5.9669e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2169e-04 - val_loss: 5.9903e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2240e-04 - val_loss: 7.2307e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 103us/step - loss: 1.2609e-04 - val_loss: 5.9261e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2368e-04 - val_loss: 5.9232e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2347e-04 - val_loss: 6.5219e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2575e-04 - val_loss: 6.3080e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2445e-04 - val_loss: 6.0502e-05\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 12s 7ms/step - loss: 2.6089e-04 - val_loss: 7.2081e-05\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.7241e-04 - val_loss: 9.0993e-05\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.5844e-04 - val_loss: 7.4402e-05\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.5335e-04 - val_loss: 6.8987e-05\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 1.4792e-04 - val_loss: 7.3658e-05\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 100us/step - loss: 1.4229e-04 - val_loss: 6.8385e-05\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.3615e-04 - val_loss: 7.2551e-05\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.3021e-04 - val_loss: 6.4459e-05\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2628e-04 - val_loss: 5.9416e-05\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 99us/step - loss: 1.2397e-04 - val_loss: 6.2478e-05\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 105us/step - loss: 1.2232e-04 - val_loss: 5.9398e-05\n",
      "Epoch 12/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2242e-04 - val_loss: 6.3505e-05\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2296e-04 - val_loss: 6.2333e-05\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2223e-04 - val_loss: 5.9936e-05\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2143e-04 - val_loss: 5.9740e-05\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2241e-04 - val_loss: 6.2314e-05\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 108us/step - loss: 1.2249e-04 - val_loss: 6.3377e-05\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2265e-04 - val_loss: 5.9259e-05\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2184e-04 - val_loss: 6.1623e-05\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 102us/step - loss: 1.2221e-04 - val_loss: 6.1923e-05\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2374e-04 - val_loss: 6.0098e-05\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 98us/step - loss: 1.2268e-04 - val_loss: 6.1708e-05\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2102e-04 - val_loss: 6.2341e-05\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 97us/step - loss: 1.2192e-04 - val_loss: 5.9172e-05\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 95us/step - loss: 1.2237e-04 - val_loss: 6.0774e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 13s 8ms/step - loss: 3.9778e-04 - val_loss: 1.4767e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 120us/step - loss: 2.1021e-04 - val_loss: 8.6968e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.8415e-04 - val_loss: 8.2772e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.8069e-04 - val_loss: 8.7010e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.7867e-04 - val_loss: 8.3630e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 116us/step - loss: 1.7784e-04 - val_loss: 8.1594e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 117us/step - loss: 1.7560e-04 - val_loss: 8.3224e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 121us/step - loss: 1.7391e-04 - val_loss: 8.3979e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.7282e-04 - val_loss: 8.0700e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 116us/step - loss: 1.7063e-04 - val_loss: 8.3002e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 111us/step - loss: 1.6905e-04 - val_loss: 7.7755e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 116us/step - loss: 1.6786e-04 - val_loss: 8.2553e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 119us/step - loss: 1.6610e-04 - val_loss: 7.5888e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 119us/step - loss: 1.6472e-04 - val_loss: 7.8867e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 117us/step - loss: 1.6310e-04 - val_loss: 7.6771e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 119us/step - loss: 1.6174e-04 - val_loss: 7.6316e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 117us/step - loss: 1.5946e-04 - val_loss: 7.5119e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - ETA: 0s - loss: 1.5816e-0 - 0s 115us/step - loss: 1.5817e-04 - val_loss: 7.3605e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 118us/step - loss: 1.5637e-04 - val_loss: 7.2365e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 119us/step - loss: 1.5391e-04 - val_loss: 7.6292e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 118us/step - loss: 1.5329e-04 - val_loss: 6.9664e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 114us/step - loss: 1.5062e-04 - val_loss: 6.9294e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.4837e-04 - val_loss: 8.4150e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 120us/step - loss: 1.4600e-04 - val_loss: 6.7489e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 122us/step - loss: 1.4422e-04 - val_loss: 6.7014e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 14s 9ms/step - loss: 2.4993e-04 - val_loss: 1.3314e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 132us/step - loss: 1.5672e-04 - val_loss: 6.8727e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.5327e-04 - val_loss: 7.5819e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.4915e-04 - val_loss: 7.1707e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.4709e-04 - val_loss: 6.7403e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.4585e-04 - val_loss: 6.8567e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.4215e-04 - val_loss: 6.9765e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.3982e-04 - val_loss: 6.4904e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.3767e-04 - val_loss: 6.3395e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 129us/step - loss: 1.3489e-04 - val_loss: 6.6321e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.3200e-04 - val_loss: 6.4714e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.2954e-04 - val_loss: 6.9787e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.3216e-04 - val_loss: 6.6065e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.2661e-04 - val_loss: 6.0961e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 121us/step - loss: 1.2563e-04 - val_loss: 6.0262e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2507e-04 - val_loss: 5.9588e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 122us/step - loss: 1.2337e-04 - val_loss: 6.3682e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2320e-04 - val_loss: 6.4640e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2387e-04 - val_loss: 5.9414e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2219e-04 - val_loss: 6.3876e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2275e-04 - val_loss: 6.2610e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 122us/step - loss: 1.2194e-04 - val_loss: 6.0244e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.2199e-04 - val_loss: 6.1214e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2215e-04 - val_loss: 6.0662e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.2362e-04 - val_loss: 6.1216e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 15s 9ms/step - loss: 2.8636e-04 - val_loss: 1.2718e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.7431e-04 - val_loss: 7.4211e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.6156e-04 - val_loss: 7.2656e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.6054e-04 - val_loss: 8.0519e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.5475e-04 - val_loss: 7.4589e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.5038e-04 - val_loss: 7.4704e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.4612e-04 - val_loss: 7.8886e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.4303e-04 - val_loss: 7.2370e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 122us/step - loss: 1.3658e-04 - val_loss: 6.6068e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.3251e-04 - val_loss: 6.4690e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 132us/step - loss: 1.2812e-04 - val_loss: 6.1991e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 129us/step - loss: 1.2530e-04 - val_loss: 6.2523e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.2355e-04 - val_loss: 6.1414e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2316e-04 - val_loss: 6.1940e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 127us/step - loss: 1.2357e-04 - val_loss: 6.3182e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2323e-04 - val_loss: 5.9926e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2310e-04 - val_loss: 6.7388e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2372e-04 - val_loss: 5.9853e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2446e-04 - val_loss: 6.2373e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.2308e-04 - val_loss: 6.1438e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2310e-04 - val_loss: 5.9967e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.2284e-04 - val_loss: 5.9755e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2354e-04 - val_loss: 5.9761e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2488e-04 - val_loss: 6.1280e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 129us/step - loss: 1.2227e-04 - val_loss: 6.0346e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 15s 9ms/step - loss: 2.8059e-04 - val_loss: 1.0041e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.6905e-04 - val_loss: 7.8282e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.6300e-04 - val_loss: 7.0098e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 122us/step - loss: 1.5844e-04 - val_loss: 7.5801e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.5236e-04 - val_loss: 7.4737e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.4803e-04 - val_loss: 6.8248e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.4349e-04 - val_loss: 6.7261e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.3902e-04 - val_loss: 6.7038e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.3451e-04 - val_loss: 6.3441e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.2975e-04 - val_loss: 6.2497e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.2782e-04 - val_loss: 7.0160e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.2494e-04 - val_loss: 6.1337e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2351e-04 - val_loss: 6.1906e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.2293e-04 - val_loss: 6.0977e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.2373e-04 - val_loss: 6.0371e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.2260e-04 - val_loss: 6.0676e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.2227e-04 - val_loss: 6.1521e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.2245e-04 - val_loss: 6.0377e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2220e-04 - val_loss: 6.0716e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.2240e-04 - val_loss: 6.3050e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2230e-04 - val_loss: 6.3419e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.2266e-04 - val_loss: 6.0240e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2244e-04 - val_loss: 6.0311e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2306e-04 - val_loss: 6.8386e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.2318e-04 - val_loss: 6.1667e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 16s 10ms/step - loss: 2.5225e-04 - val_loss: 1.3978e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.5987e-04 - val_loss: 6.8535e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.5281e-04 - val_loss: 7.7794e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.4846e-04 - val_loss: 7.0557e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.4566e-04 - val_loss: 6.9442e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.4332e-04 - val_loss: 6.7986e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.4074e-04 - val_loss: 7.1840e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.3840e-04 - val_loss: 6.5350e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.3569e-04 - val_loss: 7.2694e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 127us/step - loss: 1.3443e-04 - val_loss: 7.1797e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.3382e-04 - val_loss: 6.3551e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.3015e-04 - val_loss: 6.2111e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2738e-04 - val_loss: 6.1851e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2564e-04 - val_loss: 6.2656e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2484e-04 - val_loss: 6.0001e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.2439e-04 - val_loss: 6.5126e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.2527e-04 - val_loss: 7.8965e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.2431e-04 - val_loss: 6.0977e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 123us/step - loss: 1.2312e-04 - val_loss: 6.0866e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2484e-04 - val_loss: 6.5423e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.2593e-04 - val_loss: 5.9791e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 132us/step - loss: 1.2274e-04 - val_loss: 5.9771e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.2191e-04 - val_loss: 6.0402e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 124us/step - loss: 1.2182e-04 - val_loss: 5.9833e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 125us/step - loss: 1.2330e-04 - val_loss: 6.1191e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 17s 10ms/step - loss: 3.2705e-04 - val_loss: 1.8296e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.8935e-04 - val_loss: 7.5195e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.7420e-04 - val_loss: 8.4222e-05\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645/1645 [==============================] - 0s 128us/step - loss: 1.6836e-04 - val_loss: 7.9295e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.6491e-04 - val_loss: 7.7668e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.6180e-04 - val_loss: 7.7161e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.5862e-04 - val_loss: 7.5031e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.5512e-04 - val_loss: 7.2788e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.5176e-04 - val_loss: 7.8131e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.4862e-04 - val_loss: 7.0037e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.4425e-04 - val_loss: 7.6189e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.4136e-04 - val_loss: 7.1885e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 127us/step - loss: 1.3678e-04 - val_loss: 6.4496e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 130us/step - loss: 1.3320e-04 - val_loss: 6.2673e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.3006e-04 - val_loss: 6.3890e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 127us/step - loss: 1.2796e-04 - val_loss: 6.1453e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.2543e-04 - val_loss: 6.0279e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2427e-04 - val_loss: 6.0017e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2375e-04 - val_loss: 6.2891e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2513e-04 - val_loss: 5.9778e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 127us/step - loss: 1.2414e-04 - val_loss: 5.9671e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.2201e-04 - val_loss: 6.5234e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2594e-04 - val_loss: 6.5389e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 126us/step - loss: 1.2556e-04 - val_loss: 5.9727e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 129us/step - loss: 1.2381e-04 - val_loss: 6.1532e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 17s 11ms/step - loss: 2.7997e-04 - val_loss: 1.3117e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.7020e-04 - val_loss: 7.2306e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.6269e-04 - val_loss: 7.5063e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.6003e-04 - val_loss: 8.2783e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.5628e-04 - val_loss: 7.3202e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.5222e-04 - val_loss: 7.2604e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.4765e-04 - val_loss: 6.9370e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.4330e-04 - val_loss: 7.1467e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.3736e-04 - val_loss: 6.5593e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.3241e-04 - val_loss: 6.3044e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.2753e-04 - val_loss: 6.2130e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.2658e-04 - val_loss: 5.9926e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2428e-04 - val_loss: 6.0756e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2271e-04 - val_loss: 5.9770e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2453e-04 - val_loss: 5.9698e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2353e-04 - val_loss: 6.1943e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2250e-04 - val_loss: 6.4092e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 154us/step - loss: 1.2671e-04 - val_loss: 6.1428e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2316e-04 - val_loss: 6.7435e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2379e-04 - val_loss: 6.6976e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2325e-04 - val_loss: 6.2301e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 154us/step - loss: 1.2286e-04 - val_loss: 6.0679e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 156us/step - loss: 1.2224e-04 - val_loss: 5.9889e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2325e-04 - val_loss: 5.9633e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2209e-04 - val_loss: 5.9833e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 18s 11ms/step - loss: 2.7069e-04 - val_loss: 9.4367e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.7086e-04 - val_loss: 8.2786e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.5969e-04 - val_loss: 7.2823e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.5499e-04 - val_loss: 7.2494e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.5032e-04 - val_loss: 6.8675e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 135us/step - loss: 1.4492e-04 - val_loss: 6.5145e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.3837e-04 - val_loss: 6.8889e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.3201e-04 - val_loss: 6.1741e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.2628e-04 - val_loss: 6.4336e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2572e-04 - val_loss: 6.3432e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2429e-04 - val_loss: 6.3504e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2193e-04 - val_loss: 5.9526e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2249e-04 - val_loss: 5.9561e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2199e-04 - val_loss: 6.0864e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.2189e-04 - val_loss: 6.1151e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.2310e-04 - val_loss: 6.3084e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.2146e-04 - val_loss: 5.9485e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2286e-04 - val_loss: 5.9431e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 132us/step - loss: 1.2354e-04 - val_loss: 7.5879e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2896e-04 - val_loss: 6.1160e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2495e-04 - val_loss: 7.0739e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2463e-04 - val_loss: 5.9371e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2133e-04 - val_loss: 6.2125e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2161e-04 - val_loss: 5.9417e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 138us/step - loss: 1.2160e-04 - val_loss: 5.9694e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 19s 11ms/step - loss: 1.9270e-04 - val_loss: 7.5306e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.4358e-04 - val_loss: 7.9277e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.3325e-04 - val_loss: 6.3711e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.3023e-04 - val_loss: 6.3123e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.2848e-04 - val_loss: 6.1256e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2679e-04 - val_loss: 6.3470e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 134us/step - loss: 1.2555e-04 - val_loss: 6.2958e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2767e-04 - val_loss: 6.0699e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 133us/step - loss: 1.2846e-04 - val_loss: 6.0767e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2216e-04 - val_loss: 6.7248e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2723e-04 - val_loss: 6.2102e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 131us/step - loss: 1.2332e-04 - val_loss: 6.2525e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2297e-04 - val_loss: 6.4536e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2344e-04 - val_loss: 6.1305e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2358e-04 - val_loss: 6.1162e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.2251e-04 - val_loss: 6.1851e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2228e-04 - val_loss: 5.9799e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2223e-04 - val_loss: 5.9822e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2434e-04 - val_loss: 6.5174e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 146us/step - loss: 1.2556e-04 - val_loss: 6.1663e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2187e-04 - val_loss: 5.9979e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2161e-04 - val_loss: 6.0501e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2581e-04 - val_loss: 6.8191e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2580e-04 - val_loss: 5.9697e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2241e-04 - val_loss: 5.9704e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 20s 12ms/step - loss: 3.5850e-04 - val_loss: 1.8488e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.9870e-04 - val_loss: 7.7698e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.8050e-04 - val_loss: 8.8014e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.7461e-04 - val_loss: 8.4206e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.6936e-04 - val_loss: 7.5131e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 144us/step - loss: 1.6424e-04 - val_loss: 8.5070e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.6083e-04 - val_loss: 7.5469e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.5483e-04 - val_loss: 7.1629e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.5037e-04 - val_loss: 7.3289e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.4516e-04 - val_loss: 6.6206e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.4062e-04 - val_loss: 6.8842e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.3689e-04 - val_loss: 6.2712e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.3334e-04 - val_loss: 6.1986e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.2949e-04 - val_loss: 6.0573e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2589e-04 - val_loss: 6.6643e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2495e-04 - val_loss: 6.2263e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2466e-04 - val_loss: 6.1305e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2455e-04 - val_loss: 6.3233e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 136us/step - loss: 1.2231e-04 - val_loss: 6.0635e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 144us/step - loss: 1.2241e-04 - val_loss: 6.0252e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2602e-04 - val_loss: 6.0640e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2432e-04 - val_loss: 6.0160e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.2274e-04 - val_loss: 6.0711e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2363e-04 - val_loss: 6.1921e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 137us/step - loss: 1.2221e-04 - val_loss: 6.0161e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 20s 12ms/step - loss: 2.7847e-04 - val_loss: 7.3212e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.6850e-04 - val_loss: 1.0032e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.6306e-04 - val_loss: 6.8709e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.5039e-04 - val_loss: 7.0143e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.4611e-04 - val_loss: 7.0186e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.4086e-04 - val_loss: 6.5605e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 152us/step - loss: 1.3652e-04 - val_loss: 6.2276e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.3443e-04 - val_loss: 6.5029e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.3096e-04 - val_loss: 7.0214e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2484e-04 - val_loss: 6.7412e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2370e-04 - val_loss: 5.9945e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2394e-04 - val_loss: 6.0729e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2248e-04 - val_loss: 6.2947e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2576e-04 - val_loss: 7.0325e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2460e-04 - val_loss: 7.7646e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.2633e-04 - val_loss: 6.2487e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2436e-04 - val_loss: 6.6455e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2536e-04 - val_loss: 6.1549e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 139us/step - loss: 1.2425e-04 - val_loss: 5.9927e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 145us/step - loss: 1.2176e-04 - val_loss: 6.2967e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2235e-04 - val_loss: 6.1921e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 141us/step - loss: 1.2715e-04 - val_loss: 6.0238e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2305e-04 - val_loss: 6.6361e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 142us/step - loss: 1.2469e-04 - val_loss: 5.9531e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2179e-04 - val_loss: 5.9769e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 21s 13ms/step - loss: 2.2914e-04 - val_loss: 7.6461e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.5941e-04 - val_loss: 8.6284e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 146us/step - loss: 1.4951e-04 - val_loss: 8.1675e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.4471e-04 - val_loss: 6.8725e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - ETA: 0s - loss: 1.4614e-0 - 0s 153us/step - loss: 1.4023e-04 - val_loss: 7.0277e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.3552e-04 - val_loss: 6.7623e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.3108e-04 - val_loss: 6.1066e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2845e-04 - val_loss: 6.3742e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 155us/step - loss: 1.2633e-04 - val_loss: 6.0215e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 160us/step - loss: 1.2239e-04 - val_loss: 6.0146e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2474e-04 - val_loss: 7.4009e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.2461e-04 - val_loss: 5.9697e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 146us/step - loss: 1.2272e-04 - val_loss: 6.0614e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 155us/step - loss: 1.2277e-04 - val_loss: 6.0811e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2170e-04 - val_loss: 6.0440e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2379e-04 - val_loss: 5.9712e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 144us/step - loss: 1.2643e-04 - val_loss: 6.2087e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 179us/step - loss: 1.2342e-04 - val_loss: 6.3044e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.2497e-04 - val_loss: 6.2305e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2188e-04 - val_loss: 5.9947e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 143us/step - loss: 1.2429e-04 - val_loss: 6.3067e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2277e-04 - val_loss: 6.0992e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2173e-04 - val_loss: 5.9507e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2346e-04 - val_loss: 7.0346e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 140us/step - loss: 1.2196e-04 - val_loss: 6.0191e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 21s 13ms/step - loss: 2.5976e-04 - val_loss: 8.0727e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 163us/step - loss: 1.6529e-04 - val_loss: 8.8300e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.5757e-04 - val_loss: 6.8514e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.5040e-04 - val_loss: 6.6176e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 156us/step - loss: 1.4512e-04 - val_loss: 7.1440e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.3973e-04 - val_loss: 7.0014e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.3747e-04 - val_loss: 6.6673e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.3366e-04 - val_loss: 6.4023e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.2981e-04 - val_loss: 6.1338e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 160us/step - loss: 1.2724e-04 - val_loss: 6.1117e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.2553e-04 - val_loss: 5.9819e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2371e-04 - val_loss: 6.0912e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 158us/step - loss: 1.2281e-04 - val_loss: 5.9613e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2394e-04 - val_loss: 6.3811e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2384e-04 - val_loss: 5.9664e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2275e-04 - val_loss: 6.1313e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 146us/step - loss: 1.2232e-04 - val_loss: 5.9690e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.2241e-04 - val_loss: 6.0077e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2251e-04 - val_loss: 6.0192e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.2257e-04 - val_loss: 6.0078e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2230e-04 - val_loss: 5.9943e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 155us/step - loss: 1.2252e-04 - val_loss: 6.2375e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2282e-04 - val_loss: 6.0223e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.2248e-04 - val_loss: 5.9721e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.2198e-04 - val_loss: 6.3983e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 22s 13ms/step - loss: 2.5078e-04 - val_loss: 7.1609e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.5822e-04 - val_loss: 8.9665e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 161us/step - loss: 1.4980e-04 - val_loss: 6.9694e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 175us/step - loss: 1.4324e-04 - val_loss: 6.8654e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.3942e-04 - val_loss: 6.4409e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 161us/step - loss: 1.3624e-04 - val_loss: 6.9066e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.3105e-04 - val_loss: 6.3843e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 159us/step - loss: 1.2873e-04 - val_loss: 6.0814e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 169us/step - loss: 1.2570e-04 - val_loss: 6.5735e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 159us/step - loss: 1.2646e-04 - val_loss: 5.9981e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 161us/step - loss: 1.2660e-04 - val_loss: 6.0694e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 161us/step - loss: 1.2380e-04 - val_loss: 7.0136e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 168us/step - loss: 1.2514e-04 - val_loss: 6.0119e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 157us/step - loss: 1.2233e-04 - val_loss: 6.0019e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 164us/step - loss: 1.2272e-04 - val_loss: 6.6951e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.2529e-04 - val_loss: 6.0401e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 163us/step - loss: 1.2217e-04 - val_loss: 6.0459e-05\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645/1645 [==============================] - 0s 155us/step - loss: 1.2293e-04 - val_loss: 6.0110e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 162us/step - loss: 1.2347e-04 - val_loss: 6.6980e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 156us/step - loss: 1.2251e-04 - val_loss: 6.4561e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 171us/step - loss: 1.2537e-04 - val_loss: 6.3135e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 164us/step - loss: 1.2485e-04 - val_loss: 6.8534e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 165us/step - loss: 1.2370e-04 - val_loss: 6.0223e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 168us/step - loss: 1.2352e-04 - val_loss: 5.9711e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 163us/step - loss: 1.2229e-04 - val_loss: 6.3563e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 23s 14ms/step - loss: 2.3097e-04 - val_loss: 7.2490e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 148us/step - loss: 1.6167e-04 - val_loss: 8.9536e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 147us/step - loss: 1.4806e-04 - val_loss: 8.4379e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 158us/step - loss: 1.4391e-04 - val_loss: 6.6380e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.3740e-04 - val_loss: 7.0099e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.3314e-04 - val_loss: 6.2672e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2944e-04 - val_loss: 6.1357e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.2589e-04 - val_loss: 6.0781e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 150us/step - loss: 1.2387e-04 - val_loss: 6.4414e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 149us/step - loss: 1.2488e-04 - val_loss: 6.1691e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 152us/step - loss: 1.2619e-04 - val_loss: 6.0397e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 160us/step - loss: 1.2473e-04 - val_loss: 6.0924e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 151us/step - loss: 1.2271e-04 - val_loss: 6.8297e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 153us/step - loss: 1.2311e-04 - val_loss: 6.0201e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 154us/step - loss: 1.2363e-04 - val_loss: 6.1641e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 157us/step - loss: 1.2427e-04 - val_loss: 6.8117e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 164us/step - loss: 1.2503e-04 - val_loss: 6.7298e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 166us/step - loss: 1.2336e-04 - val_loss: 6.0764e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 164us/step - loss: 1.2543e-04 - val_loss: 5.9909e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 175us/step - loss: 1.2374e-04 - val_loss: 6.0537e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 184us/step - loss: 1.2613e-04 - val_loss: 6.2653e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 168us/step - loss: 1.2689e-04 - val_loss: 6.1026e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 176us/step - loss: 1.2160e-04 - val_loss: 6.3958e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 170us/step - loss: 1.2299e-04 - val_loss: 5.9805e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 168us/step - loss: 1.2187e-04 - val_loss: 6.0915e-05\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 25s 15ms/step - loss: 2.4741e-04 - val_loss: 8.2747e-05\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 0s 181us/step - loss: 1.6824e-04 - val_loss: 6.9176e-05\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 0s 179us/step - loss: 1.5090e-04 - val_loss: 7.0181e-05\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 0s 181us/step - loss: 1.4345e-04 - val_loss: 6.6520e-05\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 0s 179us/step - loss: 1.3742e-04 - val_loss: 6.2519e-05\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 0s 188us/step - loss: 1.2968e-04 - val_loss: 6.1813e-05\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 0s 185us/step - loss: 1.2793e-04 - val_loss: 6.0011e-05\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 0s 181us/step - loss: 1.2480e-04 - val_loss: 6.7327e-05\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 0s 187us/step - loss: 1.2331e-04 - val_loss: 6.9441e-05\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 0s 184us/step - loss: 1.2369e-04 - val_loss: 6.0131e-05\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 0s 176us/step - loss: 1.2369e-04 - val_loss: 6.0375e-05\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 0s 178us/step - loss: 1.2611e-04 - val_loss: 7.5812e-05\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 0s 184us/step - loss: 1.2477e-04 - val_loss: 5.9859e-05\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 0s 181us/step - loss: 1.2233e-04 - val_loss: 6.2735e-05\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 0s 179us/step - loss: 1.2225e-04 - val_loss: 6.0393e-05\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 0s 182us/step - loss: 1.2200e-04 - val_loss: 6.3235e-05\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 0s 190us/step - loss: 1.2198e-04 - val_loss: 6.0340e-05\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 0s 181us/step - loss: 1.2406e-04 - val_loss: 6.5193e-05\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 0s 177us/step - loss: 1.2220e-04 - val_loss: 6.3175e-05\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 0s 184us/step - loss: 1.2221e-04 - val_loss: 6.2069e-05\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 0s 173us/step - loss: 1.2314e-04 - val_loss: 6.1066e-05\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 0s 179us/step - loss: 1.2941e-04 - val_loss: 5.9737e-05\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 0s 185us/step - loss: 1.2362e-04 - val_loss: 6.4330e-05\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 0s 182us/step - loss: 1.2417e-04 - val_loss: 5.9595e-05\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 0s 185us/step - loss: 1.2228e-04 - val_loss: 6.9222e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 25s 15ms/step - loss: 2.5499e-04 - val_loss: 1.4329e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 200us/step - loss: 1.6790e-04 - val_loss: 6.9377e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.5547e-04 - val_loss: 7.9443e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.5355e-04 - val_loss: 7.3369e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.5095e-04 - val_loss: 7.0713e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.4860e-04 - val_loss: 7.2682e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.4673e-04 - val_loss: 7.0809e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.4472e-04 - val_loss: 6.5968e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.4268e-04 - val_loss: 6.6196e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.4020e-04 - val_loss: 6.7892e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.3728e-04 - val_loss: 6.3461e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.3575e-04 - val_loss: 6.7334e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.3324e-04 - val_loss: 6.5985e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.3189e-04 - val_loss: 6.4427e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.2918e-04 - val_loss: 6.3522e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2803e-04 - val_loss: 6.2972e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.2730e-04 - val_loss: 6.3072e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2704e-04 - val_loss: 6.5395e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.2536e-04 - val_loss: 6.2227e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2494e-04 - val_loss: 6.2672e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2612e-04 - val_loss: 6.1157e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2536e-04 - val_loss: 6.0581e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.2540e-04 - val_loss: 6.0563e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2621e-04 - val_loss: 6.0664e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2438e-04 - val_loss: 6.1099e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 25s 15ms/step - loss: 2.0682e-04 - val_loss: 8.2968e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.4403e-04 - val_loss: 6.7113e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.4035e-04 - val_loss: 6.3822e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 174us/step - loss: 1.3905e-04 - val_loss: 6.8696e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.3652e-04 - val_loss: 6.6373e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 177us/step - loss: 1.3487e-04 - val_loss: 6.4849e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 175us/step - loss: 1.3292e-04 - val_loss: 6.4531e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.3138e-04 - val_loss: 6.5427e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.3014e-04 - val_loss: 6.2921e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2830e-04 - val_loss: 6.4266e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 172us/step - loss: 1.2720e-04 - val_loss: 6.1296e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.2595e-04 - val_loss: 5.9908e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.2439e-04 - val_loss: 5.9237e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 198us/step - loss: 1.2418e-04 - val_loss: 5.9797e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2339e-04 - val_loss: 5.8550e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 182us/step - loss: 1.2293e-04 - val_loss: 5.8547e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.2288e-04 - val_loss: 5.8897e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2344e-04 - val_loss: 5.8698e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2426e-04 - val_loss: 6.0711e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.2255e-04 - val_loss: 6.0910e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.2295e-04 - val_loss: 5.9409e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.2582e-04 - val_loss: 6.2447e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2432e-04 - val_loss: 6.0751e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2315e-04 - val_loss: 5.9479e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 169us/step - loss: 1.2339e-04 - val_loss: 5.8521e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 26s 16ms/step - loss: 2.8202e-04 - val_loss: 1.1486e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.7293e-04 - val_loss: 7.6454e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.6833e-04 - val_loss: 7.1666e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.6208e-04 - val_loss: 8.5002e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.5927e-04 - val_loss: 7.4908e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.5575e-04 - val_loss: 7.4067e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.5286e-04 - val_loss: 7.2799e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 177us/step - loss: 1.4859e-04 - val_loss: 7.3435e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 202us/step - loss: 1.4435e-04 - val_loss: 6.5922e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.3971e-04 - val_loss: 6.7954e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.3445e-04 - val_loss: 6.5626e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.3013e-04 - val_loss: 6.0411e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2662e-04 - val_loss: 5.9989e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2519e-04 - val_loss: 5.9596e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2588e-04 - val_loss: 5.9640e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2610e-04 - val_loss: 6.0590e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 199us/step - loss: 1.2380e-04 - val_loss: 5.9622e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2364e-04 - val_loss: 6.3445e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2695e-04 - val_loss: 5.9847e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.2385e-04 - val_loss: 5.9573e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.2369e-04 - val_loss: 6.3685e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 189us/step - loss: 1.2420e-04 - val_loss: 6.1086e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.2409e-04 - val_loss: 5.9506e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2479e-04 - val_loss: 6.0876e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 187us/step - loss: 1.2338e-04 - val_loss: 6.2980e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 27s 16ms/step - loss: 2.2758e-04 - val_loss: 7.8313e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.5988e-04 - val_loss: 7.4146e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.4673e-04 - val_loss: 7.2047e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.4474e-04 - val_loss: 6.6317e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.4129e-04 - val_loss: 6.8009e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 175us/step - loss: 1.3762e-04 - val_loss: 6.6369e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 172us/step - loss: 1.3477e-04 - val_loss: 6.1621e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 173us/step - loss: 1.3003e-04 - val_loss: 6.2294e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2804e-04 - val_loss: 6.1686e-05\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 0s 169us/step - loss: 1.2719e-04 - val_loss: 6.1206e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 176us/step - loss: 1.2521e-04 - val_loss: 6.5105e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.2851e-04 - val_loss: 6.0270e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.2423e-04 - val_loss: 6.0735e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.2584e-04 - val_loss: 5.9507e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 189us/step - loss: 1.2278e-04 - val_loss: 5.9396e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2353e-04 - val_loss: 5.9704e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 175us/step - loss: 1.2280e-04 - val_loss: 5.9529e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2245e-04 - val_loss: 6.1122e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2402e-04 - val_loss: 5.9701e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.2237e-04 - val_loss: 5.9456e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.2214e-04 - val_loss: 6.5642e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.2578e-04 - val_loss: 5.9993e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2390e-04 - val_loss: 5.9465e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.2518e-04 - val_loss: 7.0583e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.2938e-04 - val_loss: 5.9537e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 27s 17ms/step - loss: 3.7912e-04 - val_loss: 1.0432e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.9550e-04 - val_loss: 9.3785e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.7821e-04 - val_loss: 7.6762e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.7338e-04 - val_loss: 8.5993e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.7180e-04 - val_loss: 7.9911e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 182us/step - loss: 1.7011e-04 - val_loss: 8.1394e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.6881e-04 - val_loss: 7.9076e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 182us/step - loss: 1.6767e-04 - val_loss: 7.9703e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.6688e-04 - val_loss: 8.1345e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.6477e-04 - val_loss: 7.7222e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.6283e-04 - val_loss: 7.5665e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.6096e-04 - val_loss: 7.7263e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.5932e-04 - val_loss: 7.3807e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.5720e-04 - val_loss: 7.4149e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.5443e-04 - val_loss: 7.5568e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.5198e-04 - val_loss: 7.1888e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.4958e-04 - val_loss: 7.3791e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.4543e-04 - val_loss: 6.9424e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.4192e-04 - val_loss: 6.5595e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.3899e-04 - val_loss: 6.5141e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.3468e-04 - val_loss: 6.2664e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.3201e-04 - val_loss: 6.1342e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 178us/step - loss: 1.3105e-04 - val_loss: 6.0745e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 181us/step - loss: 1.2713e-04 - val_loss: 6.5008e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 180us/step - loss: 1.2574e-04 - val_loss: 6.4223e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 28s 17ms/step - loss: 3.2523e-04 - val_loss: 1.7983e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.8327e-04 - val_loss: 7.4181e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.6971e-04 - val_loss: 8.9891e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 187us/step - loss: 1.6677e-04 - val_loss: 7.6755e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 189us/step - loss: 1.6321e-04 - val_loss: 8.0761e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.6003e-04 - val_loss: 7.3802e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.5771e-04 - val_loss: 7.4916e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 187us/step - loss: 1.5443e-04 - val_loss: 7.3031e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.5106e-04 - val_loss: 7.6289e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.4745e-04 - val_loss: 6.7656e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 184us/step - loss: 1.4350e-04 - val_loss: 6.6137e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.4050e-04 - val_loss: 6.3313e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.3559e-04 - val_loss: 6.4931e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.3174e-04 - val_loss: 6.4466e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2808e-04 - val_loss: 6.2747e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 200us/step - loss: 1.2638e-04 - val_loss: 6.3066e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.2376e-04 - val_loss: 5.9556e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.2314e-04 - val_loss: 5.9493e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2372e-04 - val_loss: 6.3608e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2302e-04 - val_loss: 5.9592e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.2250e-04 - val_loss: 5.9945e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.2308e-04 - val_loss: 5.9548e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 196us/step - loss: 1.2298e-04 - val_loss: 6.1983e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 194us/step - loss: 1.2445e-04 - val_loss: 6.5200e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.2394e-04 - val_loss: 5.9475e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 29s 18ms/step - loss: 2.7288e-04 - val_loss: 7.4806e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.7243e-04 - val_loss: 9.5934e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 190us/step - loss: 1.6029e-04 - val_loss: 7.0666e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 206us/step - loss: 1.5251e-04 - val_loss: 6.8654e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 191us/step - loss: 1.4777e-04 - val_loss: 7.0855e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.4059e-04 - val_loss: 7.5419e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.3522e-04 - val_loss: 6.8708e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 206us/step - loss: 1.3095e-04 - val_loss: 6.2152e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 189us/step - loss: 1.2631e-04 - val_loss: 5.9357e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.2436e-04 - val_loss: 5.9132e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2376e-04 - val_loss: 5.9179e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 201us/step - loss: 1.2741e-04 - val_loss: 6.8172e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 204us/step - loss: 1.2598e-04 - val_loss: 5.9509e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.2367e-04 - val_loss: 5.9165e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 201us/step - loss: 1.2322e-04 - val_loss: 5.9515e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 191us/step - loss: 1.2255e-04 - val_loss: 6.1118e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.2397e-04 - val_loss: 5.9207e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.2443e-04 - val_loss: 6.0618e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - ETA: 0s - loss: 1.3824e-0 - 0s 188us/step - loss: 1.2481e-04 - val_loss: 5.9188e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2289e-04 - val_loss: 5.9131e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2302e-04 - val_loss: 5.9139e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 191us/step - loss: 1.2433e-04 - val_loss: 6.4098e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.2592e-04 - val_loss: 6.1841e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 200us/step - loss: 1.2689e-04 - val_loss: 5.9477e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.2753e-04 - val_loss: 6.0384e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 30s 18ms/step - loss: 2.4234e-04 - val_loss: 7.1289e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 204us/step - loss: 1.6784e-04 - val_loss: 9.4023e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.5562e-04 - val_loss: 7.7100e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.4842e-04 - val_loss: 6.9489e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.4257e-04 - val_loss: 7.0225e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 210us/step - loss: 1.3574e-04 - val_loss: 6.2681e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.3115e-04 - val_loss: 6.3287e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 219us/step - loss: 1.2559e-04 - val_loss: 6.4965e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2368e-04 - val_loss: 6.7012e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2381e-04 - val_loss: 6.3975e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2390e-04 - val_loss: 6.0238e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2633e-04 - val_loss: 5.9643e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 218us/step - loss: 1.2523e-04 - val_loss: 6.0985e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.2402e-04 - val_loss: 6.1083e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.2838e-04 - val_loss: 6.0085e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 195us/step - loss: 1.2817e-04 - val_loss: 6.8771e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.2360e-04 - val_loss: 5.9909e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.2317e-04 - val_loss: 6.1926e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.2324e-04 - val_loss: 5.9690e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 200us/step - loss: 1.2204e-04 - val_loss: 5.9502e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 202us/step - loss: 1.2242e-04 - val_loss: 5.9607e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2397e-04 - val_loss: 6.0787e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2357e-04 - val_loss: 6.0266e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2250e-04 - val_loss: 5.9458e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 206us/step - loss: 1.2227e-04 - val_loss: 5.9561e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 31s 19ms/step - loss: 3.1873e-04 - val_loss: 1.0031e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.8123e-04 - val_loss: 8.2093e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 197us/step - loss: 1.6245e-04 - val_loss: 7.2414e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.6019e-04 - val_loss: 7.8867e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 179us/step - loss: 1.5894e-04 - val_loss: 7.3901e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 188us/step - loss: 1.5771e-04 - val_loss: 7.5876e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.5629e-04 - val_loss: 7.7279e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 187us/step - loss: 1.5461e-04 - val_loss: 7.2283e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 193us/step - loss: 1.5253e-04 - val_loss: 7.3518e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.5081e-04 - val_loss: 6.8601e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.4811e-04 - val_loss: 7.3878e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 203us/step - loss: 1.4517e-04 - val_loss: 6.8812e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 187us/step - loss: 1.4196e-04 - val_loss: 6.8090e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 186us/step - loss: 1.3874e-04 - val_loss: 6.5900e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.3521e-04 - val_loss: 7.0302e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 192us/step - loss: 1.3209e-04 - val_loss: 6.3884e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.3109e-04 - val_loss: 6.5292e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 201us/step - loss: 1.2648e-04 - val_loss: 6.0477e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.2600e-04 - val_loss: 6.0445e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - ETA: 0s - loss: 1.2515e-0 - 0s 303us/step - loss: 1.2499e-04 - val_loss: 6.0949e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 185us/step - loss: 1.2482e-04 - val_loss: 6.3924e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 183us/step - loss: 1.2440e-04 - val_loss: 6.3730e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 173us/step - loss: 1.2364e-04 - val_loss: 6.1375e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 172us/step - loss: 1.2406e-04 - val_loss: 6.4075e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 170us/step - loss: 1.2398e-04 - val_loss: 6.1219e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 32s 19ms/step - loss: 2.8862e-04 - val_loss: 8.6342e-05\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.6748e-04 - val_loss: 8.2633e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.6079e-04 - val_loss: 6.9935e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 206us/step - loss: 1.5562e-04 - val_loss: 6.9002e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 208us/step - loss: 1.5175e-04 - val_loss: 7.7477e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.4520e-04 - val_loss: 6.8498e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 208us/step - loss: 1.4223e-04 - val_loss: 6.6247e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.3696e-04 - val_loss: 6.9818e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.3388e-04 - val_loss: 6.5759e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 206us/step - loss: 1.3219e-04 - val_loss: 7.4830e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.3117e-04 - val_loss: 6.2728e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.2848e-04 - val_loss: 6.2642e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2631e-04 - val_loss: 6.4171e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 207us/step - loss: 1.2499e-04 - val_loss: 6.1311e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.2448e-04 - val_loss: 6.3322e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 201us/step - loss: 1.2413e-04 - val_loss: 6.2141e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 208us/step - loss: 1.2526e-04 - val_loss: 6.1641e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2584e-04 - val_loss: 6.5543e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2587e-04 - val_loss: 6.4107e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2361e-04 - val_loss: 7.1110e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 225us/step - loss: 1.2572e-04 - val_loss: 6.4627e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2393e-04 - val_loss: 6.2358e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 208us/step - loss: 1.2378e-04 - val_loss: 6.0462e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2368e-04 - val_loss: 6.0379e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 218us/step - loss: 1.2314e-04 - val_loss: 6.1539e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 33s 20ms/step - loss: 2.3491e-04 - val_loss: 7.1848e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 215us/step - loss: 1.5723e-04 - val_loss: 7.8210e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.4559e-04 - val_loss: 6.9816e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 209us/step - loss: 1.4115e-04 - val_loss: 6.5607e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 215us/step - loss: 1.3609e-04 - val_loss: 6.4134e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 209us/step - loss: 1.3406e-04 - val_loss: 6.3004e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 209us/step - loss: 1.2756e-04 - val_loss: 6.0546e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.2684e-04 - val_loss: 6.0810e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.2516e-04 - val_loss: 6.3005e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.2662e-04 - val_loss: 6.8004e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2744e-04 - val_loss: 5.9996e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.2506e-04 - val_loss: 5.9863e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2335e-04 - val_loss: 5.9865e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 218us/step - loss: 1.2434e-04 - val_loss: 5.9976e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.2336e-04 - val_loss: 6.2586e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2285e-04 - val_loss: 6.1073e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 219us/step - loss: 1.2388e-04 - val_loss: 6.0241e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 215us/step - loss: 1.2275e-04 - val_loss: 6.0633e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2517e-04 - val_loss: 5.9659e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2439e-04 - val_loss: 6.0856e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 212us/step - loss: 1.2329e-04 - val_loss: 6.6811e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 215us/step - loss: 1.2661e-04 - val_loss: 5.9633e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 219us/step - loss: 1.2268e-04 - val_loss: 6.2456e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.2367e-04 - val_loss: 5.9573e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2301e-04 - val_loss: 6.0256e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 33s 20ms/step - loss: 2.4773e-04 - val_loss: 7.7692e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.7752e-04 - val_loss: 8.6051e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.5238e-04 - val_loss: 8.0489e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 225us/step - loss: 1.4732e-04 - val_loss: 6.9470e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.4159e-04 - val_loss: 6.7058e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.3548e-04 - val_loss: 6.4855e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.3062e-04 - val_loss: 6.2249e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2667e-04 - val_loss: 6.0247e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2529e-04 - val_loss: 6.0958e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2316e-04 - val_loss: 5.9590e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2438e-04 - val_loss: 6.0114e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2507e-04 - val_loss: 5.9506e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2442e-04 - val_loss: 6.2360e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 228us/step - loss: 1.2300e-04 - val_loss: 6.2099e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.2333e-04 - val_loss: 5.9455e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 227us/step - loss: 1.2205e-04 - val_loss: 6.1250e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2386e-04 - val_loss: 5.9646e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 218us/step - loss: 1.2492e-04 - val_loss: 6.1753e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 221us/step - loss: 1.2403e-04 - val_loss: 6.5296e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 214us/step - loss: 1.2266e-04 - val_loss: 6.0268e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 211us/step - loss: 1.2268e-04 - val_loss: 6.0230e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 221us/step - loss: 1.2218e-04 - val_loss: 6.2170e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 216us/step - loss: 1.2604e-04 - val_loss: 6.2736e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2446e-04 - val_loss: 6.0230e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 220us/step - loss: 1.2333e-04 - val_loss: 6.1532e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 35s 21ms/step - loss: 3.0258e-04 - val_loss: 1.4140e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.6946e-04 - val_loss: 7.1551e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.6300e-04 - val_loss: 7.7503e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 221us/step - loss: 1.5707e-04 - val_loss: 7.6151e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.5356e-04 - val_loss: 6.8993e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.4936e-04 - val_loss: 7.6180e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.4606e-04 - val_loss: 6.7210e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.4086e-04 - val_loss: 6.9321e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 225us/step - loss: 1.3668e-04 - val_loss: 6.7563e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.3399e-04 - val_loss: 6.2877e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 224us/step - loss: 1.3093e-04 - val_loss: 6.0942e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 217us/step - loss: 1.2694e-04 - val_loss: 6.0738e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 224us/step - loss: 1.2628e-04 - val_loss: 6.0225e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 222us/step - loss: 1.2493e-04 - val_loss: 6.0899e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.2431e-04 - val_loss: 6.3165e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.2471e-04 - val_loss: 6.0327e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 221us/step - loss: 1.2590e-04 - val_loss: 6.2448e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.2429e-04 - val_loss: 6.1457e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2483e-04 - val_loss: 6.0192e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.2537e-04 - val_loss: 6.0176e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2504e-04 - val_loss: 6.5827e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.2543e-04 - val_loss: 6.1425e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 224us/step - loss: 1.2487e-04 - val_loss: 6.1652e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2473e-04 - val_loss: 6.1185e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 224us/step - loss: 1.2387e-04 - val_loss: 6.0080e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 35s 21ms/step - loss: 2.5214e-04 - val_loss: 8.2220e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.5951e-04 - val_loss: 8.0351e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.5391e-04 - val_loss: 6.7208e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.4665e-04 - val_loss: 6.8132e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.4205e-04 - val_loss: 7.1511e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 236us/step - loss: 1.3719e-04 - val_loss: 6.5338e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.3269e-04 - val_loss: 6.2415e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.2776e-04 - val_loss: 6.2991e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2694e-04 - val_loss: 6.2965e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2623e-04 - val_loss: 6.1107e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2700e-04 - val_loss: 5.9823e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2441e-04 - val_loss: 6.5095e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2584e-04 - val_loss: 6.9559e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.2529e-04 - val_loss: 6.0350e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2346e-04 - val_loss: 6.4024e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2393e-04 - val_loss: 6.3731e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2531e-04 - val_loss: 6.1479e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 239us/step - loss: 1.2602e-04 - val_loss: 5.9885e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.2628e-04 - val_loss: 6.2042e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2424e-04 - val_loss: 5.9919e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.2370e-04 - val_loss: 6.2226e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2491e-04 - val_loss: 6.2124e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2494e-04 - val_loss: 5.9968e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 228us/step - loss: 1.2454e-04 - val_loss: 6.3389e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2254e-04 - val_loss: 6.0676e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 37s 23ms/step - loss: 2.4001e-04 - val_loss: 7.1020e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.6362e-04 - val_loss: 8.1145e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.4652e-04 - val_loss: 7.9667e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.4357e-04 - val_loss: 6.7807e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.3589e-04 - val_loss: 6.6587e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.3217e-04 - val_loss: 6.7830e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.2724e-04 - val_loss: 6.0087e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.2559e-04 - val_loss: 5.9638e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2330e-04 - val_loss: 5.9607e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2513e-04 - val_loss: 6.0224e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2246e-04 - val_loss: 6.0834e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.2341e-04 - val_loss: 6.1183e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.2559e-04 - val_loss: 5.9622e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 239us/step - loss: 1.2263e-04 - val_loss: 6.0249e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.2312e-04 - val_loss: 6.2246e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2351e-04 - val_loss: 5.9506e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2219e-04 - val_loss: 6.0146e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2337e-04 - val_loss: 6.0177e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2233e-04 - val_loss: 6.1303e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.2241e-04 - val_loss: 6.0758e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2209e-04 - val_loss: 6.0215e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2516e-04 - val_loss: 6.6483e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2229e-04 - val_loss: 5.9708e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 247us/step - loss: 1.2320e-04 - val_loss: 6.0376e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 233us/step - loss: 1.2461e-04 - val_loss: 5.9746e-05\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 36s 22ms/step - loss: 2.1979e-04 - val_loss: 7.3342e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.5374e-04 - val_loss: 6.5893e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 227us/step - loss: 1.3892e-04 - val_loss: 6.6466e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.3281e-04 - val_loss: 6.0970e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.2716e-04 - val_loss: 6.6010e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.2871e-04 - val_loss: 5.9739e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.2935e-04 - val_loss: 6.0085e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.3392e-04 - val_loss: 6.8220e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2646e-04 - val_loss: 6.0978e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.2525e-04 - val_loss: 6.6831e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2420e-04 - val_loss: 6.0031e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.2388e-04 - val_loss: 5.9704e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 228us/step - loss: 1.2329e-04 - val_loss: 5.9688e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 236us/step - loss: 1.2744e-04 - val_loss: 7.3027e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 247us/step - loss: 1.2437e-04 - val_loss: 6.0297e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2227e-04 - val_loss: 6.0844e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 239us/step - loss: 1.2234e-04 - val_loss: 6.0002e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2355e-04 - val_loss: 6.1324e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.2212e-04 - val_loss: 8.0406e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 233us/step - loss: 1.2660e-04 - val_loss: 5.9356e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.2291e-04 - val_loss: 5.9526e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 233us/step - loss: 1.2468e-04 - val_loss: 7.4789e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.3052e-04 - val_loss: 6.6898e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2460e-04 - val_loss: 6.5602e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2248e-04 - val_loss: 6.2141e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 38s 23ms/step - loss: 4.3908e-04 - val_loss: 8.6556e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 285us/step - loss: 1.8014e-04 - val_loss: 1.0168e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 276us/step - loss: 1.7600e-04 - val_loss: 8.6266e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 280us/step - loss: 1.6993e-04 - val_loss: 7.7347e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - ETA: 0s - loss: 1.7442e-0 - 0s 284us/step - loss: 1.6999e-04 - val_loss: 7.9236e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 267us/step - loss: 1.6961e-04 - val_loss: 7.9010e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.6928e-04 - val_loss: 8.1399e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.6916e-04 - val_loss: 7.8594e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 280us/step - loss: 1.6886e-04 - val_loss: 7.9234e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 279us/step - loss: 1.6872e-04 - val_loss: 7.9137e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.6849e-04 - val_loss: 7.8635e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.6834e-04 - val_loss: 7.8797e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.6822e-04 - val_loss: 7.8649e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.6815e-04 - val_loss: 7.9214e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.6807e-04 - val_loss: 7.9550e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.6776e-04 - val_loss: 7.8846e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 269us/step - loss: 1.6774e-04 - val_loss: 7.8913e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.6771e-04 - val_loss: 7.9148e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.6748e-04 - val_loss: 7.8579e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.6764e-04 - val_loss: 8.0125e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.6731e-04 - val_loss: 7.7905e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.6739e-04 - val_loss: 7.8183e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.6730e-04 - val_loss: 7.7012e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 263us/step - loss: 1.6741e-04 - val_loss: 7.8452e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.6718e-04 - val_loss: 7.9297e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 38s 23ms/step - loss: 3.1477e-04 - val_loss: 1.6824e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 241us/step - loss: 1.8550e-04 - val_loss: 7.3272e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.7139e-04 - val_loss: 8.1678e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 278us/step - loss: 1.6638e-04 - val_loss: 7.9130e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - ETA: 0s - loss: 1.6478e-0 - 0s 245us/step - loss: 1.6436e-04 - val_loss: 7.6151e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 305us/step - loss: 1.6184e-04 - val_loss: 7.6822e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.5993e-04 - val_loss: 7.7740e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.5726e-04 - val_loss: 7.2785e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.5477e-04 - val_loss: 7.3777e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.5210e-04 - val_loss: 7.7560e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.4879e-04 - val_loss: 6.8475e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.4549e-04 - val_loss: 6.8416e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.4262e-04 - val_loss: 7.0736e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 227us/step - loss: 1.3845e-04 - val_loss: 6.5516e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.3499e-04 - val_loss: 6.4791e-05\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.3101e-04 - val_loss: 6.2780e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.2903e-04 - val_loss: 6.0101e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2677e-04 - val_loss: 6.3928e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.2580e-04 - val_loss: 6.0485e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 230us/step - loss: 1.2587e-04 - val_loss: 6.0595e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 223us/step - loss: 1.2500e-04 - val_loss: 6.2318e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 227us/step - loss: 1.2508e-04 - val_loss: 6.2103e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 319us/step - loss: 1.2580e-04 - val_loss: 6.0689e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 263us/step - loss: 1.2658e-04 - val_loss: 5.9942e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.2573e-04 - val_loss: 6.0278e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 37s 23ms/step - loss: 3.2093e-04 - val_loss: 1.0788e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.8906e-04 - val_loss: 8.9077e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.7926e-04 - val_loss: 7.4666e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.7371e-04 - val_loss: 8.1637e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.6783e-04 - val_loss: 8.0091e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.6351e-04 - val_loss: 7.3693e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.5877e-04 - val_loss: 7.1903e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.5349e-04 - val_loss: 6.7235e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 241us/step - loss: 1.4815e-04 - val_loss: 6.5015e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.4176e-04 - val_loss: 6.4307e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.3558e-04 - val_loss: 6.5360e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.3058e-04 - val_loss: 7.1837e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2935e-04 - val_loss: 6.6443e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.2553e-04 - val_loss: 5.9441e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.2613e-04 - val_loss: 6.0742e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2500e-04 - val_loss: 6.3594e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2559e-04 - val_loss: 6.7740e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.2532e-04 - val_loss: 5.9240e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.2342e-04 - val_loss: 5.9778e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2479e-04 - val_loss: 6.1998e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.2381e-04 - val_loss: 5.9476e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.2745e-04 - val_loss: 6.2007e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.3147e-04 - val_loss: 5.9138e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.3077e-04 - val_loss: 6.3738e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.2685e-04 - val_loss: 6.0797e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 38s 23ms/step - loss: 2.7683e-04 - val_loss: 7.2455e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.7701e-04 - val_loss: 1.0056e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.6375e-04 - val_loss: 7.1355e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.5823e-04 - val_loss: 7.1956e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.5477e-04 - val_loss: 7.4064e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.4979e-04 - val_loss: 7.3427e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.4515e-04 - val_loss: 6.8084e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.4018e-04 - val_loss: 7.1355e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.3920e-04 - val_loss: 6.3790e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 275us/step - loss: 1.3236e-04 - val_loss: 6.1643e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.2924e-04 - val_loss: 6.1380e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2839e-04 - val_loss: 6.1459e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.2758e-04 - val_loss: 6.1800e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 302us/step - loss: 1.2825e-04 - val_loss: 6.5265e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.2648e-04 - val_loss: 6.1997e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2598e-04 - val_loss: 6.1805e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2567e-04 - val_loss: 6.2133e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2793e-04 - val_loss: 6.4121e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.2655e-04 - val_loss: 6.5711e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.2560e-04 - val_loss: 6.0420e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2472e-04 - val_loss: 6.0178e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.2493e-04 - val_loss: 6.4884e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2904e-04 - val_loss: 6.0084e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.2443e-04 - val_loss: 6.0426e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.2602e-04 - val_loss: 7.0405e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 39s 24ms/step - loss: 3.6525e-04 - val_loss: 1.7720e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.9259e-04 - val_loss: 7.5691e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.7367e-04 - val_loss: 8.4983e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.6689e-04 - val_loss: 7.8773e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.6126e-04 - val_loss: 7.2239e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.5581e-04 - val_loss: 8.5214e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 294us/step - loss: 1.5159e-04 - val_loss: 6.8272e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.4503e-04 - val_loss: 7.2473e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 270us/step - loss: 1.4089e-04 - val_loss: 6.4974e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.3694e-04 - val_loss: 6.5762e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 272us/step - loss: 1.3369e-04 - val_loss: 6.3918e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.3050e-04 - val_loss: 6.5721e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 299us/step - loss: 1.2818e-04 - val_loss: 6.9719e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 270us/step - loss: 1.2775e-04 - val_loss: 6.0736e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.2628e-04 - val_loss: 6.0759e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 279us/step - loss: 1.2826e-04 - val_loss: 6.7638e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 268us/step - loss: 1.2505e-04 - val_loss: 6.3347e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 294us/step - loss: 1.2742e-04 - val_loss: 5.9559e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2610e-04 - val_loss: 5.9377e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 237us/step - loss: 1.2471e-04 - val_loss: 5.9588e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 279us/step - loss: 1.2376e-04 - val_loss: 5.9320e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 304us/step - loss: 1.2353e-04 - val_loss: 6.3611e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 328us/step - loss: 1.2400e-04 - val_loss: 5.9720e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 332us/step - loss: 1.2352e-04 - val_loss: 5.9299e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 353us/step - loss: 1.2353e-04 - val_loss: 6.1956e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 40s 25ms/step - loss: 2.7022e-04 - val_loss: 1.0670e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.6411e-04 - val_loss: 7.2988e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 236us/step - loss: 1.5906e-04 - val_loss: 6.7896e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.5313e-04 - val_loss: 7.6782e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.4790e-04 - val_loss: 6.7026e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.4448e-04 - val_loss: 6.6492e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.4120e-04 - val_loss: 6.4763e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.3659e-04 - val_loss: 6.4148e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.3262e-04 - val_loss: 6.0859e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.2960e-04 - val_loss: 5.9789e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 234us/step - loss: 1.2811e-04 - val_loss: 6.3004e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2618e-04 - val_loss: 5.8985e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.2452e-04 - val_loss: 5.9412e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2435e-04 - val_loss: 6.0811e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2357e-04 - val_loss: 6.1977e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2568e-04 - val_loss: 5.9063e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 270us/step - loss: 1.2389e-04 - val_loss: 6.1580e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 283us/step - loss: 1.2603e-04 - val_loss: 5.8924e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 281us/step - loss: 1.2324e-04 - val_loss: 5.8781e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2442e-04 - val_loss: 5.8801e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 304us/step - loss: 1.2354e-04 - val_loss: 5.9156e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2548e-04 - val_loss: 6.2777e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 275us/step - loss: 1.2648e-04 - val_loss: 5.9320e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.2324e-04 - val_loss: 5.8933e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 261us/step - loss: 1.2376e-04 - val_loss: 6.0492e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 40s 24ms/step - loss: 2.0695e-04 - val_loss: 7.4407e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.4869e-04 - val_loss: 6.3010e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.3714e-04 - val_loss: 6.9340e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.3392e-04 - val_loss: 7.3659e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.3155e-04 - val_loss: 6.8683e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.3036e-04 - val_loss: 6.1714e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2612e-04 - val_loss: 5.9740e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2661e-04 - val_loss: 6.1245e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2495e-04 - val_loss: 6.3410e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 239us/step - loss: 1.2433e-04 - val_loss: 5.9300e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2587e-04 - val_loss: 6.2281e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 226us/step - loss: 1.2601e-04 - val_loss: 5.8836e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2413e-04 - val_loss: 5.9420e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 236us/step - loss: 1.2387e-04 - val_loss: 6.3743e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2789e-04 - val_loss: 6.0024e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2776e-04 - val_loss: 6.4179e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.2487e-04 - val_loss: 5.8717e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 240us/step - loss: 1.2354e-04 - val_loss: 5.9721e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2654e-04 - val_loss: 6.1271e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 233us/step - loss: 1.2421e-04 - val_loss: 5.9256e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 233us/step - loss: 1.2829e-04 - val_loss: 5.9142e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 229us/step - loss: 1.2707e-04 - val_loss: 6.0428e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 232us/step - loss: 1.2486e-04 - val_loss: 6.2254e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 231us/step - loss: 1.2527e-04 - val_loss: 5.9107e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2378e-04 - val_loss: 5.9558e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 42s 25ms/step - loss: 2.7216e-04 - val_loss: 7.7145e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.7454e-04 - val_loss: 9.1165e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.5871e-04 - val_loss: 8.3579e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.5571e-04 - val_loss: 7.5270e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.4646e-04 - val_loss: 6.9013e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.4067e-04 - val_loss: 7.0361e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.3650e-04 - val_loss: 6.9853e-05\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.2996e-04 - val_loss: 6.0056e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2818e-04 - val_loss: 5.9914e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.2608e-04 - val_loss: 6.0276e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2636e-04 - val_loss: 6.0735e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2597e-04 - val_loss: 7.0257e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2661e-04 - val_loss: 6.4488e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2600e-04 - val_loss: 5.9585e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2714e-04 - val_loss: 6.5430e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2471e-04 - val_loss: 5.9354e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2408e-04 - val_loss: 5.9205e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.2417e-04 - val_loss: 6.0981e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2530e-04 - val_loss: 5.9020e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2443e-04 - val_loss: 6.1129e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2388e-04 - val_loss: 6.3638e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.2484e-04 - val_loss: 5.9017e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.2504e-04 - val_loss: 6.2059e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2651e-04 - val_loss: 6.2490e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2693e-04 - val_loss: 6.6448e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 43s 26ms/step - loss: 2.6448e-04 - val_loss: 1.3849e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.6425e-04 - val_loss: 6.7541e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.5438e-04 - val_loss: 8.0257e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.5081e-04 - val_loss: 6.9236e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 270us/step - loss: 1.4858e-04 - val_loss: 6.9099e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.4616e-04 - val_loss: 6.6466e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.4399e-04 - val_loss: 6.5893e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.4118e-04 - val_loss: 6.6293e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.3810e-04 - val_loss: 6.5350e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.3504e-04 - val_loss: 6.6790e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.3282e-04 - val_loss: 6.4316e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2948e-04 - val_loss: 5.9672e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 239us/step - loss: 1.2723e-04 - val_loss: 5.9439e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2617e-04 - val_loss: 5.9786e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2513e-04 - val_loss: 5.8858e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 247us/step - loss: 1.2474e-04 - val_loss: 6.2383e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.2403e-04 - val_loss: 5.9004e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 351us/step - loss: 1.2532e-04 - val_loss: 6.2015e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 310us/step - loss: 1.2345e-04 - val_loss: 6.9329e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 299us/step - loss: 1.2515e-04 - val_loss: 6.1916e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.2390e-04 - val_loss: 5.9218e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2475e-04 - val_loss: 6.1556e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2366e-04 - val_loss: 6.0150e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2383e-04 - val_loss: 6.0286e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.2499e-04 - val_loss: 5.9824e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 44s 27ms/step - loss: 2.3474e-04 - val_loss: 6.7671e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.5932e-04 - val_loss: 9.6512e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 264us/step - loss: 1.4556e-04 - val_loss: 6.7901e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 277us/step - loss: 1.4265e-04 - val_loss: 6.4202e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.3755e-04 - val_loss: 6.1991e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.3272e-04 - val_loss: 6.2445e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2907e-04 - val_loss: 6.0800e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.2751e-04 - val_loss: 6.0394e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 269us/step - loss: 1.2560e-04 - val_loss: 5.9513e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 261us/step - loss: 1.2464e-04 - val_loss: 6.2239e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2547e-04 - val_loss: 5.9093e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2500e-04 - val_loss: 5.9057e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.2380e-04 - val_loss: 6.1752e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2341e-04 - val_loss: 6.2692e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 276us/step - loss: 1.2439e-04 - val_loss: 5.8980e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2363e-04 - val_loss: 5.8892e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.2513e-04 - val_loss: 7.3530e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 244us/step - loss: 1.2499e-04 - val_loss: 6.2664e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2355e-04 - val_loss: 5.8770e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.2494e-04 - val_loss: 6.2373e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2417e-04 - val_loss: 5.8549e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 297us/step - loss: 1.2379e-04 - val_loss: 5.9501e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.2418e-04 - val_loss: 6.1469e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 263us/step - loss: 1.2490e-04 - val_loss: 5.9119e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 293us/step - loss: 1.2433e-04 - val_loss: 6.7034e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 45s 27ms/step - loss: 2.5627e-04 - val_loss: 7.0165e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.6260e-04 - val_loss: 9.3693e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.5535e-04 - val_loss: 7.9996e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.4813e-04 - val_loss: 7.2179e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.4098e-04 - val_loss: 6.8542e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.3520e-04 - val_loss: 7.1442e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.3034e-04 - val_loss: 7.0207e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.3049e-04 - val_loss: 6.0900e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2640e-04 - val_loss: 5.9940e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 305us/step - loss: 1.2470e-04 - val_loss: 6.0400e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 274us/step - loss: 1.2831e-04 - val_loss: 6.2112e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2612e-04 - val_loss: 6.0400e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2587e-04 - val_loss: 6.3424e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2775e-04 - val_loss: 6.1062e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2499e-04 - val_loss: 6.1173e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2934e-04 - val_loss: 5.9422e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.2613e-04 - val_loss: 6.0502e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.2452e-04 - val_loss: 5.9826e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 263us/step - loss: 1.2407e-04 - val_loss: 6.2677e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2381e-04 - val_loss: 5.9277e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2284e-04 - val_loss: 5.8950e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 263us/step - loss: 1.2350e-04 - val_loss: 6.4419e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 260us/step - loss: 1.2427e-04 - val_loss: 6.0445e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.2497e-04 - val_loss: 5.9043e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 272us/step - loss: 1.2303e-04 - val_loss: 5.8825e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 44s 27ms/step - loss: 2.6946e-04 - val_loss: 7.2743e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 268us/step - loss: 1.7581e-04 - val_loss: 1.0464e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.6085e-04 - val_loss: 7.4333e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.5218e-04 - val_loss: 6.7215e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.4561e-04 - val_loss: 7.1876e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 259us/step - loss: 1.3907e-04 - val_loss: 7.6668e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 262us/step - loss: 1.3366e-04 - val_loss: 6.1242e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.2770e-04 - val_loss: 6.1595e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 246us/step - loss: 1.2658e-04 - val_loss: 5.9694e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.2528e-04 - val_loss: 6.0024e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 288us/step - loss: 1.2440e-04 - val_loss: 5.9351e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 309us/step - loss: 1.2500e-04 - val_loss: 5.9223e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2397e-04 - val_loss: 6.0785e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 271us/step - loss: 1.2608e-04 - val_loss: 5.9825e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.2617e-04 - val_loss: 6.5561e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 250us/step - loss: 1.2665e-04 - val_loss: 6.2218e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.2616e-04 - val_loss: 6.0550e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 279us/step - loss: 1.2426e-04 - val_loss: 5.9025e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 293us/step - loss: 1.2651e-04 - val_loss: 6.0127e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 270us/step - loss: 1.2356e-04 - val_loss: 6.0753e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2369e-04 - val_loss: 5.9975e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.2321e-04 - val_loss: 5.9193e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2531e-04 - val_loss: 5.8656e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.2412e-04 - val_loss: 5.8942e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2288e-04 - val_loss: 5.8919e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 45s 28ms/step - loss: 3.3269e-04 - val_loss: 1.0622e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.8287e-04 - val_loss: 7.8003e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.6653e-04 - val_loss: 7.3066e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.6269e-04 - val_loss: 7.9117e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 0s 251us/step - loss: 1.6124e-04 - val_loss: 7.5872e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.5952e-04 - val_loss: 7.4670e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 252us/step - loss: 1.5810e-04 - val_loss: 7.4875e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.5608e-04 - val_loss: 7.1294e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.5382e-04 - val_loss: 7.6062e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.5175e-04 - val_loss: 7.2107e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.4807e-04 - val_loss: 6.7766e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.4538e-04 - val_loss: 6.4679e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 253us/step - loss: 1.4122e-04 - val_loss: 6.3607e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.3734e-04 - val_loss: 6.2975e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.3255e-04 - val_loss: 6.1192e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2844e-04 - val_loss: 6.0592e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2636e-04 - val_loss: 6.7485e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 254us/step - loss: 1.2687e-04 - val_loss: 5.9453e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2564e-04 - val_loss: 5.9895e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2669e-04 - val_loss: 5.9481e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2717e-04 - val_loss: 6.7658e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2714e-04 - val_loss: 6.1037e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2626e-04 - val_loss: 5.9413e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 258us/step - loss: 1.2511e-04 - val_loss: 5.9850e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 255us/step - loss: 1.2493e-04 - val_loss: 5.9234e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 49s 30ms/step - loss: 2.6601e-04 - val_loss: 8.2908e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 308us/step - loss: 1.6183e-04 - val_loss: 6.9723e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 306us/step - loss: 1.4668e-04 - val_loss: 8.1521e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 0s 303us/step - loss: 1.4198e-04 - val_loss: 7.6602e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 317us/step - loss: 1.3356e-04 - val_loss: 6.3657e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 325us/step - loss: 1.2878e-04 - val_loss: 5.9554e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 285us/step - loss: 1.2693e-04 - val_loss: 6.3901e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 0s 287us/step - loss: 1.2550e-04 - val_loss: 6.7712e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 282us/step - loss: 1.2447e-04 - val_loss: 6.0191e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 296us/step - loss: 1.2462e-04 - val_loss: 5.9580e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 300us/step - loss: 1.2442e-04 - val_loss: 5.9316e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 295us/step - loss: 1.2374e-04 - val_loss: 5.9258e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 307us/step - loss: 1.2435e-04 - val_loss: 5.9081e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 326us/step - loss: 1.2402e-04 - val_loss: 5.9421e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 302us/step - loss: 1.2379e-04 - val_loss: 6.2584e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 294us/step - loss: 1.2479e-04 - val_loss: 5.9392e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 302us/step - loss: 1.2392e-04 - val_loss: 5.8877e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 298us/step - loss: 1.2375e-04 - val_loss: 5.9576e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 298us/step - loss: 1.2574e-04 - val_loss: 5.9360e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 297us/step - loss: 1.2841e-04 - val_loss: 6.0882e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.2822e-04 - val_loss: 6.7350e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 287us/step - loss: 1.2434e-04 - val_loss: 5.9242e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 302us/step - loss: 1.2464e-04 - val_loss: 5.9313e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 297us/step - loss: 1.2539e-04 - val_loss: 6.2920e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 0s 295us/step - loss: 1.2453e-04 - val_loss: 5.8556e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 49s 30ms/step - loss: 2.8098e-04 - val_loss: 9.5194e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 0s 249us/step - loss: 1.8162e-04 - val_loss: 6.9973e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 0s 241us/step - loss: 1.5801e-04 - val_loss: 6.8367e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 320us/step - loss: 1.4668e-04 - val_loss: 6.3874e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 319us/step - loss: 1.3477e-04 - val_loss: 6.0559e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 314us/step - loss: 1.2833e-04 - val_loss: 6.0486e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.2516e-04 - val_loss: 5.9238e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 318us/step - loss: 1.2820e-04 - val_loss: 6.1772e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 297us/step - loss: 1.2850e-04 - val_loss: 6.1675e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 235us/step - loss: 1.2502e-04 - val_loss: 6.0215e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 242us/step - loss: 1.2436e-04 - val_loss: 5.9398e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 245us/step - loss: 1.2451e-04 - val_loss: 5.8973e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 0s 248us/step - loss: 1.2570e-04 - val_loss: 5.8652e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 243us/step - loss: 1.2487e-04 - val_loss: 5.9020e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2587e-04 - val_loss: 6.5677e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 238us/step - loss: 1.2851e-04 - val_loss: 6.8182e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 276us/step - loss: 1.2760e-04 - val_loss: 6.2474e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 273us/step - loss: 1.2443e-04 - val_loss: 6.2236e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2360e-04 - val_loss: 5.8663e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 265us/step - loss: 1.2350e-04 - val_loss: 5.8426e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 267us/step - loss: 1.2378e-04 - val_loss: 7.2135e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 256us/step - loss: 1.2620e-04 - val_loss: 5.8642e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 257us/step - loss: 1.2396e-04 - val_loss: 6.8344e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 266us/step - loss: 1.2484e-04 - val_loss: 5.8226e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 327us/step - loss: 1.2284e-04 - val_loss: 6.3258e-05\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 49s 30ms/step - loss: 2.7604e-04 - val_loss: 8.0778e-05\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 330us/step - loss: 1.6031e-04 - val_loss: 6.6472e-05\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 320us/step - loss: 1.4801e-04 - val_loss: 6.4279e-05\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 335us/step - loss: 1.3832e-04 - val_loss: 6.1658e-05\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 479us/step - loss: 1.3094e-04 - val_loss: 6.0481e-05\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 374us/step - loss: 1.2732e-04 - val_loss: 6.6614e-05\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 335us/step - loss: 1.2544e-04 - val_loss: 6.1245e-05\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 335us/step - loss: 1.2439e-04 - val_loss: 5.9906e-05\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 0s 298us/step - loss: 1.2742e-04 - val_loss: 5.9416e-05\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 0s 302us/step - loss: 1.2485e-04 - val_loss: 6.6058e-05\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 0s 298us/step - loss: 1.2438e-04 - val_loss: 5.9304e-05\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 0s 291us/step - loss: 1.2516e-04 - val_loss: 6.9331e-05\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 307us/step - loss: 1.2380e-04 - val_loss: 6.1767e-05\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 0s 297us/step - loss: 1.2330e-04 - val_loss: 5.9494e-05\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 304us/step - loss: 1.2367e-04 - val_loss: 5.8802e-05\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 0s 287us/step - loss: 1.2421e-04 - val_loss: 5.8666e-05\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 0s 287us/step - loss: 1.2486e-04 - val_loss: 6.0191e-05\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 0s 285us/step - loss: 1.2449e-04 - val_loss: 8.1500e-05\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 0s 289us/step - loss: 1.2629e-04 - val_loss: 5.8643e-05\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 0s 285us/step - loss: 1.2479e-04 - val_loss: 6.3505e-05\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 0s 286us/step - loss: 1.2318e-04 - val_loss: 6.0259e-05\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 0s 286us/step - loss: 1.2303e-04 - val_loss: 5.9664e-05\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 0s 285us/step - loss: 1.2357e-04 - val_loss: 5.9631e-05\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 0s 290us/step - loss: 1.2357e-04 - val_loss: 6.2554e-05\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 307us/step - loss: 1.2286e-04 - val_loss: 6.2689e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 52s 32ms/step - loss: 3.5480e-04 - val_loss: 7.8157e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 452us/step - loss: 1.7483e-04 - val_loss: 9.4319e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 417us/step - loss: 1.6517e-04 - val_loss: 7.2434e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 407us/step - loss: 1.6333e-04 - val_loss: 7.9953e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 413us/step - loss: 1.6202e-04 - val_loss: 7.5433e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 400us/step - loss: 1.6123e-04 - val_loss: 7.5122e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 414us/step - loss: 1.6007e-04 - val_loss: 7.6599e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 391us/step - loss: 1.5912e-04 - val_loss: 7.3708e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 404us/step - loss: 1.5780e-04 - val_loss: 7.6642e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 398us/step - loss: 1.5653e-04 - val_loss: 7.2172e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 432us/step - loss: 1.5440e-04 - val_loss: 7.4863e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 398us/step - loss: 1.5268e-04 - val_loss: 7.2431e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 377us/step - loss: 1.5024e-04 - val_loss: 7.1818e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.4746e-04 - val_loss: 7.0609e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 469us/step - loss: 1.4428e-04 - val_loss: 6.7360e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 393us/step - loss: 1.4057e-04 - val_loss: 6.6330e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 364us/step - loss: 1.3655e-04 - val_loss: 6.8678e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 360us/step - loss: 1.3313e-04 - val_loss: 6.0771e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 382us/step - loss: 1.3069e-04 - val_loss: 6.0590e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 382us/step - loss: 1.2864e-04 - val_loss: 6.0706e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 371us/step - loss: 1.2782e-04 - val_loss: 6.0327e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 365us/step - loss: 1.2715e-04 - val_loss: 6.0847e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 365us/step - loss: 1.2755e-04 - val_loss: 6.1199e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 434us/step - loss: 1.2877e-04 - val_loss: 6.1101e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 412us/step - loss: 1.2684e-04 - val_loss: 6.0889e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 53s 32ms/step - loss: 1.9230e-04 - val_loss: 6.5852e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 501us/step - loss: 1.4685e-04 - val_loss: 6.8207e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.3789e-04 - val_loss: 6.4639e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 468us/step - loss: 1.3523e-04 - val_loss: 6.3786e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 426us/step - loss: 1.3164e-04 - val_loss: 6.0746e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 423us/step - loss: 1.2919e-04 - val_loss: 6.1621e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 416us/step - loss: 1.2779e-04 - val_loss: 5.9485e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 406us/step - loss: 1.2647e-04 - val_loss: 5.9672e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 428us/step - loss: 1.2543e-04 - val_loss: 6.0385e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 448us/step - loss: 1.2626e-04 - val_loss: 7.3774e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 536us/step - loss: 1.2772e-04 - val_loss: 6.2185e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 492us/step - loss: 1.2599e-04 - val_loss: 6.7618e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 449us/step - loss: 1.2782e-04 - val_loss: 6.1814e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 436us/step - loss: 1.2801e-04 - val_loss: 5.8755e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 433us/step - loss: 1.2531e-04 - val_loss: 5.8743e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.2465e-04 - val_loss: 6.3412e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 428us/step - loss: 1.2789e-04 - val_loss: 5.9349e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 437us/step - loss: 1.2623e-04 - val_loss: 5.9802e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.2468e-04 - val_loss: 5.8948e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 459us/step - loss: 1.2460e-04 - val_loss: 5.8701e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 449us/step - loss: 1.2499e-04 - val_loss: 6.3998e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 462us/step - loss: 1.2696e-04 - val_loss: 5.8873e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 512us/step - loss: 1.2428e-04 - val_loss: 5.8613e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.2399e-04 - val_loss: 5.8689e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2520e-04 - val_loss: 6.5493e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 53s 32ms/step - loss: 2.3955e-04 - val_loss: 8.2444e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 420us/step - loss: 1.6623e-04 - val_loss: 7.2276e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 402us/step - loss: 1.5098e-04 - val_loss: 7.1691e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 448us/step - loss: 1.4422e-04 - val_loss: 8.0293e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 447us/step - loss: 1.3918e-04 - val_loss: 7.2393e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 442us/step - loss: 1.3420e-04 - val_loss: 6.3005e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 446us/step - loss: 1.3038e-04 - val_loss: 5.9032e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 413us/step - loss: 1.2784e-04 - val_loss: 6.0806e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 418us/step - loss: 1.2698e-04 - val_loss: 5.8373e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 423us/step - loss: 1.2636e-04 - val_loss: 8.8127e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 426us/step - loss: 1.2973e-04 - val_loss: 6.0871e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 424us/step - loss: 1.3008e-04 - val_loss: 6.0929e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 420us/step - loss: 1.2555e-04 - val_loss: 6.1148e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 417us/step - loss: 1.2717e-04 - val_loss: 5.8778e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 431us/step - loss: 1.2678e-04 - val_loss: 5.9287e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 431us/step - loss: 1.2511e-04 - val_loss: 5.7891e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 446us/step - loss: 1.2518e-04 - val_loss: 5.8196e-05\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 1s 409us/step - loss: 1.2440e-04 - val_loss: 6.0118e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 414us/step - loss: 1.2533e-04 - val_loss: 6.1123e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2774e-04 - val_loss: 5.7838e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2476e-04 - val_loss: 5.8084e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 422us/step - loss: 1.2616e-04 - val_loss: 7.2656e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 431us/step - loss: 1.2862e-04 - val_loss: 5.9181e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 428us/step - loss: 1.2453e-04 - val_loss: 6.6694e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 444us/step - loss: 1.2574e-04 - val_loss: 5.8457e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 53s 32ms/step - loss: 2.2919e-04 - val_loss: 8.1934e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 427us/step - loss: 1.6180e-04 - val_loss: 6.7856e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.4918e-04 - val_loss: 6.3260e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 440us/step - loss: 1.4438e-04 - val_loss: 6.3552e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 459us/step - loss: 1.3688e-04 - val_loss: 6.0147e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 461us/step - loss: 1.3082e-04 - val_loss: 5.8971e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 438us/step - loss: 1.2796e-04 - val_loss: 5.8937e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 440us/step - loss: 1.2609e-04 - val_loss: 5.8805e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 465us/step - loss: 1.2551e-04 - val_loss: 5.8276e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 454us/step - loss: 1.2559e-04 - val_loss: 6.0253e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 446us/step - loss: 1.2578e-04 - val_loss: 5.8011e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 446us/step - loss: 1.2526e-04 - val_loss: 5.8974e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 469us/step - loss: 1.2591e-04 - val_loss: 5.8106e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 431us/step - loss: 1.2573e-04 - val_loss: 6.0109e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2701e-04 - val_loss: 6.1221e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 427us/step - loss: 1.2920e-04 - val_loss: 5.8121e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.2617e-04 - val_loss: 6.1606e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 487us/step - loss: 1.2547e-04 - val_loss: 5.8179e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 512us/step - loss: 1.2493e-04 - val_loss: 5.8022e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 484us/step - loss: 1.2408e-04 - val_loss: 5.9092e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 451us/step - loss: 1.2639e-04 - val_loss: 5.8165e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.2447e-04 - val_loss: 6.0288e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 462us/step - loss: 1.2522e-04 - val_loss: 5.8573e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 457us/step - loss: 1.2581e-04 - val_loss: 5.8641e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.2442e-04 - val_loss: 5.9792e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 55s 34ms/step - loss: 3.3679e-04 - val_loss: 8.0644e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 398us/step - loss: 1.7613e-04 - val_loss: 8.8656e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 418us/step - loss: 1.6065e-04 - val_loss: 7.0661e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.5853e-04 - val_loss: 7.8001e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 414us/step - loss: 1.5687e-04 - val_loss: 7.3401e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 411us/step - loss: 1.5497e-04 - val_loss: 7.4868e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 387us/step - loss: 1.5315e-04 - val_loss: 7.2524e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 391us/step - loss: 1.5106e-04 - val_loss: 6.8217e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 386us/step - loss: 1.4734e-04 - val_loss: 7.1897e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 390us/step - loss: 1.4333e-04 - val_loss: 7.0116e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 401us/step - loss: 1.3834e-04 - val_loss: 6.1947e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 403us/step - loss: 1.3268e-04 - val_loss: 6.4380e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 392us/step - loss: 1.2903e-04 - val_loss: 6.1090e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.2703e-04 - val_loss: 5.9796e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 447us/step - loss: 1.2679e-04 - val_loss: 6.1986e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 439us/step - loss: 1.2716e-04 - val_loss: 6.0215e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 416us/step - loss: 1.2684e-04 - val_loss: 5.9014e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.2617e-04 - val_loss: 5.8599e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 436us/step - loss: 1.2716e-04 - val_loss: 5.9411e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 445us/step - loss: 1.2813e-04 - val_loss: 5.9980e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 399us/step - loss: 1.2933e-04 - val_loss: 6.1060e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 406us/step - loss: 1.2754e-04 - val_loss: 5.8583e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 411us/step - loss: 1.2564e-04 - val_loss: 6.0080e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2899e-04 - val_loss: 5.9925e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 419us/step - loss: 1.2762e-04 - val_loss: 5.8611e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 56s 34ms/step - loss: 2.6175e-04 - val_loss: 6.9268e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 424us/step - loss: 1.6927e-04 - val_loss: 9.3305e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 425us/step - loss: 1.5537e-04 - val_loss: 7.3419e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 422us/step - loss: 1.4817e-04 - val_loss: 7.0415e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 429us/step - loss: 1.4444e-04 - val_loss: 6.4332e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.4015e-04 - val_loss: 6.4646e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 422us/step - loss: 1.3752e-04 - val_loss: 6.8403e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.3284e-04 - val_loss: 6.2116e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2941e-04 - val_loss: 5.9751e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 424us/step - loss: 1.2814e-04 - val_loss: 6.0341e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2599e-04 - val_loss: 5.8566e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 428us/step - loss: 1.2682e-04 - val_loss: 5.8927e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 418us/step - loss: 1.2794e-04 - val_loss: 5.9710e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 424us/step - loss: 1.2686e-04 - val_loss: 5.8625e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 420us/step - loss: 1.2601e-04 - val_loss: 5.8681e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 420us/step - loss: 1.2557e-04 - val_loss: 5.8918e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 423us/step - loss: 1.2565e-04 - val_loss: 6.1773e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 412us/step - loss: 1.2773e-04 - val_loss: 5.8896e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 412us/step - loss: 1.2823e-04 - val_loss: 6.0225e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 412us/step - loss: 1.2545e-04 - val_loss: 6.4303e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 415us/step - loss: 1.2456e-04 - val_loss: 5.8399e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 418us/step - loss: 1.2551e-04 - val_loss: 5.8691e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 415us/step - loss: 1.2641e-04 - val_loss: 6.0320e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 437us/step - loss: 1.2488e-04 - val_loss: 5.8857e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.2473e-04 - val_loss: 5.9866e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 56s 34ms/step - loss: 2.5190e-04 - val_loss: 7.5559e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 403us/step - loss: 1.6808e-04 - val_loss: 8.2319e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 404us/step - loss: 1.5191e-04 - val_loss: 7.3585e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 416us/step - loss: 1.4617e-04 - val_loss: 8.2620e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.4181e-04 - val_loss: 6.6432e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 434us/step - loss: 1.3317e-04 - val_loss: 6.4361e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 494us/step - loss: 1.3027e-04 - val_loss: 5.9461e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 473us/step - loss: 1.2696e-04 - val_loss: 6.3555e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 462us/step - loss: 1.2551e-04 - val_loss: 6.3679e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 434us/step - loss: 1.2724e-04 - val_loss: 6.1955e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 437us/step - loss: 1.2580e-04 - val_loss: 5.9200e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 450us/step - loss: 1.2687e-04 - val_loss: 6.3728e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 534us/step - loss: 1.2752e-04 - val_loss: 6.3676e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 525us/step - loss: 1.2695e-04 - val_loss: 5.8742e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 558us/step - loss: 1.2586e-04 - val_loss: 5.8948e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 506us/step - loss: 1.2481e-04 - val_loss: 5.9399e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 490us/step - loss: 1.2515e-04 - val_loss: 5.9465e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 527us/step - loss: 1.2484e-04 - val_loss: 6.2084e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 460us/step - loss: 1.2521e-04 - val_loss: 6.2203e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 445us/step - loss: 1.2565e-04 - val_loss: 5.9401e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 443us/step - loss: 1.2665e-04 - val_loss: 6.0298e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 467us/step - loss: 1.2428e-04 - val_loss: 5.9978e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 482us/step - loss: 1.2493e-04 - val_loss: 5.9195e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 433us/step - loss: 1.2527e-04 - val_loss: 6.0661e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 388us/step - loss: 1.2506e-04 - val_loss: 5.9730e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 60s 36ms/step - loss: 2.1921e-04 - val_loss: 6.4765e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 439us/step - loss: 1.5128e-04 - val_loss: 6.4852e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 442us/step - loss: 1.4020e-04 - val_loss: 6.1610e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 468us/step - loss: 1.3321e-04 - val_loss: 6.6816e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 446us/step - loss: 1.3296e-04 - val_loss: 6.1947e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 445us/step - loss: 1.2887e-04 - val_loss: 5.8574e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 444us/step - loss: 1.2816e-04 - val_loss: 5.8350e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 427us/step - loss: 1.2643e-04 - val_loss: 6.2834e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 436us/step - loss: 1.2833e-04 - val_loss: 5.8719e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 442us/step - loss: 1.2543e-04 - val_loss: 6.0840e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 462us/step - loss: 1.2589e-04 - val_loss: 6.5526e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 477us/step - loss: 1.3353e-04 - val_loss: 5.8325e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 464us/step - loss: 1.2939e-04 - val_loss: 5.8370e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 546us/step - loss: 1.3224e-04 - val_loss: 6.5674e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 448us/step - loss: 1.3376e-04 - val_loss: 5.9988e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 606us/step - loss: 1.2655e-04 - val_loss: 6.3335e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 474us/step - loss: 1.2623e-04 - val_loss: 5.9235e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 468us/step - loss: 1.2499e-04 - val_loss: 5.8226e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 454us/step - loss: 1.2589e-04 - val_loss: 6.3726e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 484us/step - loss: 1.2685e-04 - val_loss: 5.8490e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 511us/step - loss: 1.2806e-04 - val_loss: 5.8052e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 443us/step - loss: 1.2548e-04 - val_loss: 5.8559e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 445us/step - loss: 1.2496e-04 - val_loss: 6.0776e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 459us/step - loss: 1.2647e-04 - val_loss: 6.0396e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 434us/step - loss: 1.2498e-04 - val_loss: 5.9465e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 61s 37ms/step - loss: 3.6988e-04 - val_loss: 1.2902e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.9013e-04 - val_loss: 7.9917e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 436us/step - loss: 1.7375e-04 - val_loss: 7.9567e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 417us/step - loss: 1.6771e-04 - val_loss: 7.6055e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 405us/step - loss: 1.6123e-04 - val_loss: 7.8912e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 420us/step - loss: 1.5619e-04 - val_loss: 6.9310e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 417us/step - loss: 1.5025e-04 - val_loss: 6.8698e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 448us/step - loss: 1.4406e-04 - val_loss: 7.5848e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 421us/step - loss: 1.4112e-04 - val_loss: 6.2926e-05\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.3597e-04 - val_loss: 6.1912e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 435us/step - loss: 1.3208e-04 - val_loss: 6.3063e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 443us/step - loss: 1.3019e-04 - val_loss: 6.2747e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 453us/step - loss: 1.2884e-04 - val_loss: 6.5984e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 482us/step - loss: 1.2676e-04 - val_loss: 6.1259e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 526us/step - loss: 1.2683e-04 - val_loss: 6.1003e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 465us/step - loss: 1.2799e-04 - val_loss: 5.9302e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 423us/step - loss: 1.3100e-04 - val_loss: 6.1196e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 403us/step - loss: 1.2887e-04 - val_loss: 6.3849e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 398us/step - loss: 1.2708e-04 - val_loss: 6.0168e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 404us/step - loss: 1.2678e-04 - val_loss: 6.0668e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 401us/step - loss: 1.2774e-04 - val_loss: 5.9814e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 401us/step - loss: 1.2773e-04 - val_loss: 5.8876e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 399us/step - loss: 1.2661e-04 - val_loss: 5.8887e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 400us/step - loss: 1.2631e-04 - val_loss: 6.1560e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 468us/step - loss: 1.2727e-04 - val_loss: 6.1062e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 60s 36ms/step - loss: 3.5382e-04 - val_loss: 1.5767e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.8470e-04 - val_loss: 7.3076e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 449us/step - loss: 1.6757e-04 - val_loss: 8.0664e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 471us/step - loss: 1.6147e-04 - val_loss: 7.4763e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 451us/step - loss: 1.5698e-04 - val_loss: 7.3075e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.5126e-04 - val_loss: 7.5731e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 460us/step - loss: 1.4768e-04 - val_loss: 6.6754e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 506us/step - loss: 1.3975e-04 - val_loss: 6.2105e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 472us/step - loss: 1.3293e-04 - val_loss: 6.0348e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 454us/step - loss: 1.2937e-04 - val_loss: 5.9146e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 459us/step - loss: 1.2869e-04 - val_loss: 5.9443e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 500us/step - loss: 1.3074e-04 - val_loss: 7.1831e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 507us/step - loss: 1.2946e-04 - val_loss: 6.0225e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 538us/step - loss: 1.2823e-04 - val_loss: 5.9024e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 529us/step - loss: 1.2803e-04 - val_loss: 5.8871e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 481us/step - loss: 1.2797e-04 - val_loss: 5.9016e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 501us/step - loss: 1.2734e-04 - val_loss: 5.8851e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 482us/step - loss: 1.2759e-04 - val_loss: 5.9935e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 481us/step - loss: 1.2770e-04 - val_loss: 5.8691e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 523us/step - loss: 1.2668e-04 - val_loss: 6.2415e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 481us/step - loss: 1.2745e-04 - val_loss: 5.8882e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 472us/step - loss: 1.2747e-04 - val_loss: 5.9465e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 476us/step - loss: 1.2694e-04 - val_loss: 6.1192e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 472us/step - loss: 1.2686e-04 - val_loss: 5.8687e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 470us/step - loss: 1.2609e-04 - val_loss: 5.9346e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 61s 37ms/step - loss: 2.6711e-04 - val_loss: 7.9446e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 469us/step - loss: 1.7163e-04 - val_loss: 8.1116e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 476us/step - loss: 1.5456e-04 - val_loss: 7.8696e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 484us/step - loss: 1.4891e-04 - val_loss: 7.3518e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 460us/step - loss: 1.4067e-04 - val_loss: 6.5780e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 460us/step - loss: 1.3277e-04 - val_loss: 5.9383e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 442us/step - loss: 1.3154e-04 - val_loss: 7.0849e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 496us/step - loss: 1.3136e-04 - val_loss: 5.8640e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 466us/step - loss: 1.2923e-04 - val_loss: 5.8693e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 503us/step - loss: 1.2724e-04 - val_loss: 6.2063e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 474us/step - loss: 1.2820e-04 - val_loss: 6.1582e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 498us/step - loss: 1.2756e-04 - val_loss: 5.9826e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 510us/step - loss: 1.2752e-04 - val_loss: 6.5235e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 539us/step - loss: 1.2669e-04 - val_loss: 5.8955e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 477us/step - loss: 1.2660e-04 - val_loss: 5.8472e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 479us/step - loss: 1.2723e-04 - val_loss: 6.0244e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 480us/step - loss: 1.2754e-04 - val_loss: 5.8911e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 473us/step - loss: 1.2701e-04 - val_loss: 6.1907e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 470us/step - loss: 1.2597e-04 - val_loss: 6.0316e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 474us/step - loss: 1.2634e-04 - val_loss: 6.2855e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 480us/step - loss: 1.2653e-04 - val_loss: 6.3352e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 456us/step - loss: 1.2663e-04 - val_loss: 6.6352e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 467us/step - loss: 1.2882e-04 - val_loss: 6.1181e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 530us/step - loss: 1.2886e-04 - val_loss: 6.5679e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 457us/step - loss: 1.2962e-04 - val_loss: 6.1830e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 64s 39ms/step - loss: 2.4163e-04 - val_loss: 7.6800e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 438us/step - loss: 1.5483e-04 - val_loss: 6.3832e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 451us/step - loss: 1.3979e-04 - val_loss: 6.2059e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 472us/step - loss: 1.3164e-04 - val_loss: 6.1726e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 452us/step - loss: 1.2705e-04 - val_loss: 5.8900e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 464us/step - loss: 1.2552e-04 - val_loss: 6.3812e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 457us/step - loss: 1.2644e-04 - val_loss: 5.9967e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 455us/step - loss: 1.2478e-04 - val_loss: 5.8953e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 439us/step - loss: 1.2447e-04 - val_loss: 5.9628e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 438us/step - loss: 1.2645e-04 - val_loss: 5.9959e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 460us/step - loss: 1.2428e-04 - val_loss: 5.8415e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 449us/step - loss: 1.2597e-04 - val_loss: 5.8617e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 479us/step - loss: 1.2381e-04 - val_loss: 6.3612e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 504us/step - loss: 1.2537e-04 - val_loss: 5.8175e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.2454e-04 - val_loss: 5.8457e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 512us/step - loss: 1.2465e-04 - val_loss: 6.6745e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 500us/step - loss: 1.2445e-04 - val_loss: 5.8084e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 590us/step - loss: 1.2386e-04 - val_loss: 6.2629e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 501us/step - loss: 1.2379e-04 - val_loss: 7.1080e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 504us/step - loss: 1.2865e-04 - val_loss: 6.0854e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 493us/step - loss: 1.2460e-04 - val_loss: 5.8352e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 539us/step - loss: 1.2306e-04 - val_loss: 5.8937e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 588us/step - loss: 1.2397e-04 - val_loss: 5.8710e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 442us/step - loss: 1.2454e-04 - val_loss: 6.8183e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 434us/step - loss: 1.2715e-04 - val_loss: 5.8773e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 66s 40ms/step - loss: 2.7299e-04 - val_loss: 8.1195e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 573us/step - loss: 1.6145e-04 - val_loss: 6.7331e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 578us/step - loss: 1.4644e-04 - val_loss: 6.3268e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 576us/step - loss: 1.3713e-04 - val_loss: 6.1156e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 592us/step - loss: 1.3026e-04 - val_loss: 6.2702e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 610us/step - loss: 1.2949e-04 - val_loss: 5.9086e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 593us/step - loss: 1.3105e-04 - val_loss: 6.1084e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 577us/step - loss: 1.2835e-04 - val_loss: 6.1012e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 579us/step - loss: 1.2880e-04 - val_loss: 5.8650e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 537us/step - loss: 1.2700e-04 - val_loss: 5.9763e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 545us/step - loss: 1.2561e-04 - val_loss: 6.3326e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 555us/step - loss: 1.2680e-04 - val_loss: 5.8851e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 559us/step - loss: 1.2669e-04 - val_loss: 5.8935e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 567us/step - loss: 1.2811e-04 - val_loss: 6.7394e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 681us/step - loss: 1.3099e-04 - val_loss: 5.9315e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 576us/step - loss: 1.2694e-04 - val_loss: 5.9261e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 562us/step - loss: 1.2664e-04 - val_loss: 6.1597e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 565us/step - loss: 1.2615e-04 - val_loss: 5.9645e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 562us/step - loss: 1.2631e-04 - val_loss: 5.8454e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 563us/step - loss: 1.2751e-04 - val_loss: 6.4781e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 620us/step - loss: 1.2605e-04 - val_loss: 5.8501e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 592us/step - loss: 1.2491e-04 - val_loss: 6.0769e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 590us/step - loss: 1.2582e-04 - val_loss: 5.9339e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 577us/step - loss: 1.2529e-04 - val_loss: 5.8357e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 568us/step - loss: 1.2695e-04 - val_loss: 5.8951e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 66s 40ms/step - loss: 2.4752e-04 - val_loss: 6.4833e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 576us/step - loss: 1.6115e-04 - val_loss: 6.8568e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 571us/step - loss: 1.4128e-04 - val_loss: 6.0987e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 568us/step - loss: 1.3097e-04 - val_loss: 5.9861e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 572us/step - loss: 1.2911e-04 - val_loss: 6.1211e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 571us/step - loss: 1.3067e-04 - val_loss: 6.2644e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 573us/step - loss: 1.2969e-04 - val_loss: 7.1841e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 566us/step - loss: 1.2652e-04 - val_loss: 5.9632e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.2644e-04 - val_loss: 6.6137e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.2686e-04 - val_loss: 5.8492e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.2635e-04 - val_loss: 6.7622e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 567us/step - loss: 1.2738e-04 - val_loss: 6.1526e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.2525e-04 - val_loss: 5.9267e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 572us/step - loss: 1.2463e-04 - val_loss: 6.2767e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 571us/step - loss: 1.2388e-04 - val_loss: 6.4154e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 574us/step - loss: 1.2575e-04 - val_loss: 5.9952e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 568us/step - loss: 1.2916e-04 - val_loss: 5.8895e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 577us/step - loss: 1.2442e-04 - val_loss: 5.8396e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 575us/step - loss: 1.2412e-04 - val_loss: 5.8199e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 575us/step - loss: 1.2651e-04 - val_loss: 6.8824e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 571us/step - loss: 1.2894e-04 - val_loss: 6.0694e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 576us/step - loss: 1.2600e-04 - val_loss: 6.6202e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 572us/step - loss: 1.2595e-04 - val_loss: 5.8399e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 573us/step - loss: 1.2788e-04 - val_loss: 5.8050e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 568us/step - loss: 1.2321e-04 - val_loss: 5.8027e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 67s 41ms/step - loss: 3.6839e-04 - val_loss: 8.2672e-05\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 1s 604us/step - loss: 1.7632e-04 - val_loss: 7.1433e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 570us/step - loss: 1.5277e-04 - val_loss: 6.3550e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 580us/step - loss: 1.3858e-04 - val_loss: 6.4536e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 590us/step - loss: 1.3118e-04 - val_loss: 5.9988e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 535us/step - loss: 1.2574e-04 - val_loss: 5.8306e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 514us/step - loss: 1.2453e-04 - val_loss: 5.8358e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 534us/step - loss: 1.2849e-04 - val_loss: 5.8019e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 572us/step - loss: 1.2460e-04 - val_loss: 6.8575e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 552us/step - loss: 1.2710e-04 - val_loss: 6.4892e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 557us/step - loss: 1.2422e-04 - val_loss: 6.0107e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 526us/step - loss: 1.2459e-04 - val_loss: 5.8022e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 560us/step - loss: 1.2384e-04 - val_loss: 6.0931e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 584us/step - loss: 1.2439e-04 - val_loss: 5.8667e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 526us/step - loss: 1.2449e-04 - val_loss: 5.8844e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 542us/step - loss: 1.2374e-04 - val_loss: 5.7930e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 531us/step - loss: 1.2498e-04 - val_loss: 5.8059e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 532us/step - loss: 1.2469e-04 - val_loss: 5.8257e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 615us/step - loss: 1.2412e-04 - val_loss: 6.3958e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 548us/step - loss: 1.2585e-04 - val_loss: 6.2453e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 553us/step - loss: 1.2790e-04 - val_loss: 6.3050e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 539us/step - loss: 1.2922e-04 - val_loss: 6.1785e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 553us/step - loss: 1.2672e-04 - val_loss: 6.0161e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 551us/step - loss: 1.2438e-04 - val_loss: 5.9374e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 545us/step - loss: 1.2277e-04 - val_loss: 5.8594e-05\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 64s 39ms/step - loss: 2.9609e-04 - val_loss: 6.7852e-05\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 519us/step - loss: 1.5240e-04 - val_loss: 6.2582e-05\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 492us/step - loss: 1.3547e-04 - val_loss: 6.0023e-05\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 525us/step - loss: 1.2844e-04 - val_loss: 5.8549e-05\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 473us/step - loss: 1.2533e-04 - val_loss: 6.4067e-05\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 472us/step - loss: 1.2677e-04 - val_loss: 5.9349e-05\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 470us/step - loss: 1.3111e-04 - val_loss: 7.3464e-05\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 489us/step - loss: 1.3191e-04 - val_loss: 5.8363e-05\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 484us/step - loss: 1.2813e-04 - val_loss: 5.8313e-05\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 471us/step - loss: 1.2585e-04 - val_loss: 5.8179e-05\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 470us/step - loss: 1.2634e-04 - val_loss: 6.3393e-05\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 468us/step - loss: 1.2960e-04 - val_loss: 6.0746e-05\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 462us/step - loss: 1.2816e-04 - val_loss: 5.9136e-05\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 465us/step - loss: 1.2614e-04 - val_loss: 5.8129e-05\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 473us/step - loss: 1.2756e-04 - val_loss: 6.0286e-05\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 471us/step - loss: 1.2389e-04 - val_loss: 5.8862e-05\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 463us/step - loss: 1.2603e-04 - val_loss: 5.8429e-05\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 479us/step - loss: 1.2711e-04 - val_loss: 6.0534e-05\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 527us/step - loss: 1.2404e-04 - val_loss: 5.8497e-05\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 467us/step - loss: 1.2373e-04 - val_loss: 5.9120e-05\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 464us/step - loss: 1.2408e-04 - val_loss: 5.8114e-05\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 464us/step - loss: 1.2483e-04 - val_loss: 6.9198e-05\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 528us/step - loss: 1.2529e-04 - val_loss: 5.8067e-05\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 485us/step - loss: 1.2542e-04 - val_loss: 6.0265e-05\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 467us/step - loss: 1.2755e-04 - val_loss: 5.9538e-05\n",
      "Test RMSE LSTM eBay Inc. : 0.00812224994427141\n",
      "Test RMSE HAR eBay Inc. : 0.008451955908195549\n",
      "Test MSE_VAR LSTM eBay Inc. : 4.347229038644794e-07\n",
      "Test MSE_VAR HAR eBay Inc. : 4.421958410066635e-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd5gV1fnA8e+7uxTpbUH60hFRUZdiQZGiCCpqNGqMYhKjJhqNioolamxBjTXqLzF2o7FHURALTcECC4IISBUFRFhAYGkLu3t+f8zcu7fMbXvn7i3zfp5nn7136pm5M/OeOefMGTHGoJRSyrvy0p0ApZRS6aWBQCmlPE4DgVJKeZwGAqWU8jgNBEop5XEaCJRSyuM0EKicIiJtROQTESkTkQdqMP9gEVmWirQplak0EHiEiKwRkT0islNEfhKR50SkUZzzDhGRdalOo0suATYDTYwx1zpNICIDRGSyiGwTka0iMkdEfgNgjPnUGNOrthIrIseKyGcist1Oy2wR6Z/kMteIyHC30ugWETEi0j3d6VDhNBB4y6nGmEZAP+Bw4MbaWKmIFNTGemydgSUmwpOSInIUMA2YCXQHWgJ/AE6utRRWp6UJ8B7wD6AF0B74K1Be22lRHmeM0T8P/AFrgOEB3+8DJgV8rwf8HfgB2Aj8EzgAaAjsAaqAnfZfO+A54K6A+YcA60LWdwPwNdaFrcAeNs4eth14FahvT98K66K4DdgKfArkRdiWo4G59jLmAkfbw58D9gP77HQOd5h3FvB4lP0Uuh03AOuBMmAZMMweng/cBKyyx80DOkZLn8O6ioFtEcbVs/fDIQHDWtu/RWGk/QW8aP9We+x9cL097yDgM3v6hcCQgOXOAO6yx+8E3sUKkC8BO+xtKLKnFeAhYJO9fV8DfeM8Bg3Q3f58O/Aa8IK9/xYDxQHTdgTeAkqBLcBj6T6Hcvkv7QnQv1r6oQMCAdABWAQ8EjD+YWAiVs60sX0x+Js9LujiaA97jtiBYIF9Qh8QMGwOViBpASwFLrPH/Q0r+NSx/wYD4rAdLYCfgQuwgst59veWTukKmbcBUAmcEGU/+bcD6AWsBdrZ34uAbvbn6+x92Mu+OB5mXzyjpi9kXU3si9zzWHckzUPGPwHcG/D9KuDdWPuL8KDf3l7PKKxgMcL+XmiPnwGsBLoBTYElwHJguL0NLwDP2tOehBX0mtnbfRDQNs5jMDQQ7LXTlG9vzxf2uHysYPUQVkakPnBsus+hXP7ToiFveVtEyrAubpuA2wBERIDfA1cbY7YaY8qAe4Bzk1zfo8aYtcaYPSHDfjTGbMUKNv3s4fuBtkBnY8x+Y5XVOxXvjAZWGGNeNMZUGGP+C3wLnBpHeppjXQg3xJn+SqyceR8RqWOMWWOMWWWPuxi4xRizzFgWGmO2JJI+Y8wO4FisC+S/gVIRmSgibexJngd+JSK+8/QCrBw/xL+/AH4NTDbGTDbGVBljPgJKsC7CPs8aY1YZY7YD7wOrjDEfG2MqgNexihJ9620M9MYKPEuNMfHuz1Cz7DRV2tt1mD18AFZm4TpjzC5jzF5jzKwarkPFQQOBt5xujGmMlevtjVW8AFZRQwNgnl2Bug2YYg9PxlqHYT8FfN4N+Cqs78fKlX4oIqtFZHyEZbYDvg8Z9j1WrjeWn7GKTdrGMS3GmJXAn7Fyr5tE5BURaWeP7ohVLJRU+uwL6UXGmA5AX3v+h+1xXwK7gONFpDdWncZEe9Z49xdY9SZn+35b+/c9luD9sDHg8x6H743sNE0DHgMeBzaKyJN2XUdNhB4L9e36pI7A93YQUrVAA4EHGWNmYhWh/N0etBnrZD/YGNPM/mtqrIplsHKsoXZhBQ+fA51WlUCayowx1xpjumLlnq8RkWEOk/6IdWEL1AmrHD/WOnYDnwO/SCBdLxtjjrXXaYB77VFrsYpS3Ezft1i/S9+Awc9j5egvAN4wxuy1p422v0L3+1rgxYDftpkxpqExZkKsNEVI56PGmCOBg4GeWMVkbloLdKrlRgaepoHAux4GRohIP2NMFVbRxEMi0hpARNqLyEn2tBuBliLSNGD+BcAoEWkhIgdi5ZxrTEROEZHudjHVDqximUqHSScDPUXkVyJSICLnAH2wKk7jcT1wkYhcJyIt7XUfJiKvOKSpl4gMFZF6WOXZewLS9BRwp4j0EMuh9vLiTp+I9BaRa0Wkg/29I1adwhcBk70InIEVDF6Ic39tBLoGLOM/wKkicpKI5ItIfbtJcIc491lgmvuLyEARqYOVGdjrW6+IXCQiaxJdpoM5WMV3E0SkoZ3eY1xYropAA4FHGWNKsS4sf7EH3YBV1PCFiOwAPsaqCPXlVP8LrLaLFtphXaAWYlVMfojVAigZPex17sTKtT9hjJnhkO4twCnAtVgVntcDpxhjNsezEmPMZ8BQ+2+1iGwFnsS6gIeqB0zAumP6CavVzk32uAexWr18iHUhfhqrUjyR9JUBA4EvRWQXVgD4xp7Xl951wHysXP6nAfNG219/A26xf6txxpi1wBg77aVYOe7rqNn53wQr0/AzVpHXFqrvLDsCs2uwzCB2ncGpWEVhPwDrgHPA/8DfzmTXoYL5WhkopTKUiDwD/GiMuSXdaYlGRD4ErjLGLE13WlRiNBAolcFEpAirGO5wY8x36U2NylVaNKRUhhKRO7GKiu7XIKBSSe8IlFLK4/SOQCmlPC4r2+m2atXKFBUVpTsZSimVVebNm7fZGBP2oGhWBoKioiJKSkrSnQyllMoqIhL61DugRUNKKeV5GgiUUsrjNBAopZTHaSBQSimP00CglFIep4FAKaU8TgOBUkp5nAYCFWTD9j1MXbox9oRKqZyhgUAFGfPYbH73vD6sp6KrqjIMe2AGk76u6euKVSbRQKCCbCorT3cSVBbYvb+SVaW7uP6NhelOinKBBgKllPI4DQRKKeVxGgiUUsrjNBAopZTHaSBQSiVM32yYWzQQKKVqTETSnQTlAg0ESinlca4EAhEZKSLLRGSliIx3GH+ciMwXkQoROStk3FgRWWH/jXUjPUopFY+Vm8rSnYSMkHQgEJF84HHgZKAPcJ6I9AmZ7AfgIuDlkHlbALcBA4EBwG0i0jzZNCmlVCxTl25k+IOf8M6C9elOStq5cUcwAFhpjFltjNkHvAKMCZzAGLPGGPM1UBUy70nAR8aYrcaYn4GPgJEupEkplUK5UFW8fONOAJZs2JHmlKSfG4GgPbA24Ps6e5ir84rIJSJSIiIlpaWlNUqoUspdWlWcG9wIBE7HQrwZhrjnNcY8aYwpNsYUFxYWxp04pZRS0bkRCNYBHQO+dwB+rIV5lVJKucCNQDAX6CEiXUSkLnAuMDHOeT8AThSR5nYl8Yn2MKWUSimTEzUd7kg6EBhjKoArsC7gS4HXjDGLReQOETkNQET6i8g64GzgXyKy2J53K3AnVjCZC9xhD1NKqVohWtNBgRsLMcZMBiaHDLs14PNcrGIfp3mfAZ5xIx1KqdqhPUzkFn2yWClVc5qZzgkaCJRSyuM0ECilPEmLt6ppIFBKeZp2oKqBQClVE5qbzikaCJRSNaaZ6dyggUDF7eUvf+CMJ2anOxnKoz5ZXsr3W3alOxk5yZXnCJQ33PS/RelOgvKwC5+ZA8CaCaPTnJLco3cESilP0+ItDQRKqSxnjOHBj5bz47Y96U5K1tJAoJRKWCZ12PbtT2U8OnUFl788P91JyVoaCJRSNSYZ0Ai/ssoKSuX7Q1+AqOKlgUAp5UlGHy3200CglPK0DLipSTsNBEqpnKAX9JrTQKBUFjnzidkMe2BGupOhHbblGA0EytOqqgwvfr6G8orKdCclLvN/2Maq0sx5utYpF15aVk7R+ElM+npDraRBg1LyNBDkqKUbdtDvjg/ZVLY33UnJaG99tZ6/vLOYx6evSndScsbyjWUAvPTl97W63kSLhjSAVNNAkKOenvUd23bvZ8ay0nQnJaOV7d0PwI49+9OcEpUu+s5iDQTK4zRX6D7dp9lHA0GO0pMx3Lc/7eCs//uMPfuq6wN0N6VObbXiyaSnnKP5y9vfMOaxWelOhiMNBDlOb3qr3fXeUkq+/5mS77f6h/keKtKmh4nJxEtvokU8tb0NL37xPQvXba/ltcZHA4FSaDlxTTnttWzJoftoJkADQc7KtpOxNoTuk6279lFRpfspVWoruGoxaPJceTGNiIwEHgHygaeMMRNCxtcDXgCOBLYA5xhj1ohIEbAUWGZP+oUx5jI30qQsmdApWKYRhL37Kznizo+qh+luynr6G9Zc0ncEIpIPPA6cDPQBzhORPiGT/Q742RjTHXgIuDdg3CpjTD/7T4NAllqzeRerSncmPN8xE6bxxIyVKUhRdKE9Veo1xD2aQ88+bhQNDQBWGmNWG2P2Aa8AY0KmGQM8b39+AxgmmlVNrVo+GYf8fQbDHpiZ8Hzrt+3hvinLYk/ogmgXKD0aExNPz52112qohvNpwPJzIxC0B9YGfF9nD3OcxhhTAWwHWtrjuojIVyIyU0QGR1qJiFwiIiUiUlJaqg9JxUuvb+FEwusLNF9SM5m032qakszZgvRxIxA4NxyIb5oNQCdjzOHANcDLItLEaSXGmCeNMcXGmOLCwsKkEqy8KVoO8MlPVrO6BkVbKpxmtLOPG4FgHdAx4HsH4MdI04hIAdAU2GqMKTfGbAEwxswDVgE9XUiT5+nJGFmkHODFL5TUajqUyhRuBIK5QA8R6SIidYFzgYkh00wExtqfzwKmGWOMiBTalc2ISFegB7DahTQpWwbduWcUx7sDjZ5ZSd80lrykm48aYypE5ArgA6zmo88YYxaLyB1AiTFmIvA08KKIrAS2YgULgOOAO0SkAqgELjPGbA1fi1LJi/lshQZNV6TtwpxgrkeftanmynMExpjJwOSQYbcGfN4LnO0w35vAm26kQQXTXFIUesFPWjxHVyZVJEeVLelMIX2yOMfpMe7M6ULm21XlFZVUJfjE8R3vLuGaVxckna5skwmHl2Z5kqeBQHlGvDdJvW6Zwrg3Fia07Gdmf8dbX62vQaqUWzIhKGUrDQQ5SnNJkcXTB85b8/WiXlN67GUfDQQ5Ltd61SyvqGTgPR/z0ZKNSS1H61BSL9OPPD0EqmkgUBlv3c+7uWfyUqqqDJt2lLNxRzl/fXdxwsuJdd67Vbn5w5bdjHt9Ifsrq2JPnKUy6SKabFoyPWDVBg0EOSqTTtRkXfnfr3jyk9UsWr+dqUuTuxOA1Fegj3tjIW/MW8e873+OOM2mHXvZtntfahNSC0L3ZWWV4fFpVieCM5eX8seX5rmynt37KhJOi4qfBoIclwsnx/7K6qh2+7tLAGu73l34Iz9t3xv/gozjRz8h/iKjUY98yuD7psVcT6ALn5nD0AdmADDgnqkcHtANdq547+sfKQkIgJMX/eTKcq96xXstsmqTK88R5LJNO/ZSryCfpg3qpDspnhcY1PZXGP70368oatmAGdedEHPeyirDnDXWs4rRYmO8rUaXbNgRc5rQ9XyyPLizxFy6a/Mpr0hNcVi0uyutnk6eJ+8IPlz8E8V3fUx5RWXMaQfcM5X+93xcC6lyVy6dGk5PgFbZV9ENcd4RPD0rvp5LQu8Inpn1XVBndC98vibovQunPTaLsr37Y6bXyyoqq+h/98e8uzC0C7L4bd0VuxjNF3iNMewsj12UpL9SNU8GgjveW8LmneVs2lEe1/T7Esjl7Ai5KKjk+a7NTi2g4i362hjyW0fKjQfeEZRXVHLHe0sY+sBMKiqreOHzNdz6zuKg9y58vW47t7z9jXN6c6FcLlEO+3X7nv2UlpVz+8TEK/hr4ulZ39H3tg/YsH1PXNN78WcK5clAkKpb8ncWrOfQ2z/km/XbU7OCHLZyU826gK4y8QXqwN9cROh/d/hdnghBdQ6B80x4/1tufcf5QrZlp3NuNRsvMKtKd8bV2imRu55KO7rm5aVmh4Sez5MXbQDgx23xBQLl0UCQKjOXWWXA3/5UVuvr/njJxqAiimxrJz/lmw1B34vGT+KBD2O/uWxfRRU9b3kfgLVbd7NyU833/fKNOznu/un+74G7cG6UMurQC36q9nxlgt1eJGrjjr0Me2Amd763JIG5Yl/cK+0dmZ/iyOi7A6veTVkYidPEk4HAd5Gs6XH5v6/Wcdb/fRa+XPt/bR9+a7fu5uIXSrjaoa+bbCmecErnP6atxBgTUNQSfRmD75vO8Ac/cRxXk3L7wHkS2Yv+4yvhNca3XLDe9VxeUUlllWHdz7uDpntr/jq+/Sm8MvuT5aVURMnt+8rhv1ydRAfADhvtC2D5KbojCOU/D7Pj0M8IngwEPstCcu7PzPqO3z03N+Z8V7+6MKiJXKjaPgB377Mqvb/fsjvGlNmny42T4y7rjSa4aCjxeWoi0nqKxk+KOM/7izZQNH4SW3aG118FBsv12/awaUc59035lmPvnc4b89ZRNH4SW3ft45rXFjLy4U+D5p29cjMXPjOHR+02/k7iDbiJOvEhKzjnJXi1ueu9JVH3VSS+gJkXa0Oy4K558Y/bWbs19ee1JwOB7+f/3fMlQWXTd7y3hKnfbgKo0cUnWnHM3v2VKbu19+VcA4/7zD/Eg0U7Z3/eHV4BXxvbF7iOaOnbuCO45VIyaXt29hoAVjjUmYQmwRiYYRdHTnj/W4CI9VObyqw0fr9lV8R1J3LXtLksQiseh0X4MiqJFg09Neu7uKYLXWV144L4ZHI3LKMfncXg+6bHnjBJ3gwEAUfO8Adncu+Ub4PGT160gaP+No3pdlDwKdu7n1veXuS4zEtfLOHtBVbzOKfjvfdfptDtpsnhIxKwZvOuqE1eHVvVJLVG9xljuGfyUqYv28Rzs6tP9K9+2JZQ18/J1IHEs09E4l/H8o3BF23fbF9+l3gRiz+oxzHtTf9bxLKNwXe18TyBG3HdAa2dJrz/LQMjNJvevLOcUY9+Gja8qspEXX88RUOH3v4B1yfY86uPv/kocd4RKD9PBoJQz87+Lii3/seX5gPw7tfB7Z6fmLGK/3zxg/97aVm5v035B4uruz6IlcNY/ON2Nofc+heNn8Tj0yPftm/fs58hf5/Bzf/7JmxcKu5wX/h8jevL3FdRRWlZOU9+sprfPDvX/5QwwEdLNvLsZ9HXee1r1ReIzSEtdQIv2jOXl/K395cGFfMlGjgEmP/DtqDv8fKt674pVmX3prK9Ucvmg+e1/p/z5Bcxp521crP/s+94Cnyu4s73lrBlZzl791cmlOsV4J8zV4U1ufUJbCXlu9bur6xi0N+mBv2moeIJBDv2VvBaybqo03z70w4+WV7Kq3N/cBxfVRWcNhWbJwNB6C1wVRWOufXQrohDi3aOnjCVYQ/M5NGpK4KGz1xeythn5vDZqs04Gf3oLEY+XF2p6btw3P9B5FYy2+3ikS9Wbwkb51i2aw+bvXIzReMnhRVfOAnMzf1rZs1eHT150QYuezG8f5mVm3bS85b3eWdB5IeKAh/UchKa+w3066e/9H/euqucf81c7S/mA3j+8++jLjuUiDD2mTn+7/F2ZbF7XwUL11UXz+wqr2DA3VP5S4Smp2BlKObYdw/JxvTAQ+DpWd9x5F0fc/Y/P/cPe2fBj5zw9xlJrqVaaVk5ReMnccSdH7GpLPpzOXkiTF60gblrErtTCm1RNvLhT7nwmTnc8KZ1dx4a431f/zFtBXdPiq8FVEVlFX99dzEbd+zl2Hun8cY8Kxi9MueHGE81p07og4qp5MkuJkIPnH1x59aCZ/T1gfPgR8uDhv/PfkHJovXbmf+XEY7L8uVov1m/nU9XOAeM4DRaRUJ1CxKL3a/MXQvA/O9/5uRD2kad9rC/fuj/vL6GbbB9d1NgbVv9Onl0b93Y3yXDB4sj9z3ju4g99WniQWj2yuoAGVokMO/74AtPPDnF0KD/Y5yBILSS1pdrj9Rt9tn//Iy5a6wLzeuXHZV0s1+ntvqL1m8PKqb6bvMupnyzgW2793PugE7+4b5Vx+o+w6kuoWxv7CKpPBH/8bHqnlHc+d4SLh7chQ7NG4RNe1dAE9bL/jM/bLwT38Ocvn3ou0u/eXQfx+kDt6L7zVYTZF8dzfVvLOSsIzsw/i0r2KyZMDriejeV7eVfM1dz06iDXG0ZdfnLX7m2rFg8ekdQM99tjlzR5sR3TESqJN6ys5xT/jErrI7Cia8Pl7r54T9ZYAXh7n0VlDrkzAJTcN+UbylZs9Xqq2f8JN63H8AJ7NwNrH6WfAIf8S8tK49a6QhW7v6Uf8zyN+eM5wK3YuNO1m7dzV2TlsacNprAB79eL1nLL/7v8yhTu+uHkBYel9p3R5GCjy8IAGwuK0/6jmBVhAfz/jsnuBjlsv/MZ/xbi5j3/VZueXuR1UzXYe13vbck7PjdsC2Bjv4CBAaY+T/8zHOfreGa15zrA+KtKIbqYLt8407KKyrjKip98fM1LLfvMB/6eHnY+CoTf3HiTW99w9OzvuOTFaVh4x6btsKxqXk8QvumSiXP3RFUVhnHC2Usb81fx8dLN8WeMIh19ke6aE4LqYzOE6sv++Pun84j5/ZjTL/2rC7dydAHZnLZ8d0AqGffEUz55ieueW0BBzatz+pSa/n7Kqvoc+sHjuvyHdP7K6t4YsYqnpixyj/uDy/Nd8zxvDl/PdO+3cjLvx/EVa9U5058T+X65nlrfniZbmA3DC9/+QMH1LXSHa0PmDlrtrrSQmL7nupb6uve+Drp5bkhnmMuP0+CLmL7K6uo4xD4o0m0COysf36OMXDlsB6OT+I+Nes7hh7UmmYH1GXUo5/ywm8H8Js4mljHst/O2ARmoGvSqm5neUVQ0WyvW6bQrbBh2HSzV25m885yTjusHSIStajOp8uN1cXFq0p3MuyBmdx1el/aNq1PzzaN+fuHy2hUr8DfgOPVOWs5oVdrwDonAoPcooDiwoc+Ws7VI3r6v495bBb7Kw2TrxrsHxb6tPze/ZXUr5MfM8015blAEJpji1eknEs0m3eWs3TDjqBy/TUBdxWhFykD/idbr3plAcd0b8VQ+4L6tl3c5Csauuw/Vk7TFwQAduyJXKZYaQxvzFtHpxbht+EAk77eEDbMd6cydenGoIurf5lVhu8274q5b2763yJO6FUIpOep61CZEhxCXfLiPA5sUt///eb/LeL8gZ0Z8/hsLj2+K2MOa+/6On2BZ8DdUyNOc/ekpSz+0crNXxhQb5KMMjtDsGbzbv45cxXvLPiRgV1aJLwcp9z2qtLgjNeefZWc/5RVh1TT7qx9zXNfL1kbVAcEcGz3VgBMWfwTW3aWs8V+liPQ0oC7oUemruCRqSu4+4y+nD+wc9jyAP4S0n9V779M4cubhtEm4Phwk2RbVwQAxcXFpqSkpEbz1uQBlUzStVVDrhrew/GAblg3n137YveoqpSXnHVkB3/lb7KKOzeP+jDpb44p4tAOTbn61fgyjge1beIPEoF35U7XqetH9uKPQ7onmOJgIjLPGFMcNtxLgeD5z9ZwWy31gKiUUjWx7K6R9LplSsTxq+4ZVeNK6UiBwJXKYhEZKSLLRGSliIx3GF9PRF61x38pIkUB4260hy8TkZPcSE8kGgSUUpkuWhAA/E2N3ZR0IBCRfOBx4GSgD3CeiIS21/od8LMxpjvwEHCvPW8f4FzgYGAk8IS9PKWUUg4SbUIeDzeWOABYaYxZbYzZB7wCjAmZZgzwvP35DWCYWD1ojQFeMcaUG2O+A1bay1NKKeWgcX332/i4EQjaA2sDvq+zhzlOY4ypALYDLeOcFwARuURESkSkpLS09trXKqVUJln/s/sv3HEjEDjVWoTWQEeaJp55rYHGPGmMKTbGFBcWFiaYRKWUyg2peCe2G4FgHdAx4HsHILRDGf80IlIANAW2xjmvaw7r0DRVi1YqqzRrUCfdSVA1lIpus90IBHOBHiLSRUTqYlX+TgyZZiIw1v58FjDNWO1WJwLn2q2KugA9AHeeWHHwvz8ewy+LO6Rq8SkVq4Lo4XP6MbhHq6jTNKir9fCZ6u4z+kYdf0SnZq6tq/eBjTm9n/sPp+Wik/se6MpybjvVub+jUMWdm7uyvkQlHQjsMv8rgA+ApcBrxpjFInKHiJxmT/Y00FJEVgLXAOPteRcDrwFLgCnA5caYlD0RlZcn3HfWYalavKOLji5yZTn9OkS+EHQtbMjph7fnvrMOjbqMJXeMdCUtANPHDWH5XSe7tjyvO6e4Y9TxT43tT/8idy4SZxzenptHH+TKstLp+J7hRcRnHuFugLtgUGdXlvObY7r4P48/uTdXDevBMd1bhk3X9IA47tRS0L22K+2QjDGTjTE9jTHdjDF328NuNcZMtD/vNcacbYzpbowZYIxZHTDv3fZ8vYwx77uRnkxy+2kHc/aRHTjz8PAD9N8XVj/XccPI3v7PTnctgeWC//39IMDK2QF0truNaNv0AAob13NMh2/5X940LGycU9oCXTmsR9iwyioT9S7lnjMOqVFR3Ht/OjbhebLdL4s7UBCjT6F9FVV0dOilM5Lp44ZEHDfsoNbUyc/joLZNgoY3jHLH2LVVeP89yRp3Yk/mOByPPrEyUaGB0a2eP7vEua2N6kVuvXNufyuw/3l4DxbeeiIAH159HJOvHMxlx3fj6hE9+b9fHxk2X4uGdWOuNxWvWfBk76O17f6zD+PBc/px1+l9efWSQXx9+4msmTCaEX3a+Ke59LiuPHxOPyD4wut0S3lUt5asmTCa60f2AoJr19+5/Jigaaf8eTADu7Tg94OtHEmbJvUpahl8QblqePX6Qjuf61rYkLOPrA5Mvnmb22XMHVsc4LjNvxrYKepBPfO6IY7D+7Z3Dh5Trz0+4rKctGpUl0uP6xo23Lcf0u3mUdU58nj6WmtUvyDoncWxRLqYvXTxQLq3tjIQN43qTeuAjMPoQ4O7KQ8srjoyySKLW0YfFHThnnDmIVwxtAetm9SPmAu+Ymh4dwq+PquAsP1x55i+/vLzCWcewt1n9OX+GHfJTqaPG8JRXa3ceuhP89SFxf5jPtrPMeEXh7Jmwmj+PLwnTe1zpWebxvRpVx18m9SvE9b3162n9uHGk3v7zy+fHq0bxSz6TYbnA0F+nvD5jXRyNWgAABjYSURBVENpYrfNfeG3A7jvF4fyxyHdwqY984j2SbXh/fWgzgzs2pIm9cMP/Lw84fTD27Nmwuig/tkPbmddGI2xgkJgp2ROlUZtmwZ3StX7wCa8eulRQTnOwP7610wYTeeWDYNOsED3/eJQOrZowKmHtQPgiqFWDqdlI+sCEq13zCF2T4xh2yrQuWXDhG67uxU2iphGJ+UVVdw4Krz4I1Lf9G4a1NW587SPrznO34tsn3ZN+PvZVjFlld3Ny6fXn8CSO06i5JbhQfP964IjaVSvgAKHHO9FRxfRponzXaCTY7pXX0wG9yhkzs3Dw6bp17EZzRrU4VcB7yq47bSD/Z8fObdf3Otr3+wAXr54IBcP7srL9p0swDn9q4vCFtw6gg+vPi5s3laN6rHy7uDiR6ei3eN7FjLnpmGcN6Cj/+KclyecP7Azre3zJdJvErium0cdxHn2Nke6yFdUVfcKGvrei/MHdgqdPKauIT2lNq5fh0uP70Z+XvB5dUDA3VoiGYJ4eT4QFOQJbZseQIO61gW+e+tG/LJ/R8fc7IO/7Ee9gtqpcC3u3JwzDm8fdED+5pgufOFwKx3YXVRcB4k9SeDdw78vLGapXYcwI6BYwXeh93V/XVVl/DkcgDr2AfvyxQPDVnPhUZ2ZF3BRW3jrifQ+sDEfXm3l7u88vTrHOX3cEN69Inqx0LO/CX7WsFebxv4Lq8/vjrVy/E+cf0TUZaXSpceHZyI+Gz+U7q0bc82Invz7wmKO6d7K3wWz7/fr2KIBDeoW0KpRPYb1toJorzaNGX6QdefYoF74sXf7aQf7MwvJ8qXjvAEdWXDriUHHUqN6Bcy5eRhf3jQs6jEWmoGafOVgjraDj+9YGndiz6BliAg92zR2XF5okVlh43r+IiDfInq2aUTrJvWD02Vvi28fF+RFv9SV3DKc3x/Xlb+deUjYuMA74sB3dvQvsoLL4786gjf/cDR3nxE+byyPnnc4T48N6/qH0PxVYLFgKoqGPNcNdSQ3jurNNa8t9AcA30E1pl+7oNcr1s2vnRehvvGHowH8r/VzLD3wXUgiLCP09jJktqBWRAX5efhiXFGrhhzSvimLAl54c/3IXlRUVvnvDHxOPawtyz4so3ubRgzpVciMZdUP+4mI/84BoGmDOkz5c3jOD+Ivlw1Up0Do1zH4InjTqIO49Liu/pxgoF4RLjZuuWPMwZx+eHvHO752zazihLoFef4iQd91q8qh40ffm8auHtHTf+Hz1QnFa82E0RTf9VHY+51jidQ8sXXj2F0gXz+yt/9dFxcM6hyUafClKVnvXH4MkxZt8GdCAovWIr3AvsoY6uRL2MuXYjEGLh7cldft3ksPDaj3unFUb24Y2YseSRxXTerXYdhBbcKGB/4Gz17Un/5dWrB9z34em7aCo7qFVzIny/OBwHdYjOnXnjEBTep81/tmIeWXsSr13OY/sB0uFpHGLb/rZJZvLOPAps4nri/IxXNK+C5WrRvX5+FzDw8bf/kJ3bngqCKaHlAnocpMn6nXHh924fz0+hM4/fHZbNkVfgFr3bhe0LtxQ2/P8/PEMQgAvHrpIMfhyWpSv4D3/jSYji0O8O/bPw3tzsYde6O+iL36IhU+Lt/3GwX8toN7OBeNRcuaWHe6iQWCWOLNCrn94FPf9k3s/03p276p/5WmwXfEwfP4vjoF22gCl+P73L11Izq3rM6w1MnLo1Nh4se8k9cuPSroJT3jTurFuNetrqxPsO8OG9Ur4G9nJl7nEQ/PFg11bhn9B/TlyHwnqa9SrSDOO4L3/nQsD/4y+aaq0Up6It2i1y3Io2/7prRq5Fx27Gsb3TJKZa6vTLVlhGUEpsFX2VeTRhvdChuFtXTq2KIBs8cPdZy+dUB5uDHhgSCaaK08auqVSwbx9e0n0allg6Df49oTe8VsqiwOF3uf5vZvE9gyq2Wj2C1KQr34uwFcd1KvuKaN91IZ7y53u4f7ly4ODuS/OKIDR3Zuzu+PC28A4Ft3v07N6NWmMTeefFCNHsQymKiZMbcM6NKC4qLqeoyzjuzAiD5tgloWppInA8HkKwfz2qVHRZ1GAm4pF9w6wt8cL7CZ58fXBBdzjOlXXWzSt31TzjwivofXju0euzWAm4fg1cN7suDWEVEv8jeM7M2McUNo38y5VZCTVFRihQq98Mco+mVagq2NEjWoa81v00PrCALdMvogbj2lD0N7V1e4h17I/mS3qgnd7W/axYpgVcpffkKCLzOJ8TPGe0FN9BmaSC3QfEJbFzVvWJc3/3A0bZtWz+dLm2+XNqhbwAdXH8dhHZ2fw7n/rEOZdGV43VTgNvqO61j1DG7794XFQS0LU8mTRUN92jVh7377ubUIV1jfSVplDM0aVOfETjq4+knDwCKIRbefSIO6BUH1CfGYe/PwGC2RIp901TmVhFZJXp4EbZOTgvw8ihIstz9/YCfrheQB72N1W+DeiOeOoGthI/LzhMqq6oKKq4f3dHxheW0LLL8O1bBeAb89NnpT12tPtHL6h7RvFvQ+7WSbesYSustX3H0yn64opWXD4IxFomXnh7Rvytqte/j94C41LgePejg4jDs7xoN8xkC3woZcenzXoFZUucaTgSAevorUeF8Y3aBuQY0eaIn0AFgop4u976BPRSdUNdGjTWNXKgMh+IQOLNoIveuIp2godIrQJnup9NivDo9YdxKY2UjGFUO7M7xPa0Y/Oiup5cTL6Tgf2tu9nGu/js2TXp7j+ZLA/MF1BMKNJ2f/k9jRaCCI4LTD2rP+5z1Bj4ZH49JDjWGi1hGkpCFZ5gks2gjdH4nUEfguDsmUYB3aoSlfO7xsPJJTDm0XcZxEqSxORH6euNKENN54NKx38PMhmXQUZlrmKFt4so4gUKQDJj9PuGJoDxpGqWD0nQAN6+anvHw82mGdha+drrGgoiHiC8ChF4fB3WM/mBbYdjzQxBjPOiQiL0plsZNaqIKx1hNjfEF+nv95jcwTpSi1BvvPK6eWZwOBGydVbVSORi3yjFLZmO0i3e2E3gF0a90o5rIO79Q8aN6mDeoEVcI6OfHgA+2nvMMrMJ2e8K0JX+XoEWnqcTIZqboDdotz0ZA7ic7F882zgcAnmR/1gDr5tGxYlzvGRO9C2BVRniPwktDY26ZJfVbfMyrqPE+PLWbiFccEdYcR74Vs4hXHMvnKwUHD/uDQ/UhN9D6wCdPHDeGy49xZXm1KpEiuNlXf/cX2/G9jvxU32t1ahu6CGvFsIHAjd5CfJ8z7ywh+EaEYwQ3x3HXkYnlopM0O3B++kzQvxlW9cf06HBrWjXf0eXxPOrdoWDeoozCobq3jhi6tGsZMf23xdeE8oEv0fnkA/+47tEPTWn/IMpo69r502qWBx9STFxzp2I119bSZ8ZvUFq0szhJOl3pftwVHd0tdr4SZxq3TM9a1t3tIkdN1J/Xiw8U/ubT2mqmTn8dtp/ZhxaadKWnKeEz3VnG3+vJlpAKbU2eCa07shcF62CxUaP1SPHIvi+XM84Eg03/oaNerolYNmT1+KG0jdKmQzSJtd7QiiUTK7iMtZvhBbfh46caw4Zef0D3xB7NSIN5WbKlW/TBcZp1BTQ+oE7Go9owj2vOfL36Iazneuh/wcCDItju/SOdbIk/+5oJIv9vnNw6lfgI9w0YKKFcM7c5TDr1BOjkwBwNwvKL1k+S2l38/kE07ymNPGMNfT+vL6tJdfLZqS8oqfE89rB3vLkzZa9dTxrOBIFtkW8BKtUgX8MBuBuLx22O78P43NS/qef2yo2L2V5XLarPFmltFn/l5knh/Uwlu3yPn9OOBs2v3dbhuyJxanjTJtFvbSHKxQjiaSJV1QV3OJ7FL+he1cCwPz48z8vYvahFXt8y5yvcAW++27nXtXbunYvSV1TQDlpcnUV/hmqk8e0eQLRltrzw9HK9UtuYY0aeNv6tjFd3IvgcyfdyQGr1HIpZU3gUnumyvZMA8GwhS5Y4xB3NAnP0TxaNrYUMa1M3n2hHuNVnMBpHO11SGxauG9fBcs8FkpCII1JZYdx9eOwo8HwjcjvcXHlXk6vIa1itgif0KSRVSNOTyr5clpYQZ7/2rBruaGXJTonfYXjkmsq8wyyWa88tOqXyi1SvFAKl2UNsmCXdhXlt6trGeD4nV66/Xrg+eDQQ+Xon42Sbik8Uur+fja46nfh3PnwaeceWwHrx26VFBbwOLxivXh6TOABFpISIficgK+79j71kiMtaeZoWIjA0YPkNElonIAvsvek9gLvJWvM8dwV1MJL+87q0b0aN1Y9eWpzJbQX5efF1oeEyyWaHxwFRjTA9gqv09iIi0AG4DBgIDgNtCAsb5xph+9t+m0PmVN8XTfNS9dVn/NQ44S8W7njOd1zKKyf7CY4Ah9ufngRnADSHTnAR8ZIzZCiAiHwEjgf8muW7lQanon81rJ30i3r78GNo19e7zEl7JHCQbCNoYYzYAGGM2RCjaaQ+sDfi+zh7m86yIVAJvAneZCE94icglwCUAnTol3+GWx+qC0uqhcw6jjUsPXwW2+nD7JM2WhwtrU78IL33PdV67PsQMBCLyMeDUxeDNca7DaZf6zrjzjTHrRaQxViC4AHjBaSHGmCeBJwGKi4v1jM0iZxzuXjfdeamo1/XaWa/i5pXMQcxAYIwZHmmciGwUkbb23UBbwKmMfx3VxUcAHbCKkDDGrLf/l4nIy1h1CI6BQClIzZPWviV645RX8fFW5iDZ/NVEwNcKaCzwjsM0HwAnikhzu5L4ROADESkQkVYAIlIHOAX4Jsn0xM1r7YRzRXBfQ+5cunP5lZ8qOU6HRC4eJ8kGggnACBFZAYywvyMixSLyFIBdSXwnMNf+u8MeVg8rIHwNLADWA/9OMj0Ji/VgicosqQ3gOXiGZ5FMusB6LZ+YVGWxMWYLMMxheAlwccD3Z4BnQqbZBRyZzPqT9eh5h3NEJ29WhmWrwFZDzRrUdWWZHjvnM57+HrXPew2EA5x2WLt0J0ElyHeR6NexGf93/hGuLjuTcqQqM3jlmNBn61VW8RUNXTCoM61dekOYb5keOedVHLx2V6KBQGWVVDwF7LWTXiXCG9kDDQQqq/iaj1a5eM/uazBQLwvfLKVSQyuLlcpgeSlo9H/vWYcypFchh3bQhgMqmNYRKJWBfDk1N+8ImtSvwzn9k++2ROUOr70iVgOByip5WrGrlOs0EKiskoo7AqVCXTmsB51aNODobq3SnZRaoXUEKqv4m3pqHFAp1KddEz65/oR0J6PWaCBQGeuPQ7oxtHdwz+b+umKNBEq5RgOByljXj+wdNqyu3cRTOw1Uyj0aCFRWuXpETwTh7GL33nGgMoPRJgBpo4FAZZUm9etw66l90p0MlUJ6s1f7tNWQUkp5nAYCpZTyOA0ESinlcRoIlFKqBnKpLkMDgVJKeZwGAqWU8jgNBEop5XEaCJRSyuM0ECillMdpIFBKKY/TQKCUUh6XVF9DItICeBUoAtYAvzTG/Oww3RRgEDDLGHNKwPAuwCtAC2A+cIExZl8yaaoNs8cPZXd5RbqToVROaVDXuhwV5Gn+tLYlu8fHA1ONMT2AqfZ3J/cDFzgMvxd4yJ7/Z+B3SaanVrRvdgA92jROdzKUyim3n3owVw/vGfYOCpV6yQaCMcDz9ufngdOdJjLGTAXKAoeJ1aH8UOCNWPMrpXJf0wZ1uGp4D/LycuiR3SyRbCBoY4zZAGD/TySUtwS2GWN8ZSzrgPaRJhaRS0SkRERKSktLa5xgpZRSwWLWEYjIx8CBDqNuTnLdTmE/4pspjDFPAk8CFBcX6xsslFLKJTEDgTFmeKRxIrJRRNoaYzaISFtgUwLr3gw0E5EC+66gA/BjAvMrpZRyQbJFQxOBsfbnscA78c5orLePTwfOqsn8Siml3JFsIJgAjBCRFcAI+zsiUiwiT/kmEpFPgdeBYSKyTkROskfdAFwjIiux6gyeTjI9SimlEpTUcwTGmC3AMIfhJcDFAd8HR5h/NTAgmTQopZRKjj65oZRSCbBKtXOLBgKllKoByaFXlGkgUEopj9NAoJRSHqeBQCmlPC6pVkNKqcwx7drjWb9tT7qTobKQBgKlckTXwkZ0LWyU7mSoLKSBQCmPO65nIR2bH5DuZKg00kCglMe98Ft9ptPrtLJYKaU8TgOBUkp5nAYCpZTyOA0ESinlcRoIlFLK4zQQKKWUx2kgUEopj9NAoJRSHqeBQCmlPE4DgVJKeZwGAqWUSsAfT+gOQMuGddOcEvdoX0NKKZWAXw/qzK8HdU53MlyldwRKKeVxGgiUUsrjNBAopZTHJRUIRKSFiHwkIivs/80jTDdFRLaJyHshw58Tke9EZIH91y+Z9CillEpcsncE44GpxpgewFT7u5P7gQsijLvOGNPP/luQZHqUUkolKNlAMAZ43v78PHC600TGmKlAWZLrUkoplQLJBoI2xpgNAPb/1jVYxt0i8rWIPCQi9SJNJCKXiEiJiJSUlpbWNL1KKaVCxAwEIvKxiHzj8DfGhfXfCPQG+gMtgBsiTWiMedIYU2yMKS4sLHRh1UoppSCOB8qMMcMjjRORjSLS1hizQUTaApsSWbnvbgIoF5FngXGJzK+UUip5yRYNTQTG2p/HAu8kMrMdPBARwapf+CbJ9CillEpQsoFgAjBCRFYAI+zviEixiDzlm0hEPgVeB4aJyDoROcke9ZKILAIWAa2Au5JMj1JKqQQl1deQMWYLMMxheAlwccD3wRHmH5rM+pVSSiVPnyxWSimP00CglFIep4FAKaU8TgOBUkp5nAYCpZTyOA0ESinlcRoIlFLK4zQQKKWUx2kgUEopj9NAoJRSHqeBQCmlPE4DgVJKeZwGAqWU8jgNBEop5XEaCJRSyuOSeh+BUio7PPeb/uwqr0x3MlSG0kCglAcM6dU63UlQGUyLhpRSyuM0ECillMdpIFBKKY/TQKCUUh6ngUAppTxOA4FSSnmcBgKllPI4DQRKKeVxYoxJdxoSJiKlwPdJLKIVsNml5GSiXN4+3bbslcvbly3b1tkYUxg6MCsDQbJEpMQYU5zudKRKLm+fblv2yuXty/Zt06IhpZTyOA0ESinlcV4NBE+mOwEplsvbp9uWvXJ5+7J62zxZR6CUUqqaV+8IlFJK2TQQKKWUx+VEIBCRjiIyXUSWishiEbnKHt5CRD4SkRX2/+b2cBGRR0VkpYh8LSJHhCyviYisF5HH0rE9odzcPhHpJCIf2staIiJF6dkqf3rc3Lb77GUstaeRdG2XnZ5Et623iHwuIuUiMi5kWSNFZJm93ePTsT2h3Nq+SMtJJzd/O3t8voh8JSLv1fa2xMUYk/V/QFvgCPtzY2A50Ae4DxhvDx8P3Gt/HgW8DwgwCPgyZHmPAC8Dj6V729zePmAGMML+3AhokAvbBhwNzAby7b/PgSFZtm2tgf7A3cC4gOXkA6uArkBdYCHQJwuPy0jb57icXNi2gOVdY19T3kv37+b0lxN3BMaYDcaY+fbnMmAp0B4YAzxvT/Y8cLr9eQzwgrF8ATQTkbYAInIk0Ab4sBY3ISq3tk9E+gAFxpiP7GXtNMbsrs1tCeXib2eA+lgXynpAHWBjrW2Ig0S3zRizyRgzF9gfsqgBwEpjzGpjzD7gFXsZaeXW9kVZTtq4+NshIh2A0cBTtZD0GsmJQBDILuo4HPgSaGOM2QDWD4sVtcH6QdcGzLYOaC8iecADwHW1ld5EJbN9QE9gm4i8Zd+m3i8i+bWV9liS2TZjzOfAdGCD/feBMWZp7aQ8tji3LZJIv2fGSHL7Ii0nI7iwbQ8D1wNVKUpi0nIqEIhII+BN4M/GmB3RJnUYZoA/ApONMWsdxqedC9tXAAwGxmHdxnYFLnI5mTWS7LaJSHfgIKAD1kVyqIgc535KE5fAtkVchMOwjGn37cL2ubocNyWbJhE5BdhkjJnneuJclDOBQETqYP1gLxlj3rIHbwwo8mkLbLKHrwM6BszeAfgROAq4QkTWAH8HLhSRCbWQ/Jhc2r51wFd2EUMF8DYQVFGeDi5t2xnAF3Zx106seoRBtZH+aBLctkgibXPaubR9kZaTVi5t2zHAafY15RWsDMp/UpTkGsuJQGC3DnkaWGqMeTBg1ERgrP15LPBOwPAL7RYog4Dtdpng+caYTsaYIqxc8wvGmLS30HBr+4C5QHMR8fU+OBRYkvINiMLFbfsBOF5ECuwT+Hisct20qcG2RTIX6CEiXUSkLnCuvYy0cmv7oiwnbdzaNmPMjcaYDvY15VxgmjHm1ylIcnLSUUPt9h9wLNat8tfAAvtvFNASmAqssP+3sKcX4HGslhiLgGKHZV5E5rQacm37gBH2chYBzwF1c2HbsFrW/Avr4r8EeDALf7cDsXL/O4Bt9ucm9rhRWC1XVgE3p3vb3Ny+SMvJhW0LWeYQMrTVkHYxoZRSHpcTRUNKKaVqTgOBUkp5nAYCpZTyOA0ESinlcRoIlFLK4zQQKKWUx2kgUEopj/t/bzvYjA5gYckAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 69s 42ms/step - loss: 2.3155e-04 - val_loss: 1.9291e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 1.2480e-04 - val_loss: 2.0754e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.1408e-04 - val_loss: 1.8770e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 253us/step - loss: 1.1289e-04 - val_loss: 1.9130e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 221us/step - loss: 1.1206e-04 - val_loss: 1.9040e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 1.1150e-04 - val_loss: 1.9136e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.1136e-04 - val_loss: 1.9032e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 238us/step - loss: 1.1058e-04 - val_loss: 1.9034e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.0988e-04 - val_loss: 1.8935e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 1.0931e-04 - val_loss: 1.8990e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 1.0887e-04 - val_loss: 1.8967e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 1.0812e-04 - val_loss: 1.8915e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 1.0724e-04 - val_loss: 1.8987e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 199us/step - loss: 1.0693e-04 - val_loss: 1.8730e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.0575e-04 - val_loss: 1.9211e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 212us/step - loss: 1.0501e-04 - val_loss: 1.8627e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 200us/step - loss: 1.0402e-04 - val_loss: 1.9047e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.0278e-04 - val_loss: 1.8741e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 216us/step - loss: 1.0166e-04 - val_loss: 1.8974e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 1.0096e-04 - val_loss: 1.9243e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 9.9324e-05 - val_loss: 1.8786e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 9.7475e-05 - val_loss: 1.8708e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 205us/step - loss: 9.5662e-05 - val_loss: 1.8845e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 216us/step - loss: 9.4247e-05 - val_loss: 1.8987e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 274us/step - loss: 9.2657e-05 - val_loss: 1.8566e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 67s 40ms/step - loss: 2.3139e-04 - val_loss: 2.1138e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 209us/step - loss: 1.2984e-04 - val_loss: 1.9760e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 208us/step - loss: 1.1926e-04 - val_loss: 1.8903e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 212us/step - loss: 1.1760e-04 - val_loss: 1.9379e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 205us/step - loss: 1.1682e-04 - val_loss: 1.9169e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 202us/step - loss: 1.1606e-04 - val_loss: 1.9236e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 198us/step - loss: 1.1577e-04 - val_loss: 1.9128e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 188us/step - loss: 1.1503e-04 - val_loss: 1.9183e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.1450e-04 - val_loss: 1.9216e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 205us/step - loss: 1.1397e-04 - val_loss: 1.8989e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 208us/step - loss: 1.1305e-04 - val_loss: 1.9121e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 189us/step - loss: 1.1213e-04 - val_loss: 1.9113e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.1119e-04 - val_loss: 1.9287e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 1.1012e-04 - val_loss: 1.9047e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 207us/step - loss: 1.0837e-04 - val_loss: 1.8746e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 1.0722e-04 - val_loss: 1.9000e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 201us/step - loss: 1.0494e-04 - val_loss: 1.9136e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.0315e-04 - val_loss: 1.8742e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 210us/step - loss: 1.0013e-04 - val_loss: 1.8565e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 204us/step - loss: 9.6860e-05 - val_loss: 1.8751e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 194us/step - loss: 9.4069e-05 - val_loss: 1.9043e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 199us/step - loss: 9.0998e-05 - val_loss: 1.8820e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 224us/step - loss: 8.7350e-05 - val_loss: 1.8860e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 8.3045e-05 - val_loss: 1.8780e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 7.9405e-05 - val_loss: 1.8806e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 73s 45ms/step - loss: 2.0646e-04 - val_loss: 2.5233e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 264us/step - loss: 1.2586e-04 - val_loss: 1.8789e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 255us/step - loss: 1.1625e-04 - val_loss: 1.9587e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 257us/step - loss: 1.1325e-04 - val_loss: 1.9042e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 267us/step - loss: 1.1173e-04 - val_loss: 1.8922e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 272us/step - loss: 1.1006e-04 - val_loss: 1.8988e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 267us/step - loss: 1.0834e-04 - val_loss: 1.9075e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.0590e-04 - val_loss: 1.9087e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 1.0345e-04 - val_loss: 1.9036e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 270us/step - loss: 1.0051e-04 - val_loss: 1.9694e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 266us/step - loss: 9.7595e-05 - val_loss: 1.8538e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 259us/step - loss: 9.2886e-05 - val_loss: 1.8469e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 278us/step - loss: 8.8750e-05 - val_loss: 1.8506e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 8.4715e-05 - val_loss: 1.8453e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 8.1139e-05 - val_loss: 1.8519e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 7.5825e-05 - val_loss: 1.8593e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 7.2256e-05 - val_loss: 1.8834e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 6.9758e-05 - val_loss: 1.8911e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 246us/step - loss: 6.7667e-05 - val_loss: 1.9116e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 6.6448e-05 - val_loss: 1.9575e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 6.5667e-05 - val_loss: 1.9462e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 6.4789e-05 - val_loss: 1.9598e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 247us/step - loss: 6.4737e-05 - val_loss: 1.9863e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.4435e-05 - val_loss: 1.9739e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 220us/step - loss: 6.4546e-05 - val_loss: 1.9757e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 70s 43ms/step - loss: 2.0732e-04 - val_loss: 2.4847e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 249us/step - loss: 1.2712e-04 - val_loss: 1.8811e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 1.1872e-04 - val_loss: 1.9462e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 281us/step - loss: 1.1564e-04 - val_loss: 1.9161e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 238us/step - loss: 1.1424e-04 - val_loss: 1.9015e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.1289e-04 - val_loss: 1.8949e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 232us/step - loss: 1.1105e-04 - val_loss: 1.9201e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.0917e-04 - val_loss: 1.9148e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 1.0682e-04 - val_loss: 1.8801e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.0372e-04 - val_loss: 1.9490e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.0135e-04 - val_loss: 1.8652e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 9.7410e-05 - val_loss: 1.9033e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 9.3978e-05 - val_loss: 1.9302e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 9.0649e-05 - val_loss: 1.9150e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 8.5425e-05 - val_loss: 1.8738e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 238us/step - loss: 8.1319e-05 - val_loss: 1.8753e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 247us/step - loss: 7.6514e-05 - val_loss: 1.8988e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 223us/step - loss: 7.3052e-05 - val_loss: 1.9316e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.9695e-05 - val_loss: 1.9192e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 6.8141e-05 - val_loss: 1.9400e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 6.7203e-05 - val_loss: 1.9572e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 6.5323e-05 - val_loss: 1.9971e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 6.4669e-05 - val_loss: 1.9882e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.4794e-05 - val_loss: 2.0006e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 226us/step - loss: 6.4964e-05 - val_loss: 2.0313e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 76s 46ms/step - loss: 2.5187e-04 - val_loss: 1.9263e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.2588e-04 - val_loss: 2.0795e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 1.1584e-04 - val_loss: 1.8834e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 226us/step - loss: 1.1684e-04 - val_loss: 1.9248e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 1.1526e-04 - val_loss: 1.9176e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 1.1442e-04 - val_loss: 1.9109e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 220us/step - loss: 1.1408e-04 - val_loss: 1.9155e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.1303e-04 - val_loss: 1.8933e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 223us/step - loss: 1.1238e-04 - val_loss: 1.9091e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 1.1151e-04 - val_loss: 1.9061e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 1.1043e-04 - val_loss: 1.9052e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 1.0947e-04 - val_loss: 1.8971e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 211us/step - loss: 1.0834e-04 - val_loss: 1.9041e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.0741e-04 - val_loss: 1.8891e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 1.0569e-04 - val_loss: 1.8989e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 219us/step - loss: 1.0428e-04 - val_loss: 1.8709e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 256us/step - loss: 1.0250e-04 - val_loss: 1.8942e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 1.0052e-04 - val_loss: 1.8706e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 264us/step - loss: 9.8402e-05 - val_loss: 1.8840e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 9.6116e-05 - val_loss: 1.8773e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 278us/step - loss: 9.3468e-05 - val_loss: 1.8654e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 9.0873e-05 - val_loss: 1.8739e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 8.8472e-05 - val_loss: 1.8532e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 8.4938e-05 - val_loss: 1.8539e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 8.3013e-05 - val_loss: 1.8553e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 72s 44ms/step - loss: 2.0943e-04 - val_loss: 2.3285e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 1.2829e-04 - val_loss: 1.8897e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 1.1639e-04 - val_loss: 1.9084e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 1.1302e-04 - val_loss: 1.9127e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 211us/step - loss: 1.1192e-04 - val_loss: 1.9096e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 1.1062e-04 - val_loss: 1.9023e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.0921e-04 - val_loss: 1.8956e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.0790e-04 - val_loss: 1.9115e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.0619e-04 - val_loss: 1.8632e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 235us/step - loss: 1.0444e-04 - val_loss: 1.9037e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 219us/step - loss: 1.0169e-04 - val_loss: 1.8899e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 212us/step - loss: 9.9198e-05 - val_loss: 1.8717e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 9.6215e-05 - val_loss: 1.8744e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 9.3146e-05 - val_loss: 1.8633e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 8.9541e-05 - val_loss: 1.8446e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 213us/step - loss: 8.6093e-05 - val_loss: 1.8457e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 8.2368e-05 - val_loss: 1.8977e-04\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 0s 237us/step - loss: 7.8987e-05 - val_loss: 1.8806e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 7.5262e-05 - val_loss: 1.8651e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 212us/step - loss: 7.2428e-05 - val_loss: 1.8834e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 213us/step - loss: 6.9624e-05 - val_loss: 1.8754e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 223us/step - loss: 6.8398e-05 - val_loss: 1.9018e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 6.8064e-05 - val_loss: 1.9071e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 218us/step - loss: 6.4983e-05 - val_loss: 1.9191e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 6.5147e-05 - val_loss: 1.9467e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 75s 46ms/step - loss: 1.9931e-04 - val_loss: 2.4768e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.2425e-04 - val_loss: 1.8751e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 1.1451e-04 - val_loss: 1.9837e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 1.1213e-04 - val_loss: 1.8805e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 1.1010e-04 - val_loss: 1.9187e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 270us/step - loss: 1.0869e-04 - val_loss: 1.9163e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 264us/step - loss: 1.0658e-04 - val_loss: 1.8797e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 1.0409e-04 - val_loss: 1.8909e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 1.0142e-04 - val_loss: 1.8628e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 273us/step - loss: 9.8381e-05 - val_loss: 1.8551e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 9.4910e-05 - val_loss: 1.8877e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 9.0153e-05 - val_loss: 1.8529e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 8.6119e-05 - val_loss: 1.8494e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 8.1499e-05 - val_loss: 1.8609e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 7.6642e-05 - val_loss: 1.8775e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 7.2575e-05 - val_loss: 1.9208e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 6.9516e-05 - val_loss: 1.9494e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 235us/step - loss: 6.8543e-05 - val_loss: 1.9540e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 6.6070e-05 - val_loss: 1.9859e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.6950e-05 - val_loss: 2.0184e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.6049e-05 - val_loss: 2.0130e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.4996e-05 - val_loss: 2.0205e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 6.5122e-05 - val_loss: 2.0390e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 221us/step - loss: 6.6119e-05 - val_loss: 2.0086e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 238us/step - loss: 6.4738e-05 - val_loss: 2.0596e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 75s 46ms/step - loss: 2.0185e-04 - val_loss: 2.4227e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 202us/step - loss: 1.2317e-04 - val_loss: 1.8742e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 199us/step - loss: 1.1537e-04 - val_loss: 1.9205e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 186us/step - loss: 1.1282e-04 - val_loss: 1.9255e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 192us/step - loss: 1.1143e-04 - val_loss: 1.8967e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 200us/step - loss: 1.0946e-04 - val_loss: 1.9299e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 196us/step - loss: 1.0785e-04 - val_loss: 1.9180e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 202us/step - loss: 1.0424e-04 - val_loss: 1.8715e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 189us/step - loss: 1.0140e-04 - val_loss: 1.8969e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 191us/step - loss: 9.7115e-05 - val_loss: 1.8730e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 188us/step - loss: 9.1982e-05 - val_loss: 1.8672e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 191us/step - loss: 8.6925e-05 - val_loss: 1.8634e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 189us/step - loss: 8.1568e-05 - val_loss: 1.8744e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 189us/step - loss: 7.6143e-05 - val_loss: 1.8761e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 196us/step - loss: 7.1654e-05 - val_loss: 1.9149e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 191us/step - loss: 6.8716e-05 - val_loss: 1.9316e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 189us/step - loss: 6.7127e-05 - val_loss: 1.9670e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 196us/step - loss: 6.5328e-05 - val_loss: 2.0145e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 191us/step - loss: 6.4528e-05 - val_loss: 1.9981e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 191us/step - loss: 6.4846e-05 - val_loss: 2.0097e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 6.5545e-05 - val_loss: 2.0591e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 213us/step - loss: 6.6185e-05 - val_loss: 2.0237e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 220us/step - loss: 6.4906e-05 - val_loss: 1.9979e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 199us/step - loss: 6.4438e-05 - val_loss: 2.0226e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 198us/step - loss: 6.4607e-05 - val_loss: 2.0147e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 79s 48ms/step - loss: 2.7608e-04 - val_loss: 1.8959e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 1.2115e-04 - val_loss: 2.1358e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 226us/step - loss: 1.2150e-04 - val_loss: 1.9184e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.1750e-04 - val_loss: 1.9024e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 1.1714e-04 - val_loss: 1.9350e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 264us/step - loss: 1.1713e-04 - val_loss: 1.9202e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 269us/step - loss: 1.1706e-04 - val_loss: 1.9232e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 262us/step - loss: 1.1695e-04 - val_loss: 1.9224e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 258us/step - loss: 1.1695e-04 - val_loss: 1.9239e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 271us/step - loss: 1.1690e-04 - val_loss: 1.9147e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.1669e-04 - val_loss: 1.9205e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 1.1656e-04 - val_loss: 1.9118e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.1643e-04 - val_loss: 1.9219e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 223us/step - loss: 1.1624e-04 - val_loss: 1.9136e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 260us/step - loss: 1.1606e-04 - val_loss: 1.9089e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 256us/step - loss: 1.1587e-04 - val_loss: 1.9142e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 1.1545e-04 - val_loss: 1.9252e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 285us/step - loss: 1.1499e-04 - val_loss: 1.9098e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 1.1445e-04 - val_loss: 1.9190e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 1.1445e-04 - val_loss: 1.9403e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 232us/step - loss: 1.1359e-04 - val_loss: 1.9186e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 1.1228e-04 - val_loss: 1.8961e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.1121e-04 - val_loss: 1.9194e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 253us/step - loss: 1.0972e-04 - val_loss: 1.9050e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 1.0801e-04 - val_loss: 1.8956e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 79s 48ms/step - loss: 2.0665e-04 - val_loss: 2.4608e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 226us/step - loss: 1.2706e-04 - val_loss: 1.8732e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 1.1474e-04 - val_loss: 1.9585e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 208us/step - loss: 1.1219e-04 - val_loss: 1.8820e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 1.1074e-04 - val_loss: 1.9061e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 203us/step - loss: 1.0888e-04 - val_loss: 1.8946e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 207us/step - loss: 1.0725e-04 - val_loss: 1.8775e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 200us/step - loss: 1.0519e-04 - val_loss: 1.8828e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 204us/step - loss: 1.0261e-04 - val_loss: 1.8669e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 219us/step - loss: 9.9792e-05 - val_loss: 1.8895e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 9.6688e-05 - val_loss: 1.8624e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 232us/step - loss: 9.4044e-05 - val_loss: 1.8574e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 223us/step - loss: 8.9647e-05 - val_loss: 1.8641e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 8.4980e-05 - val_loss: 1.8630e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 8.1187e-05 - val_loss: 1.8606e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 7.6997e-05 - val_loss: 1.9156e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 210us/step - loss: 7.3085e-05 - val_loss: 1.8917e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 7.0057e-05 - val_loss: 1.9185e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.7525e-05 - val_loss: 1.9571e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 204us/step - loss: 6.6379e-05 - val_loss: 1.9630e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 216us/step - loss: 6.5219e-05 - val_loss: 1.9812e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 206us/step - loss: 6.4957e-05 - val_loss: 1.9932e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 219us/step - loss: 6.4836e-05 - val_loss: 2.0037e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 221us/step - loss: 6.4447e-05 - val_loss: 2.0242e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 210us/step - loss: 6.5702e-05 - val_loss: 2.0097e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 82s 50ms/step - loss: 1.9213e-04 - val_loss: 2.5404e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 235us/step - loss: 1.2749e-04 - val_loss: 1.8746e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 253us/step - loss: 1.1472e-04 - val_loss: 1.9478e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.1232e-04 - val_loss: 1.9083e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 1.1067e-04 - val_loss: 1.9034e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 1.0832e-04 - val_loss: 1.9160e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 267us/step - loss: 1.0617e-04 - val_loss: 1.8705e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.0392e-04 - val_loss: 1.8524e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 1.0086e-04 - val_loss: 1.9141e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 9.6184e-05 - val_loss: 1.9313e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 227us/step - loss: 9.2659e-05 - val_loss: 1.8857e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 8.8943e-05 - val_loss: 1.8807e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 229us/step - loss: 8.2134e-05 - val_loss: 1.9097e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 7.7990e-05 - val_loss: 1.8789e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 7.4037e-05 - val_loss: 1.8955e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 7.0893e-05 - val_loss: 1.9246e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 263us/step - loss: 6.8307e-05 - val_loss: 1.9728e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 248us/step - loss: 6.7350e-05 - val_loss: 2.0047e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 257us/step - loss: 6.5451e-05 - val_loss: 2.0069e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 254us/step - loss: 6.5524e-05 - val_loss: 2.0061e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 6.4693e-05 - val_loss: 2.0162e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 6.5058e-05 - val_loss: 2.0223e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 235us/step - loss: 6.5393e-05 - val_loss: 2.0289e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 6.6568e-05 - val_loss: 2.0137e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 6.7068e-05 - val_loss: 2.0152e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 79s 48ms/step - loss: 2.0488e-04 - val_loss: 2.5290e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 209us/step - loss: 1.2671e-04 - val_loss: 1.8777e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 210us/step - loss: 1.1782e-04 - val_loss: 1.9404e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 213us/step - loss: 1.1468e-04 - val_loss: 1.9312e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 1.1307e-04 - val_loss: 1.8776e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 235us/step - loss: 1.1007e-04 - val_loss: 1.9540e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.0886e-04 - val_loss: 1.8729e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 1.0476e-04 - val_loss: 1.8633e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 1.0045e-04 - val_loss: 1.8616e-04\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1647/1647 [==============================] - 0s 230us/step - loss: 9.6168e-05 - val_loss: 1.8473e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 9.0666e-05 - val_loss: 1.8578e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 8.4028e-05 - val_loss: 1.8885e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 7.8392e-05 - val_loss: 1.8767e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 214us/step - loss: 7.2898e-05 - val_loss: 1.9082e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 246us/step - loss: 6.8297e-05 - val_loss: 1.9397e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 6.8059e-05 - val_loss: 2.0021e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 248us/step - loss: 6.6626e-05 - val_loss: 2.0009e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 257us/step - loss: 6.5056e-05 - val_loss: 2.0198e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 6.5003e-05 - val_loss: 2.0297e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 6.5756e-05 - val_loss: 2.0321e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 6.7149e-05 - val_loss: 2.0071e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 6.6005e-05 - val_loss: 2.0127e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 220us/step - loss: 6.4809e-05 - val_loss: 2.0405e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 210us/step - loss: 6.5471e-05 - val_loss: 2.0470e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 6.6259e-05 - val_loss: 2.0195e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 84s 51ms/step - loss: 2.1050e-04 - val_loss: 2.3066e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 261us/step - loss: 1.2947e-04 - val_loss: 1.8862e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 267us/step - loss: 1.1360e-04 - val_loss: 1.9068e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.1102e-04 - val_loss: 1.9080e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 1.0959e-04 - val_loss: 1.9066e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 1.0798e-04 - val_loss: 1.8864e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 1.0626e-04 - val_loss: 1.9082e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.0464e-04 - val_loss: 1.8851e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.0251e-04 - val_loss: 1.8869e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.0023e-04 - val_loss: 1.8798e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 9.8216e-05 - val_loss: 1.8784e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 9.5190e-05 - val_loss: 1.8711e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 9.2372e-05 - val_loss: 1.8809e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 8.9334e-05 - val_loss: 1.8711e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 8.6112e-05 - val_loss: 1.8718e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 8.3528e-05 - val_loss: 1.9419e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 8.0135e-05 - val_loss: 1.8980e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 7.7099e-05 - val_loss: 1.8805e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 7.3616e-05 - val_loss: 1.9001e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 7.1086e-05 - val_loss: 1.8948e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.9186e-05 - val_loss: 1.9137e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.7322e-05 - val_loss: 1.9333e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 246us/step - loss: 6.6135e-05 - val_loss: 1.9455e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 6.5810e-05 - val_loss: 1.9645e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 6.6042e-05 - val_loss: 1.9796e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 85s 51ms/step - loss: 2.2819e-04 - val_loss: 2.2172e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.3007e-04 - val_loss: 1.9014e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 1.1784e-04 - val_loss: 1.9036e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 1.1494e-04 - val_loss: 1.9160e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 1.1337e-04 - val_loss: 1.9084e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 258us/step - loss: 1.1258e-04 - val_loss: 1.9010e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 257us/step - loss: 1.1140e-04 - val_loss: 1.9224e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 1.0959e-04 - val_loss: 1.8948e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 230us/step - loss: 1.0789e-04 - val_loss: 1.9054e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 1.0701e-04 - val_loss: 1.8637e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 222us/step - loss: 1.0431e-04 - val_loss: 1.8876e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 1.0164e-04 - val_loss: 1.8882e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 231us/step - loss: 9.8580e-05 - val_loss: 1.8713e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 9.5276e-05 - val_loss: 1.8653e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 216us/step - loss: 9.1509e-05 - val_loss: 1.8755e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 221us/step - loss: 8.8495e-05 - val_loss: 1.8443e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 216us/step - loss: 8.3006e-05 - val_loss: 1.8787e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 217us/step - loss: 7.8747e-05 - val_loss: 1.9230e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 218us/step - loss: 7.4965e-05 - val_loss: 1.8912e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 225us/step - loss: 7.0932e-05 - val_loss: 1.9247e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 6.9978e-05 - val_loss: 1.9221e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 273us/step - loss: 6.7208e-05 - val_loss: 1.9414e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 228us/step - loss: 6.5486e-05 - val_loss: 1.9643e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 253us/step - loss: 6.5291e-05 - val_loss: 1.9831e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 6.4824e-05 - val_loss: 1.9908e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 88s 54ms/step - loss: 2.0848e-04 - val_loss: 2.4284e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 1.2411e-04 - val_loss: 1.8760e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 1.1681e-04 - val_loss: 1.9162e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 1.1340e-04 - val_loss: 1.9245e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 259us/step - loss: 1.1067e-04 - val_loss: 1.9371e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.0778e-04 - val_loss: 1.9092e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 246us/step - loss: 1.0376e-04 - val_loss: 1.8944e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 9.7676e-05 - val_loss: 1.9028e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 289us/step - loss: 9.1972e-05 - val_loss: 1.8967e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 1s 329us/step - loss: 8.4938e-05 - val_loss: 1.8997e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 254us/step - loss: 7.8354e-05 - val_loss: 1.8845e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 251us/step - loss: 7.2304e-05 - val_loss: 1.9084e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 247us/step - loss: 6.8340e-05 - val_loss: 1.9462e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 6.5855e-05 - val_loss: 1.9820e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 254us/step - loss: 6.4931e-05 - val_loss: 1.9957e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 259us/step - loss: 6.5185e-05 - val_loss: 2.0466e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 262us/step - loss: 6.5660e-05 - val_loss: 2.0069e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 6.5103e-05 - val_loss: 2.0101e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 6.5000e-05 - val_loss: 2.0517e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 6.6283e-05 - val_loss: 2.0343e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 6.6170e-05 - val_loss: 2.0555e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 245us/step - loss: 6.4989e-05 - val_loss: 1.9997e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 6.4191e-05 - val_loss: 2.0077e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 6.4734e-05 - val_loss: 1.9948e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 250us/step - loss: 6.4813e-05 - val_loss: 1.9971e-04\n",
      "Train on 1647 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1647/1647 [==============================] - 88s 54ms/step - loss: 1.9271e-04 - val_loss: 2.4199e-04\n",
      "Epoch 2/25\n",
      "1647/1647 [==============================] - 0s 253us/step - loss: 1.2252e-04 - val_loss: 1.8742e-04\n",
      "Epoch 3/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 1.1424e-04 - val_loss: 1.9118e-04\n",
      "Epoch 4/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 1.1119e-04 - val_loss: 1.8915e-04\n",
      "Epoch 5/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 1.0836e-04 - val_loss: 1.8838e-04\n",
      "Epoch 6/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 1.0475e-04 - val_loss: 1.9105e-04\n",
      "Epoch 7/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 1.0030e-04 - val_loss: 1.8501e-04\n",
      "Epoch 8/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 9.4773e-05 - val_loss: 1.8716e-04\n",
      "Epoch 9/25\n",
      "1647/1647 [==============================] - 0s 242us/step - loss: 8.8963e-05 - val_loss: 1.8837e-04\n",
      "Epoch 10/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 8.2002e-05 - val_loss: 1.8783e-04\n",
      "Epoch 11/25\n",
      "1647/1647 [==============================] - 0s 233us/step - loss: 7.5597e-05 - val_loss: 1.8728e-04\n",
      "Epoch 12/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 7.0481e-05 - val_loss: 1.9031e-04\n",
      "Epoch 13/25\n",
      "1647/1647 [==============================] - 0s 244us/step - loss: 6.7994e-05 - val_loss: 1.9676e-04\n",
      "Epoch 14/25\n",
      "1647/1647 [==============================] - 0s 234us/step - loss: 6.5846e-05 - val_loss: 1.9660e-04\n",
      "Epoch 15/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.4697e-05 - val_loss: 1.9889e-04\n",
      "Epoch 16/25\n",
      "1647/1647 [==============================] - 0s 241us/step - loss: 6.4444e-05 - val_loss: 1.9969e-04\n",
      "Epoch 17/25\n",
      "1647/1647 [==============================] - 0s 243us/step - loss: 6.4436e-05 - val_loss: 1.9984e-04\n",
      "Epoch 18/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.4432e-05 - val_loss: 2.0217e-04\n",
      "Epoch 19/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 6.5002e-05 - val_loss: 1.9976e-04\n",
      "Epoch 20/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 6.4737e-05 - val_loss: 1.9919e-04\n",
      "Epoch 21/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 6.4483e-05 - val_loss: 2.0005e-04\n",
      "Epoch 22/25\n",
      "1647/1647 [==============================] - 0s 236us/step - loss: 6.6254e-05 - val_loss: 2.0478e-04\n",
      "Epoch 23/25\n",
      "1647/1647 [==============================] - 0s 237us/step - loss: 6.4424e-05 - val_loss: 1.9990e-04\n",
      "Epoch 24/25\n",
      "1647/1647 [==============================] - 0s 240us/step - loss: 6.4270e-05 - val_loss: 2.0116e-04\n",
      "Epoch 25/25\n",
      "1647/1647 [==============================] - 0s 239us/step - loss: 6.4604e-05 - val_loss: 1.9802e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 87s 53ms/step - loss: 1.7834e-04 - val_loss: 2.3948e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 1.1486e-04 - val_loss: 1.8556e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 1.0670e-04 - val_loss: 1.9156e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 387us/step - loss: 1.0313e-04 - val_loss: 1.8774e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 335us/step - loss: 1.0219e-04 - val_loss: 1.8881e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 1.0089e-04 - val_loss: 1.9012e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 317us/step - loss: 9.9023e-05 - val_loss: 1.8566e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 9.8085e-05 - val_loss: 1.9119e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 9.5909e-05 - val_loss: 1.8562e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 9.4241e-05 - val_loss: 1.8508e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 9.2454e-05 - val_loss: 1.8665e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 9.0096e-05 - val_loss: 1.8830e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 8.8109e-05 - val_loss: 1.8659e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 8.5625e-05 - val_loss: 1.8545e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 323us/step - loss: 8.3251e-05 - val_loss: 1.9110e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 8.1889e-05 - val_loss: 1.9263e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 327us/step - loss: 7.9381e-05 - val_loss: 1.8746e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 7.7050e-05 - val_loss: 1.8837e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 7.4281e-05 - val_loss: 1.8908e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 7.2344e-05 - val_loss: 1.8923e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 7.1062e-05 - val_loss: 1.9150e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 7.0945e-05 - val_loss: 1.9148e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 292us/step - loss: 6.9072e-05 - val_loss: 1.9277e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 6.7665e-05 - val_loss: 1.9406e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 6.7771e-05 - val_loss: 1.9586e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 89s 54ms/step - loss: 2.1180e-04 - val_loss: 2.3411e-04\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 295us/step - loss: 1.3014e-04 - val_loss: 1.8872e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 293us/step - loss: 1.1698e-04 - val_loss: 1.9219e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 1.1517e-04 - val_loss: 1.9036e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 270us/step - loss: 1.1336e-04 - val_loss: 1.9153e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 283us/step - loss: 1.1260e-04 - val_loss: 1.8953e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 1.1144e-04 - val_loss: 1.8900e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 1.1015e-04 - val_loss: 1.8958e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 285us/step - loss: 1.0826e-04 - val_loss: 1.8868e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 1.0650e-04 - val_loss: 1.8865e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 1.0444e-04 - val_loss: 1.9431e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 270us/step - loss: 1.0189e-04 - val_loss: 1.8672e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 286us/step - loss: 9.8414e-05 - val_loss: 1.8840e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 283us/step - loss: 9.5415e-05 - val_loss: 1.8452e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 9.1113e-05 - val_loss: 1.8411e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 8.8292e-05 - val_loss: 1.8351e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 8.2192e-05 - val_loss: 1.8666e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 7.7306e-05 - val_loss: 1.8523e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 280us/step - loss: 7.3020e-05 - val_loss: 1.8929e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 6.9860e-05 - val_loss: 1.9258e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 313us/step - loss: 6.8459e-05 - val_loss: 1.9078e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.7269e-05 - val_loss: 1.9257e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 6.7539e-05 - val_loss: 1.9359e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 272us/step - loss: 6.6553e-05 - val_loss: 1.9409e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 267us/step - loss: 6.6842e-05 - val_loss: 1.9347e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 90s 55ms/step - loss: 1.7859e-04 - val_loss: 2.1185e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 1.1093e-04 - val_loss: 1.8835e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 1.0596e-04 - val_loss: 1.8884e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 1.0408e-04 - val_loss: 1.9008e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 1.0150e-04 - val_loss: 1.9026e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 9.8950e-05 - val_loss: 1.8518e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 9.6348e-05 - val_loss: 1.8478e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 9.2336e-05 - val_loss: 1.8525e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 8.8254e-05 - val_loss: 1.8372e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 8.3975e-05 - val_loss: 1.8405e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 8.0190e-05 - val_loss: 1.8463e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 296us/step - loss: 7.5860e-05 - val_loss: 1.8552e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 7.2723e-05 - val_loss: 1.8721e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 7.0782e-05 - val_loss: 1.8991e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.7844e-05 - val_loss: 1.9102e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 6.6774e-05 - val_loss: 1.9305e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 293us/step - loss: 6.6787e-05 - val_loss: 1.9975e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 6.5728e-05 - val_loss: 2.0003e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.6937e-05 - val_loss: 1.9495e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 292us/step - loss: 6.5461e-05 - val_loss: 1.9637e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.5387e-05 - val_loss: 1.9603e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.5287e-05 - val_loss: 1.9628e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 6.5962e-05 - val_loss: 2.0016e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 6.6306e-05 - val_loss: 1.9506e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 6.6832e-05 - val_loss: 1.9905e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 91s 55ms/step - loss: 2.0161e-04 - val_loss: 2.0381e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 337us/step - loss: 1.2323e-04 - val_loss: 1.9737e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 343us/step - loss: 1.1838e-04 - val_loss: 1.8769e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 332us/step - loss: 1.1504e-04 - val_loss: 1.9213e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 1.1298e-04 - val_loss: 1.8972e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 322us/step - loss: 1.0948e-04 - val_loss: 1.8632e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 1.0469e-04 - val_loss: 1.8621e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 325us/step - loss: 9.9954e-05 - val_loss: 1.8455e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 345us/step - loss: 9.5225e-05 - val_loss: 1.8385e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 329us/step - loss: 8.7781e-05 - val_loss: 1.8643e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 328us/step - loss: 8.0520e-05 - val_loss: 1.8725e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 7.4159e-05 - val_loss: 1.8729e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 7.0296e-05 - val_loss: 1.9050e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.6951e-05 - val_loss: 1.9319e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.6846e-05 - val_loss: 1.9592e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.5830e-05 - val_loss: 1.9672e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 6.5836e-05 - val_loss: 1.9690e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 322us/step - loss: 6.6094e-05 - val_loss: 1.9608e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 6.5641e-05 - val_loss: 1.9679e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 6.5409e-05 - val_loss: 1.9627e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 323us/step - loss: 6.6533e-05 - val_loss: 1.9936e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 346us/step - loss: 6.5945e-05 - val_loss: 1.9623e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 338us/step - loss: 6.6984e-05 - val_loss: 1.9881e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.7683e-05 - val_loss: 1.9580e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 6.6017e-05 - val_loss: 1.9592e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 93s 56ms/step - loss: 2.2500e-04 - val_loss: 2.0296e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 1.2323e-04 - val_loss: 1.9700e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 284us/step - loss: 1.1237e-04 - val_loss: 1.8745e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 274us/step - loss: 1.1190e-04 - val_loss: 1.9294e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 1.1050e-04 - val_loss: 1.8949e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 302us/step - loss: 1.0930e-04 - val_loss: 1.9046e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 1.0820e-04 - val_loss: 1.8935e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 1.0699e-04 - val_loss: 1.8977e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 274us/step - loss: 1.0569e-04 - val_loss: 1.8734e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 283us/step - loss: 1.0441e-04 - val_loss: 1.8689e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 1.0220e-04 - val_loss: 1.9031e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 280us/step - loss: 1.0064e-04 - val_loss: 1.8578e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 292us/step - loss: 9.8612e-05 - val_loss: 1.8576e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 273us/step - loss: 9.5730e-05 - val_loss: 1.8932e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 9.2855e-05 - val_loss: 1.8556e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 9.0054e-05 - val_loss: 1.8374e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 8.6841e-05 - val_loss: 1.8443e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 287us/step - loss: 8.2846e-05 - val_loss: 1.8514e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 7.9252e-05 - val_loss: 1.8469e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 284us/step - loss: 7.5874e-05 - val_loss: 1.8478e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 272us/step - loss: 7.3979e-05 - val_loss: 1.8574e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.9954e-05 - val_loss: 1.8672e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.8319e-05 - val_loss: 1.8874e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 279us/step - loss: 6.6815e-05 - val_loss: 1.9115e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.6357e-05 - val_loss: 1.9213e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 94s 57ms/step - loss: 1.8544e-04 - val_loss: 2.2845e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 1.0806e-04 - val_loss: 1.8524e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 1.0354e-04 - val_loss: 1.9028e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 1.0036e-04 - val_loss: 1.8817e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 9.8221e-05 - val_loss: 1.8486e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 9.5308e-05 - val_loss: 1.8929e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 9.2243e-05 - val_loss: 1.8510e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 8.8751e-05 - val_loss: 1.8746e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 8.5209e-05 - val_loss: 1.8873e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 8.2284e-05 - val_loss: 1.8600e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 7.8830e-05 - val_loss: 1.9219e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 7.6218e-05 - val_loss: 1.9239e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 7.2820e-05 - val_loss: 1.8577e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.9137e-05 - val_loss: 1.8709e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.7013e-05 - val_loss: 1.8912e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.7229e-05 - val_loss: 1.8963e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.6155e-05 - val_loss: 1.9138e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.5302e-05 - val_loss: 1.9183e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.5354e-05 - val_loss: 1.9208e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 6.5854e-05 - val_loss: 1.9228e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.5301e-05 - val_loss: 1.9228e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.5132e-05 - val_loss: 1.9465e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.6036e-05 - val_loss: 1.9353e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.5834e-05 - val_loss: 1.9453e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.6253e-05 - val_loss: 1.9281e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 95s 58ms/step - loss: 1.9608e-04 - val_loss: 2.1067e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 329us/step - loss: 1.2248e-04 - val_loss: 1.9515e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 329us/step - loss: 1.1275e-04 - val_loss: 1.8816e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 330us/step - loss: 1.0791e-04 - val_loss: 1.8902e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 1.0392e-04 - val_loss: 1.8686e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 322us/step - loss: 9.9885e-05 - val_loss: 1.8499e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 331us/step - loss: 9.4748e-05 - val_loss: 1.8391e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 339us/step - loss: 8.9079e-05 - val_loss: 1.8368e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 8.3096e-05 - val_loss: 1.8583e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 324us/step - loss: 7.7323e-05 - val_loss: 1.8575e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 328us/step - loss: 7.2021e-05 - val_loss: 1.8707e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 322us/step - loss: 6.8481e-05 - val_loss: 1.8873e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 338us/step - loss: 6.6802e-05 - val_loss: 1.8989e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 337us/step - loss: 6.6879e-05 - val_loss: 1.9700e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 329us/step - loss: 7.0423e-05 - val_loss: 1.9134e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 325us/step - loss: 6.7231e-05 - val_loss: 1.9142e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 321us/step - loss: 6.5434e-05 - val_loss: 1.9271e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.5378e-05 - val_loss: 1.9286e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 335us/step - loss: 6.5463e-05 - val_loss: 1.9270e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 333us/step - loss: 6.5285e-05 - val_loss: 1.9317e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 342us/step - loss: 6.8136e-05 - val_loss: 1.9287e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 342us/step - loss: 6.7476e-05 - val_loss: 1.9625e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 345us/step - loss: 6.6692e-05 - val_loss: 2.0241e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.8308e-05 - val_loss: 1.9269e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 6.5286e-05 - val_loss: 1.9329e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 95s 58ms/step - loss: 1.9159e-04 - val_loss: 1.9905e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 1.1851e-04 - val_loss: 1.9790e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 302us/step - loss: 1.1232e-04 - val_loss: 1.8658e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 1.0884e-04 - val_loss: 1.9300e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 1.0542e-04 - val_loss: 1.9079e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 323us/step - loss: 1.0112e-04 - val_loss: 1.8819e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 9.6529e-05 - val_loss: 1.8721e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 313us/step - loss: 9.0375e-05 - val_loss: 1.9546e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 8.6568e-05 - val_loss: 1.8791e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 7.8845e-05 - val_loss: 1.8781e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 7.5050e-05 - val_loss: 1.8966e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 302us/step - loss: 6.9929e-05 - val_loss: 1.9733e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 6.9082e-05 - val_loss: 1.9865e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.8867e-05 - val_loss: 1.9849e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 321us/step - loss: 6.8594e-05 - val_loss: 1.9812e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.8097e-05 - val_loss: 2.0473e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.7717e-05 - val_loss: 1.9872e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 6.6315e-05 - val_loss: 1.9916e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 6.5973e-05 - val_loss: 2.0088e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 6.7112e-05 - val_loss: 1.9923e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.7248e-05 - val_loss: 1.9868e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 6.6350e-05 - val_loss: 1.9764e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 6.5531e-05 - val_loss: 1.9790e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 317us/step - loss: 6.5694e-05 - val_loss: 1.9812e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.5926e-05 - val_loss: 1.9955e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 105s 64ms/step - loss: 1.8963e-04 - val_loss: 2.3004e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 287us/step - loss: 1.1559e-04 - val_loss: 1.8591e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 291us/step - loss: 1.0430e-04 - val_loss: 1.8756e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 9.9967e-05 - val_loss: 1.8910e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 286us/step - loss: 9.7322e-05 - val_loss: 1.8844e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 9.3405e-05 - val_loss: 1.8779e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 9.0233e-05 - val_loss: 1.8798e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 292us/step - loss: 8.6724e-05 - val_loss: 1.8771e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 292us/step - loss: 8.3311e-05 - val_loss: 1.8555e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 8.0181e-05 - val_loss: 1.8539e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 7.7958e-05 - val_loss: 1.8599e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 7.5278e-05 - val_loss: 1.8729e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 7.2571e-05 - val_loss: 1.8809e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 7.0685e-05 - val_loss: 1.8952e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 6.9640e-05 - val_loss: 1.9151e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.9754e-05 - val_loss: 1.9227e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.7593e-05 - val_loss: 1.9441e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 6.6292e-05 - val_loss: 1.9474e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 6.6157e-05 - val_loss: 1.9825e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.6140e-05 - val_loss: 1.9667e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.6508e-05 - val_loss: 2.0019e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.6197e-05 - val_loss: 1.9732e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.5829e-05 - val_loss: 1.9887e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 6.6186e-05 - val_loss: 1.9732e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 296us/step - loss: 6.5405e-05 - val_loss: 1.9728e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 97s 59ms/step - loss: 2.4051e-04 - val_loss: 2.2358e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 288us/step - loss: 1.3493e-04 - val_loss: 1.9569e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 1.2205e-04 - val_loss: 1.8910e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 287us/step - loss: 1.1582e-04 - val_loss: 1.9661e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 1.1111e-04 - val_loss: 1.8889e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 1.0582e-04 - val_loss: 1.9183e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 1.0083e-04 - val_loss: 1.9174e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 9.6183e-05 - val_loss: 1.9621e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 313us/step - loss: 9.3200e-05 - val_loss: 1.9782e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 8.6611e-05 - val_loss: 1.8716e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 8.1158e-05 - val_loss: 1.8808e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 7.6442e-05 - val_loss: 1.8586e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 7.1882e-05 - val_loss: 1.8784e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 7.0732e-05 - val_loss: 1.9038e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.8576e-05 - val_loss: 1.9493e-04\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.7492e-05 - val_loss: 1.9412e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 6.6210e-05 - val_loss: 1.9913e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.7670e-05 - val_loss: 1.9451e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 6.5834e-05 - val_loss: 1.9484e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 349us/step - loss: 6.6262e-05 - val_loss: 1.9527e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 348us/step - loss: 6.6165e-05 - val_loss: 1.9536e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 340us/step - loss: 6.5312e-05 - val_loss: 1.9617e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 349us/step - loss: 6.5679e-05 - val_loss: 1.9523e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 346us/step - loss: 6.5425e-05 - val_loss: 1.9571e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 331us/step - loss: 6.5544e-05 - val_loss: 1.9551e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 105s 64ms/step - loss: 1.9245e-04 - val_loss: 2.0230e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 1.1843e-04 - val_loss: 1.9530e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 1.1194e-04 - val_loss: 1.8913e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 1.0753e-04 - val_loss: 1.8704e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 1.0454e-04 - val_loss: 1.8556e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 316us/step - loss: 1.0026e-04 - val_loss: 1.8493e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 9.5643e-05 - val_loss: 1.8531e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 9.0253e-05 - val_loss: 1.8435e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 8.3275e-05 - val_loss: 1.8526e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 7.7340e-05 - val_loss: 1.8531e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 7.2756e-05 - val_loss: 1.9332e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 6.9731e-05 - val_loss: 1.8967e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.6768e-05 - val_loss: 1.9255e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.5491e-05 - val_loss: 1.9392e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 6.5532e-05 - val_loss: 1.9463e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 6.6650e-05 - val_loss: 1.9659e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 6.6605e-05 - val_loss: 1.9521e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.6834e-05 - val_loss: 1.9433e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 321us/step - loss: 6.6258e-05 - val_loss: 1.9471e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 331us/step - loss: 6.5312e-05 - val_loss: 1.9439e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 6.6159e-05 - val_loss: 1.9519e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 311us/step - loss: 6.5450e-05 - val_loss: 1.9459e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 322us/step - loss: 6.7182e-05 - val_loss: 1.9507e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.5184e-05 - val_loss: 1.9422e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 324us/step - loss: 6.5818e-05 - val_loss: 1.9425e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 100s 61ms/step - loss: 1.9090e-04 - val_loss: 1.8706e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 335us/step - loss: 1.1634e-04 - val_loss: 2.0251e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 334us/step - loss: 1.0899e-04 - val_loss: 1.8766e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 354us/step - loss: 1.0344e-04 - val_loss: 1.8473e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 331us/step - loss: 9.8080e-05 - val_loss: 1.8528e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 317us/step - loss: 8.9910e-05 - val_loss: 1.8545e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 323us/step - loss: 8.3044e-05 - val_loss: 1.8471e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 324us/step - loss: 7.5665e-05 - val_loss: 1.8624e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 6.9910e-05 - val_loss: 1.9035e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 6.7049e-05 - val_loss: 1.9215e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 328us/step - loss: 6.6096e-05 - val_loss: 1.9504e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 333us/step - loss: 6.6043e-05 - val_loss: 1.9699e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 337us/step - loss: 6.7041e-05 - val_loss: 1.9783e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 6.7275e-05 - val_loss: 1.9705e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 6.5523e-05 - val_loss: 1.9402e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 326us/step - loss: 6.6388e-05 - val_loss: 1.9798e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 336us/step - loss: 6.5915e-05 - val_loss: 1.9388e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 6.6298e-05 - val_loss: 1.9468e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 334us/step - loss: 6.5187e-05 - val_loss: 1.9701e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 335us/step - loss: 6.5675e-05 - val_loss: 1.9500e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 1s 323us/step - loss: 6.5251e-05 - val_loss: 1.9462e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 6.6268e-05 - val_loss: 1.9422e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 324us/step - loss: 6.6971e-05 - val_loss: 2.0426e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 341us/step - loss: 6.6458e-05 - val_loss: 1.9486e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 335us/step - loss: 6.6049e-05 - val_loss: 1.9333e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 107s 65ms/step - loss: 1.9125e-04 - val_loss: 2.0180e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 1.1132e-04 - val_loss: 1.9115e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 1.0272e-04 - val_loss: 1.8520e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 9.8364e-05 - val_loss: 1.8693e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 9.4205e-05 - val_loss: 1.8439e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 8.9634e-05 - val_loss: 1.8488e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 290us/step - loss: 8.5563e-05 - val_loss: 1.8414e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 8.1837e-05 - val_loss: 1.8721e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 289us/step - loss: 7.7459e-05 - val_loss: 1.8728e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 283us/step - loss: 7.4133e-05 - val_loss: 1.8653e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 7.1275e-05 - val_loss: 1.8876e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 288us/step - loss: 6.8978e-05 - val_loss: 1.9010e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 286us/step - loss: 6.7653e-05 - val_loss: 1.9238e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 6.6515e-05 - val_loss: 1.9262e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.5819e-05 - val_loss: 1.9402e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.6166e-05 - val_loss: 1.9604e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.6419e-05 - val_loss: 1.9546e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.6190e-05 - val_loss: 1.9557e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 294us/step - loss: 6.5579e-05 - val_loss: 1.9521e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 6.5491e-05 - val_loss: 1.9584e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 300us/step - loss: 6.6224e-05 - val_loss: 1.9821e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - ETA: 0s - loss: 6.3437e-0 - 1s 308us/step - loss: 6.6756e-05 - val_loss: 1.9581e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 6.5779e-05 - val_loss: 1.9536e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.5614e-05 - val_loss: 1.9487e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 6.5556e-05 - val_loss: 1.9559e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 106s 65ms/step - loss: 2.0051e-04 - val_loss: 2.4979e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 1.2267e-04 - val_loss: 1.8721e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 314us/step - loss: 1.1119e-04 - val_loss: 1.9512e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 1.0868e-04 - val_loss: 1.8708e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 1.0507e-04 - val_loss: 1.8848e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 295us/step - loss: 1.0101e-04 - val_loss: 1.8816e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 9.6804e-05 - val_loss: 1.8919e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 317us/step - loss: 9.2287e-05 - val_loss: 1.8888e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 320us/step - loss: 8.6731e-05 - val_loss: 1.8608e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 8.0943e-05 - val_loss: 1.8469e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 7.6895e-05 - val_loss: 1.8495e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 7.2943e-05 - val_loss: 1.8672e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 6.9553e-05 - val_loss: 1.9418e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.8184e-05 - val_loss: 1.9481e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 1s 325us/step - loss: 6.6211e-05 - val_loss: 1.9275e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 6.6352e-05 - val_loss: 1.9457e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 1s 319us/step - loss: 6.6295e-05 - val_loss: 1.9593e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.6446e-05 - val_loss: 1.9398e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 1s 318us/step - loss: 6.5643e-05 - val_loss: 1.9446e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 297us/step - loss: 6.6384e-05 - val_loss: 1.9513e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.5738e-05 - val_loss: 1.9670e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.5809e-05 - val_loss: 2.0026e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 312us/step - loss: 6.5896e-05 - val_loss: 1.9438e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.5566e-05 - val_loss: 1.9394e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 313us/step - loss: 6.5327e-05 - val_loss: 1.9874e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 112s 68ms/step - loss: 2.0233e-04 - val_loss: 2.0956e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 1.1641e-04 - val_loss: 1.8953e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 1.1114e-04 - val_loss: 1.8732e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 1s 310us/step - loss: 1.0671e-04 - val_loss: 1.9137e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 1.0250e-04 - val_loss: 1.8639e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 9.7324e-05 - val_loss: 1.8500e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 9.1013e-05 - val_loss: 1.9005e-04\n",
      "Epoch 8/25\n",
      "1646/1646 [==============================] - 1s 306us/step - loss: 8.5072e-05 - val_loss: 1.8867e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 7.7579e-05 - val_loss: 1.8576e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 1s 317us/step - loss: 7.1658e-05 - val_loss: 1.8656e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 6.7502e-05 - val_loss: 1.9412e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 1s 304us/step - loss: 6.7065e-05 - val_loss: 1.9112e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 1s 309us/step - loss: 6.5618e-05 - val_loss: 1.9339e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 6.5650e-05 - val_loss: 1.9312e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 303us/step - loss: 6.5307e-05 - val_loss: 1.9450e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 6.5680e-05 - val_loss: 1.9393e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 302us/step - loss: 6.6498e-05 - val_loss: 1.9318e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 6.5822e-05 - val_loss: 1.9413e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 299us/step - loss: 6.7562e-05 - val_loss: 1.9269e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 1s 315us/step - loss: 7.0449e-05 - val_loss: 1.9183e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 298us/step - loss: 6.5901e-05 - val_loss: 1.9252e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 301us/step - loss: 6.5392e-05 - val_loss: 1.9451e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 1s 305us/step - loss: 6.5842e-05 - val_loss: 1.9836e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.7382e-05 - val_loss: 1.9310e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 307us/step - loss: 6.5775e-05 - val_loss: 1.9340e-04\n",
      "Train on 1646 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1646/1646 [==============================] - 111s 68ms/step - loss: 1.9488e-04 - val_loss: 1.8781e-04\n",
      "Epoch 2/25\n",
      "1646/1646 [==============================] - 0s 275us/step - loss: 1.2517e-04 - val_loss: 2.1292e-04\n",
      "Epoch 3/25\n",
      "1646/1646 [==============================] - 0s 267us/step - loss: 1.1131e-04 - val_loss: 1.8889e-04\n",
      "Epoch 4/25\n",
      "1646/1646 [==============================] - 0s 261us/step - loss: 1.0415e-04 - val_loss: 1.8933e-04\n",
      "Epoch 5/25\n",
      "1646/1646 [==============================] - 0s 258us/step - loss: 9.8640e-05 - val_loss: 1.8543e-04\n",
      "Epoch 6/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 9.1784e-05 - val_loss: 1.8572e-04\n",
      "Epoch 7/25\n",
      "1646/1646 [==============================] - 0s 264us/step - loss: 8.4549e-05 - val_loss: 1.8427e-04\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646/1646 [==============================] - 0s 261us/step - loss: 7.6027e-05 - val_loss: 1.8704e-04\n",
      "Epoch 9/25\n",
      "1646/1646 [==============================] - 0s 261us/step - loss: 6.9631e-05 - val_loss: 1.8874e-04\n",
      "Epoch 10/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 6.7347e-05 - val_loss: 1.9373e-04\n",
      "Epoch 11/25\n",
      "1646/1646 [==============================] - 0s 268us/step - loss: 6.5960e-05 - val_loss: 1.9609e-04\n",
      "Epoch 12/25\n",
      "1646/1646 [==============================] - 0s 286us/step - loss: 6.7199e-05 - val_loss: 1.9641e-04\n",
      "Epoch 13/25\n",
      "1646/1646 [==============================] - 0s 273us/step - loss: 6.7435e-05 - val_loss: 1.9390e-04\n",
      "Epoch 14/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 6.6223e-05 - val_loss: 1.9457e-04\n",
      "Epoch 15/25\n",
      "1646/1646 [==============================] - 0s 264us/step - loss: 6.5888e-05 - val_loss: 1.9516e-04\n",
      "Epoch 16/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 6.6783e-05 - val_loss: 1.9564e-04\n",
      "Epoch 17/25\n",
      "1646/1646 [==============================] - 0s 258us/step - loss: 6.5309e-05 - val_loss: 1.9425e-04\n",
      "Epoch 18/25\n",
      "1646/1646 [==============================] - 0s 262us/step - loss: 6.6224e-05 - val_loss: 1.9567e-04\n",
      "Epoch 19/25\n",
      "1646/1646 [==============================] - 0s 260us/step - loss: 6.6520e-05 - val_loss: 1.9774e-04\n",
      "Epoch 20/25\n",
      "1646/1646 [==============================] - 0s 263us/step - loss: 6.8061e-05 - val_loss: 1.9827e-04\n",
      "Epoch 21/25\n",
      "1646/1646 [==============================] - 0s 258us/step - loss: 6.5419e-05 - val_loss: 1.9325e-04\n",
      "Epoch 22/25\n",
      "1646/1646 [==============================] - 0s 258us/step - loss: 6.5349e-05 - val_loss: 1.9421e-04\n",
      "Epoch 23/25\n",
      "1646/1646 [==============================] - 0s 273us/step - loss: 6.5769e-05 - val_loss: 1.9602e-04\n",
      "Epoch 24/25\n",
      "1646/1646 [==============================] - 0s 264us/step - loss: 6.6405e-05 - val_loss: 1.9936e-04\n",
      "Epoch 25/25\n",
      "1646/1646 [==============================] - 1s 308us/step - loss: 6.5501e-05 - val_loss: 1.9370e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 113s 69ms/step - loss: 2.6545e-04 - val_loss: 2.0050e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 1.3571e-04 - val_loss: 2.0841e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 359us/step - loss: 1.2401e-04 - val_loss: 1.9091e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 358us/step - loss: 1.2311e-04 - val_loss: 1.9610e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 1.2176e-04 - val_loss: 1.9355e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 364us/step - loss: 1.2108e-04 - val_loss: 1.9393e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 1.2014e-04 - val_loss: 1.9416e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 1.1934e-04 - val_loss: 1.9280e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 358us/step - loss: 1.1856e-04 - val_loss: 1.9297e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 359us/step - loss: 1.1798e-04 - val_loss: 1.9169e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 356us/step - loss: 1.1690e-04 - val_loss: 1.9295e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 358us/step - loss: 1.1590e-04 - val_loss: 1.9194e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 362us/step - loss: 1.1521e-04 - val_loss: 1.9085e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 380us/step - loss: 1.1409e-04 - val_loss: 1.9248e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 1.1345e-04 - val_loss: 1.8908e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 364us/step - loss: 1.1263e-04 - val_loss: 1.9344e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 354us/step - loss: 1.1084e-04 - val_loss: 1.9072e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 1.0926e-04 - val_loss: 1.8921e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 353us/step - loss: 1.0758e-04 - val_loss: 1.8966e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 1.0584e-04 - val_loss: 1.9011e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 359us/step - loss: 1.0345e-04 - val_loss: 1.8824e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 359us/step - loss: 1.0116e-04 - val_loss: 1.9106e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 356us/step - loss: 9.8451e-05 - val_loss: 1.8904e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 355us/step - loss: 9.4909e-05 - val_loss: 1.8550e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 9.1134e-05 - val_loss: 1.8665e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 112s 68ms/step - loss: 2.0337e-04 - val_loss: 2.3911e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 406us/step - loss: 1.2420e-04 - val_loss: 1.8796e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 1.1727e-04 - val_loss: 1.9234e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 1.1468e-04 - val_loss: 1.9296e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 383us/step - loss: 1.1298e-04 - val_loss: 1.9092e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 1.1116e-04 - val_loss: 1.8807e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 1.1010e-04 - val_loss: 1.9467e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 1.0714e-04 - val_loss: 1.8840e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 1.0527e-04 - val_loss: 1.8716e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 402us/step - loss: 1.0257e-04 - val_loss: 1.8595e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 376us/step - loss: 9.9376e-05 - val_loss: 1.8953e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 373us/step - loss: 9.6714e-05 - val_loss: 1.9258e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 9.4091e-05 - val_loss: 1.9388e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 376us/step - loss: 8.9109e-05 - val_loss: 1.8891e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 371us/step - loss: 8.4126e-05 - val_loss: 1.8329e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 8.0751e-05 - val_loss: 1.8508e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 7.6865e-05 - val_loss: 1.8859e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 379us/step - loss: 7.4210e-05 - val_loss: 1.8471e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 7.1972e-05 - val_loss: 1.8541e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 6.9444e-05 - val_loss: 1.8647e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 6.8007e-05 - val_loss: 1.8803e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 6.7374e-05 - val_loss: 1.8896e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 6.8289e-05 - val_loss: 1.9452e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 380us/step - loss: 6.9396e-05 - val_loss: 1.8905e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 6.7196e-05 - val_loss: 1.9042e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 118s 72ms/step - loss: 1.9005e-04 - val_loss: 1.9984e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 1.2000e-04 - val_loss: 2.0141e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 1.1822e-04 - val_loss: 1.8778e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 391us/step - loss: 1.1115e-04 - val_loss: 1.8765e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 1.0685e-04 - val_loss: 1.9302e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 421us/step - loss: 1.0351e-04 - val_loss: 1.8590e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 9.8633e-05 - val_loss: 1.8738e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 9.3436e-05 - val_loss: 1.8633e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 8.7418e-05 - val_loss: 1.8445e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 8.2186e-05 - val_loss: 1.8595e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 7.6337e-05 - val_loss: 1.9037e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 7.2141e-05 - val_loss: 1.8823e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 406us/step - loss: 6.8128e-05 - val_loss: 1.9027e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 391us/step - loss: 6.7108e-05 - val_loss: 1.9341e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 387us/step - loss: 6.7413e-05 - val_loss: 1.9391e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.6378e-05 - val_loss: 1.9432e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 6.6404e-05 - val_loss: 1.9480e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 404us/step - loss: 6.6142e-05 - val_loss: 1.9979e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 382us/step - loss: 6.6796e-05 - val_loss: 1.9567e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 6.6909e-05 - val_loss: 1.9633e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 388us/step - loss: 6.6916e-05 - val_loss: 2.0037e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 6.6709e-05 - val_loss: 1.9702e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 6.6589e-05 - val_loss: 1.9407e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 414us/step - loss: 6.6184e-05 - val_loss: 1.9374e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 6.6537e-05 - val_loss: 1.9391e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 118s 72ms/step - loss: 1.7387e-04 - val_loss: 1.8707e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 386us/step - loss: 1.1878e-04 - val_loss: 1.9636e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 1.1228e-04 - val_loss: 1.9953e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 1.1163e-04 - val_loss: 1.8662e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 391us/step - loss: 1.0731e-04 - val_loss: 1.8773e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 382us/step - loss: 1.0349e-04 - val_loss: 1.8958e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 9.8771e-05 - val_loss: 1.8615e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 9.2057e-05 - val_loss: 1.9522e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 8.6100e-05 - val_loss: 1.8471e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 386us/step - loss: 7.9905e-05 - val_loss: 1.8673e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 391us/step - loss: 7.1724e-05 - val_loss: 1.9497e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 7.0057e-05 - val_loss: 1.8993e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 408us/step - loss: 6.7772e-05 - val_loss: 1.9341e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 388us/step - loss: 6.6816e-05 - val_loss: 1.9588e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 6.7317e-05 - val_loss: 1.9289e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 6.6450e-05 - val_loss: 1.9356e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 6.6880e-05 - val_loss: 1.9438e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 386us/step - loss: 6.6565e-05 - val_loss: 1.9335e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 6.6424e-05 - val_loss: 1.9329e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 6.6667e-05 - val_loss: 1.9348e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 6.6535e-05 - val_loss: 1.9385e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 6.7761e-05 - val_loss: 1.9326e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 387us/step - loss: 6.9242e-05 - val_loss: 1.9979e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 388us/step - loss: 6.9693e-05 - val_loss: 1.9566e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.8120e-05 - val_loss: 1.9251e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 123s 75ms/step - loss: 2.1674e-04 - val_loss: 2.5497e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 1.2855e-04 - val_loss: 1.8864e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 1.1895e-04 - val_loss: 1.9493e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 379us/step - loss: 1.1291e-04 - val_loss: 1.8974e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 370us/step - loss: 1.0997e-04 - val_loss: 1.9066e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 1.0725e-04 - val_loss: 1.8980e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 367us/step - loss: 1.0425e-04 - val_loss: 1.8901e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 1.0021e-04 - val_loss: 1.8600e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 380us/step - loss: 9.6458e-05 - val_loss: 1.8656e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 360us/step - loss: 9.2179e-05 - val_loss: 1.8787e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 8.8484e-05 - val_loss: 1.8463e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 368us/step - loss: 8.5107e-05 - val_loss: 1.8493e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 8.1643e-05 - val_loss: 1.8506e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 374us/step - loss: 7.7280e-05 - val_loss: 1.8585e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 369us/step - loss: 7.3871e-05 - val_loss: 1.8758e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 368us/step - loss: 7.0936e-05 - val_loss: 1.8815e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 369us/step - loss: 6.9741e-05 - val_loss: 1.8833e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 366us/step - loss: 6.9161e-05 - val_loss: 1.8989e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 368us/step - loss: 6.7790e-05 - val_loss: 1.9216e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 370us/step - loss: 6.7444e-05 - val_loss: 1.9235e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 6.8147e-05 - val_loss: 1.9275e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 373us/step - loss: 6.8845e-05 - val_loss: 1.9622e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 380us/step - loss: 6.9143e-05 - val_loss: 1.9126e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 6.7411e-05 - val_loss: 1.9306e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 378us/step - loss: 6.8206e-05 - val_loss: 1.9445e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 124s 75ms/step - loss: 2.0999e-04 - val_loss: 2.2333e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 1.2373e-04 - val_loss: 1.8996e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 343us/step - loss: 1.1718e-04 - val_loss: 1.8777e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 345us/step - loss: 1.1359e-04 - val_loss: 1.9679e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 1.0984e-04 - val_loss: 1.8899e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 355us/step - loss: 1.0554e-04 - val_loss: 1.9164e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 353us/step - loss: 1.0156e-04 - val_loss: 1.8602e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 343us/step - loss: 9.7160e-05 - val_loss: 1.8702e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 9.1396e-05 - val_loss: 1.8595e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 8.4650e-05 - val_loss: 1.8997e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 7.9305e-05 - val_loss: 1.8744e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 353us/step - loss: 7.4819e-05 - val_loss: 1.8768e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 359us/step - loss: 7.1372e-05 - val_loss: 1.9138e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 348us/step - loss: 6.8356e-05 - val_loss: 1.9185e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 348us/step - loss: 6.6833e-05 - val_loss: 1.9343e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 6.9328e-05 - val_loss: 1.9431e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 347us/step - loss: 6.7139e-05 - val_loss: 1.9461e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 352us/step - loss: 6.6176e-05 - val_loss: 1.9473e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 350us/step - loss: 6.6154e-05 - val_loss: 1.9495e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 345us/step - loss: 6.6643e-05 - val_loss: 1.9846e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 351us/step - loss: 6.8501e-05 - val_loss: 1.9500e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 362us/step - loss: 6.7078e-05 - val_loss: 1.9502e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 348us/step - loss: 6.7873e-05 - val_loss: 1.9460e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 345us/step - loss: 6.6222e-05 - val_loss: 1.9488e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 353us/step - loss: 6.6817e-05 - val_loss: 1.9577e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 127s 77ms/step - loss: 2.0185e-04 - val_loss: 1.8836e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 411us/step - loss: 1.2493e-04 - val_loss: 2.1156e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 405us/step - loss: 1.1114e-04 - val_loss: 1.8818e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 413us/step - loss: 1.0338e-04 - val_loss: 1.8679e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 413us/step - loss: 9.6471e-05 - val_loss: 1.8728e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 440us/step - loss: 8.9371e-05 - val_loss: 1.8448e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 412us/step - loss: 8.4478e-05 - val_loss: 1.9536e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 413us/step - loss: 7.8127e-05 - val_loss: 1.8550e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 437us/step - loss: 7.1290e-05 - val_loss: 1.8589e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 419us/step - loss: 6.8500e-05 - val_loss: 1.8792e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 414us/step - loss: 6.6979e-05 - val_loss: 1.8928e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 424us/step - loss: 6.7805e-05 - val_loss: 1.9491e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 412us/step - loss: 6.8898e-05 - val_loss: 1.9188e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 407us/step - loss: 6.7628e-05 - val_loss: 1.9115e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 434us/step - loss: 6.6533e-05 - val_loss: 1.9050e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 409us/step - loss: 6.8569e-05 - val_loss: 1.9121e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 417us/step - loss: 6.7253e-05 - val_loss: 1.9127e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 415us/step - loss: 6.6826e-05 - val_loss: 1.9115e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 415us/step - loss: 6.6522e-05 - val_loss: 1.9271e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 421us/step - loss: 6.6761e-05 - val_loss: 1.9097e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 412us/step - loss: 6.7054e-05 - val_loss: 2.0198e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 431us/step - loss: 6.8538e-05 - val_loss: 1.9436e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 415us/step - loss: 6.8920e-05 - val_loss: 1.9253e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 400us/step - loss: 6.7330e-05 - val_loss: 1.9110e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 411us/step - loss: 6.6580e-05 - val_loss: 1.9263e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 129s 78ms/step - loss: 1.6820e-04 - val_loss: 1.8763e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 376us/step - loss: 1.1246e-04 - val_loss: 1.9622e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 408us/step - loss: 1.0098e-04 - val_loss: 1.8973e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 472us/step - loss: 9.5698e-05 - val_loss: 1.8445e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 382us/step - loss: 8.9711e-05 - val_loss: 1.8351e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 8.4288e-05 - val_loss: 1.8365e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 399us/step - loss: 7.6742e-05 - val_loss: 1.8501e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 7.0936e-05 - val_loss: 1.8657e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 374us/step - loss: 6.8294e-05 - val_loss: 1.9062e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 6.9564e-05 - val_loss: 1.9369e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 383us/step - loss: 6.6759e-05 - val_loss: 1.9156e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 388us/step - loss: 6.6319e-05 - val_loss: 2.0106e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.7625e-05 - val_loss: 1.9232e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 387us/step - loss: 6.6988e-05 - val_loss: 1.9215e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 381us/step - loss: 6.6239e-05 - val_loss: 1.9294e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 6.6754e-05 - val_loss: 1.9294e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 396us/step - loss: 6.7874e-05 - val_loss: 1.9952e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 6.8876e-05 - val_loss: 1.9228e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 386us/step - loss: 6.6883e-05 - val_loss: 1.9514e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 6.7102e-05 - val_loss: 1.9360e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 383us/step - loss: 6.5690e-05 - val_loss: 1.9631e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 394us/step - loss: 6.6412e-05 - val_loss: 1.9236e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 384us/step - loss: 6.6152e-05 - val_loss: 1.9269e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 380us/step - loss: 6.5713e-05 - val_loss: 1.9221e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 6.5899e-05 - val_loss: 1.9603e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 129s 78ms/step - loss: 2.1147e-04 - val_loss: 2.4968e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 386us/step - loss: 1.3276e-04 - val_loss: 1.8783e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 396us/step - loss: 1.1646e-04 - val_loss: 1.9335e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 399us/step - loss: 1.1306e-04 - val_loss: 1.8990e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 1.1078e-04 - val_loss: 1.9166e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 397us/step - loss: 1.0915e-04 - val_loss: 1.8765e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 404us/step - loss: 1.0652e-04 - val_loss: 1.8978e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 1.0347e-04 - val_loss: 1.8818e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 1.0020e-04 - val_loss: 1.8824e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 394us/step - loss: 9.6772e-05 - val_loss: 1.8691e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 9.2990e-05 - val_loss: 1.8818e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 395us/step - loss: 8.8998e-05 - val_loss: 1.9054e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 404us/step - loss: 8.4645e-05 - val_loss: 1.8476e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 388us/step - loss: 7.9935e-05 - val_loss: 1.8916e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 394us/step - loss: 7.5648e-05 - val_loss: 1.8749e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 7.2472e-05 - val_loss: 1.9197e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 392us/step - loss: 6.9838e-05 - val_loss: 1.9125e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 387us/step - loss: 6.7601e-05 - val_loss: 1.9178e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 385us/step - loss: 6.9702e-05 - val_loss: 1.9150e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 397us/step - loss: 6.8166e-05 - val_loss: 1.9302e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.7976e-05 - val_loss: 1.9188e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.7087e-05 - val_loss: 1.9260e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 389us/step - loss: 6.7522e-05 - val_loss: 1.9452e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 390us/step - loss: 6.6766e-05 - val_loss: 1.9308e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 387us/step - loss: 6.7190e-05 - val_loss: 1.9253e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 131s 79ms/step - loss: 1.4078e-04 - val_loss: 1.8762e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 409us/step - loss: 1.0270e-04 - val_loss: 1.9012e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 402us/step - loss: 9.0234e-05 - val_loss: 1.9775e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 397us/step - loss: 8.5568e-05 - val_loss: 1.8817e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 399us/step - loss: 7.9297e-05 - val_loss: 1.8426e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 400us/step - loss: 7.5104e-05 - val_loss: 1.8425e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 396us/step - loss: 7.1505e-05 - val_loss: 1.8869e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 399us/step - loss: 6.9318e-05 - val_loss: 1.8686e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 396us/step - loss: 6.7830e-05 - val_loss: 1.8801e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 399us/step - loss: 6.7365e-05 - val_loss: 1.8890e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 415us/step - loss: 6.7181e-05 - val_loss: 1.8963e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 393us/step - loss: 6.7135e-05 - val_loss: 1.9040e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 398us/step - loss: 6.7061e-05 - val_loss: 1.9002e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 404us/step - loss: 6.6820e-05 - val_loss: 1.9179e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 402us/step - loss: 6.7911e-05 - val_loss: 1.8965e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 413us/step - loss: 6.7439e-05 - val_loss: 1.9098e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 401us/step - loss: 6.7628e-05 - val_loss: 1.9025e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 426us/step - loss: 6.7241e-05 - val_loss: 1.9339e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 403us/step - loss: 6.7859e-05 - val_loss: 1.9128e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 406us/step - loss: 6.7368e-05 - val_loss: 1.9150e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 403us/step - loss: 6.6966e-05 - val_loss: 1.9102e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 396us/step - loss: 6.7274e-05 - val_loss: 1.9073e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 407us/step - loss: 6.7192e-05 - val_loss: 1.9071e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 402us/step - loss: 6.6765e-05 - val_loss: 1.9078e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 403us/step - loss: 6.7756e-05 - val_loss: 1.9271e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 130s 79ms/step - loss: 1.7239e-04 - val_loss: 1.8726e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 573us/step - loss: 1.1546e-04 - val_loss: 1.9551e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 571us/step - loss: 1.0678e-04 - val_loss: 1.9021e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 489us/step - loss: 1.0147e-04 - val_loss: 1.9396e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 465us/step - loss: 9.6666e-05 - val_loss: 1.9173e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 519us/step - loss: 8.8596e-05 - val_loss: 1.8905e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 490us/step - loss: 8.2726e-05 - val_loss: 1.9159e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 491us/step - loss: 7.4538e-05 - val_loss: 1.8557e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 483us/step - loss: 6.9004e-05 - val_loss: 1.9059e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 469us/step - loss: 6.9132e-05 - val_loss: 1.9123e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 475us/step - loss: 6.6385e-05 - val_loss: 1.9111e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 502us/step - loss: 6.7193e-05 - val_loss: 1.9158e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 510us/step - loss: 6.7433e-05 - val_loss: 1.9373e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 485us/step - loss: 6.6728e-05 - val_loss: 1.9116e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 503us/step - loss: 6.6363e-05 - val_loss: 1.9150e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 462us/step - loss: 6.6735e-05 - val_loss: 1.9148e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 484us/step - loss: 6.6682e-05 - val_loss: 1.9154e-04\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1645/1645 [==============================] - 1s 493us/step - loss: 6.6180e-05 - val_loss: 1.9243e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 502us/step - loss: 6.7260e-05 - val_loss: 1.9144e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 496us/step - loss: 6.7468e-05 - val_loss: 1.9126e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 487us/step - loss: 6.9501e-05 - val_loss: 1.9021e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 480us/step - loss: 6.9618e-05 - val_loss: 1.9105e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 486us/step - loss: 6.6624e-05 - val_loss: 1.9188e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 482us/step - loss: 6.6186e-05 - val_loss: 1.9146e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 491us/step - loss: 6.6332e-05 - val_loss: 1.9203e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 133s 81ms/step - loss: 1.8676e-04 - val_loss: 1.9071e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 477us/step - loss: 1.2227e-04 - val_loss: 2.0725e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 476us/step - loss: 1.0785e-04 - val_loss: 1.9047e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 485us/step - loss: 1.0117e-04 - val_loss: 1.8987e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 474us/step - loss: 9.3909e-05 - val_loss: 1.8921e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 497us/step - loss: 8.7184e-05 - val_loss: 1.8445e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 508us/step - loss: 7.8280e-05 - val_loss: 1.8491e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 478us/step - loss: 7.2771e-05 - val_loss: 1.8745e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 469us/step - loss: 6.7609e-05 - val_loss: 1.9378e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 489us/step - loss: 6.6724e-05 - val_loss: 1.9305e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 458us/step - loss: 6.6758e-05 - val_loss: 1.9490e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 479us/step - loss: 6.7531e-05 - val_loss: 1.9375e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 497us/step - loss: 6.6656e-05 - val_loss: 1.9643e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 492us/step - loss: 6.7932e-05 - val_loss: 1.9335e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 500us/step - loss: 6.6729e-05 - val_loss: 1.9303e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 488us/step - loss: 6.6950e-05 - val_loss: 1.9452e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 478us/step - loss: 6.7880e-05 - val_loss: 1.9279e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 467us/step - loss: 6.6655e-05 - val_loss: 1.9215e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 457us/step - loss: 6.6830e-05 - val_loss: 1.9352e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 493us/step - loss: 6.7515e-05 - val_loss: 1.9371e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 491us/step - loss: 6.6580e-05 - val_loss: 1.9334e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 467us/step - loss: 6.7153e-05 - val_loss: 1.9196e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 474us/step - loss: 6.7840e-05 - val_loss: 1.9232e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 474us/step - loss: 6.6134e-05 - val_loss: 1.9241e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 493us/step - loss: 6.6503e-05 - val_loss: 1.9321e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 131s 80ms/step - loss: 2.0409e-04 - val_loss: 2.4604e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 477us/step - loss: 1.2136e-04 - val_loss: 1.8687e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 465us/step - loss: 1.1097e-04 - val_loss: 1.9166e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 468us/step - loss: 1.0585e-04 - val_loss: 1.8967e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 469us/step - loss: 1.0258e-04 - val_loss: 1.8662e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 480us/step - loss: 9.8654e-05 - val_loss: 1.8612e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 467us/step - loss: 9.4711e-05 - val_loss: 1.8386e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 472us/step - loss: 9.0269e-05 - val_loss: 1.8410e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 482us/step - loss: 8.4808e-05 - val_loss: 1.8682e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 458us/step - loss: 7.9756e-05 - val_loss: 1.8593e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 499us/step - loss: 7.4751e-05 - val_loss: 1.8733e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 515us/step - loss: 7.1266e-05 - val_loss: 1.8648e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 471us/step - loss: 6.8666e-05 - val_loss: 1.8921e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 483us/step - loss: 6.8022e-05 - val_loss: 1.8931e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 490us/step - loss: 6.7247e-05 - val_loss: 1.9045e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 447us/step - loss: 6.6663e-05 - val_loss: 1.9933e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 489us/step - loss: 6.8212e-05 - val_loss: 1.9142e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 472us/step - loss: 6.6811e-05 - val_loss: 1.9220e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 496us/step - loss: 6.8130e-05 - val_loss: 1.9329e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 494us/step - loss: 6.8380e-05 - val_loss: 1.9230e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 468us/step - loss: 6.6830e-05 - val_loss: 1.9145e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 481us/step - loss: 6.7029e-05 - val_loss: 1.9175e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 489us/step - loss: 6.6928e-05 - val_loss: 1.9109e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 462us/step - loss: 6.6354e-05 - val_loss: 1.9147e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 493us/step - loss: 6.6561e-05 - val_loss: 1.9130e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 136s 83ms/step - loss: 2.0731e-04 - val_loss: 2.3641e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 541us/step - loss: 1.2038e-04 - val_loss: 1.8707e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 539us/step - loss: 1.1284e-04 - val_loss: 1.8992e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 554us/step - loss: 1.0738e-04 - val_loss: 1.9368e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 527us/step - loss: 1.0385e-04 - val_loss: 1.8887e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 509us/step - loss: 9.7926e-05 - val_loss: 1.8691e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 544us/step - loss: 9.2529e-05 - val_loss: 1.8969e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 573us/step - loss: 8.6432e-05 - val_loss: 1.8984e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 539us/step - loss: 8.0000e-05 - val_loss: 1.8450e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 545us/step - loss: 7.3631e-05 - val_loss: 1.8573e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 559us/step - loss: 6.9655e-05 - val_loss: 1.9299e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 536us/step - loss: 6.8078e-05 - val_loss: 1.9296e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 548us/step - loss: 6.6963e-05 - val_loss: 1.9289e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 546us/step - loss: 6.7150e-05 - val_loss: 1.9933e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 537us/step - loss: 6.7596e-05 - val_loss: 1.9290e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 542us/step - loss: 6.6941e-05 - val_loss: 1.9457e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 564us/step - loss: 6.7124e-05 - val_loss: 1.9377e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 541us/step - loss: 6.7383e-05 - val_loss: 1.9603e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 539us/step - loss: 6.7145e-05 - val_loss: 1.9273e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 513us/step - loss: 6.6891e-05 - val_loss: 1.9320e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 528us/step - loss: 6.7531e-05 - val_loss: 1.9421e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 514us/step - loss: 6.6875e-05 - val_loss: 1.9287e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 527us/step - loss: 6.6514e-05 - val_loss: 1.9303e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 518us/step - loss: 6.7258e-05 - val_loss: 1.9654e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 572us/step - loss: 6.6837e-05 - val_loss: 1.9316e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 138s 84ms/step - loss: 1.7928e-04 - val_loss: 1.9497e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 514us/step - loss: 1.1811e-04 - val_loss: 1.9424e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 519us/step - loss: 1.0214e-04 - val_loss: 1.9259e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 482us/step - loss: 9.5234e-05 - val_loss: 1.8824e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 554us/step - loss: 8.7409e-05 - val_loss: 1.9384e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 500us/step - loss: 8.0157e-05 - val_loss: 1.8431e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 496us/step - loss: 7.3012e-05 - val_loss: 1.8675e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 531us/step - loss: 7.0172e-05 - val_loss: 1.8993e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 505us/step - loss: 6.7774e-05 - val_loss: 1.9443e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 515us/step - loss: 6.7792e-05 - val_loss: 1.9689e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 499us/step - loss: 6.9765e-05 - val_loss: 1.9422e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 527us/step - loss: 6.7491e-05 - val_loss: 1.9227e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 519us/step - loss: 6.8471e-05 - val_loss: 1.9237e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 509us/step - loss: 6.7025e-05 - val_loss: 1.9243e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 516us/step - loss: 6.6264e-05 - val_loss: 1.9546e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 502us/step - loss: 6.8129e-05 - val_loss: 1.9256e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 526us/step - loss: 6.6990e-05 - val_loss: 1.9525e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 497us/step - loss: 6.7412e-05 - val_loss: 1.9283e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 528us/step - loss: 6.6299e-05 - val_loss: 1.9363e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 512us/step - loss: 6.6943e-05 - val_loss: 1.9288e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 512us/step - loss: 6.6376e-05 - val_loss: 1.9275e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 515us/step - loss: 6.7462e-05 - val_loss: 1.9212e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 508us/step - loss: 6.6188e-05 - val_loss: 1.9270e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 524us/step - loss: 6.6795e-05 - val_loss: 1.9487e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 524us/step - loss: 6.7262e-05 - val_loss: 1.9297e-04\n",
      "Train on 1645 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1645/1645 [==============================] - 136s 83ms/step - loss: 1.6764e-04 - val_loss: 1.9342e-04\n",
      "Epoch 2/25\n",
      "1645/1645 [==============================] - 1s 534us/step - loss: 1.0447e-04 - val_loss: 1.8436e-04\n",
      "Epoch 3/25\n",
      "1645/1645 [==============================] - 1s 500us/step - loss: 9.3435e-05 - val_loss: 1.8440e-04\n",
      "Epoch 4/25\n",
      "1645/1645 [==============================] - 1s 513us/step - loss: 8.4342e-05 - val_loss: 1.8481e-04\n",
      "Epoch 5/25\n",
      "1645/1645 [==============================] - 1s 524us/step - loss: 7.5934e-05 - val_loss: 1.8609e-04\n",
      "Epoch 6/25\n",
      "1645/1645 [==============================] - 1s 548us/step - loss: 6.9837e-05 - val_loss: 1.9037e-04\n",
      "Epoch 7/25\n",
      "1645/1645 [==============================] - 1s 541us/step - loss: 6.9376e-05 - val_loss: 1.9662e-04\n",
      "Epoch 8/25\n",
      "1645/1645 [==============================] - 1s 502us/step - loss: 6.6670e-05 - val_loss: 1.9407e-04\n",
      "Epoch 9/25\n",
      "1645/1645 [==============================] - 1s 532us/step - loss: 6.6512e-05 - val_loss: 2.0116e-04\n",
      "Epoch 10/25\n",
      "1645/1645 [==============================] - 1s 538us/step - loss: 6.8736e-05 - val_loss: 1.9400e-04\n",
      "Epoch 11/25\n",
      "1645/1645 [==============================] - 1s 533us/step - loss: 6.7791e-05 - val_loss: 1.9351e-04\n",
      "Epoch 12/25\n",
      "1645/1645 [==============================] - 1s 516us/step - loss: 6.7054e-05 - val_loss: 1.9267e-04\n",
      "Epoch 13/25\n",
      "1645/1645 [==============================] - 1s 527us/step - loss: 6.8705e-05 - val_loss: 2.0443e-04\n",
      "Epoch 14/25\n",
      "1645/1645 [==============================] - 1s 504us/step - loss: 6.9341e-05 - val_loss: 1.9266e-04\n",
      "Epoch 15/25\n",
      "1645/1645 [==============================] - 1s 527us/step - loss: 6.9337e-05 - val_loss: 1.9435e-04\n",
      "Epoch 16/25\n",
      "1645/1645 [==============================] - 1s 517us/step - loss: 6.7741e-05 - val_loss: 1.9262e-04\n",
      "Epoch 17/25\n",
      "1645/1645 [==============================] - 1s 503us/step - loss: 6.8072e-05 - val_loss: 1.9808e-04\n",
      "Epoch 18/25\n",
      "1645/1645 [==============================] - 1s 547us/step - loss: 6.7259e-05 - val_loss: 1.9710e-04\n",
      "Epoch 19/25\n",
      "1645/1645 [==============================] - 1s 517us/step - loss: 6.7902e-05 - val_loss: 1.9446e-04\n",
      "Epoch 20/25\n",
      "1645/1645 [==============================] - 1s 552us/step - loss: 6.6376e-05 - val_loss: 1.9227e-04\n",
      "Epoch 21/25\n",
      "1645/1645 [==============================] - 1s 509us/step - loss: 6.6391e-05 - val_loss: 1.9287e-04\n",
      "Epoch 22/25\n",
      "1645/1645 [==============================] - 1s 496us/step - loss: 6.6476e-05 - val_loss: 1.9573e-04\n",
      "Epoch 23/25\n",
      "1645/1645 [==============================] - 1s 569us/step - loss: 6.7580e-05 - val_loss: 1.9351e-04\n",
      "Epoch 24/25\n",
      "1645/1645 [==============================] - 1s 519us/step - loss: 6.6428e-05 - val_loss: 1.9160e-04\n",
      "Epoch 25/25\n",
      "1645/1645 [==============================] - 1s 535us/step - loss: 6.6671e-05 - val_loss: 2.0025e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 140s 85ms/step - loss: 3.2538e-04 - val_loss: 3.0258e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 554us/step - loss: 1.7640e-04 - val_loss: 1.9696e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 555us/step - loss: 1.5504e-04 - val_loss: 2.0673e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 556us/step - loss: 1.4757e-04 - val_loss: 1.9894e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 562us/step - loss: 1.4286e-04 - val_loss: 2.0154e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 570us/step - loss: 1.3938e-04 - val_loss: 1.9806e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 521us/step - loss: 1.3543e-04 - val_loss: 1.9776e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 533us/step - loss: 1.3215e-04 - val_loss: 1.9536e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 559us/step - loss: 1.2893e-04 - val_loss: 1.9431e-04\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 557us/step - loss: 1.2594e-04 - val_loss: 1.9385e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 538us/step - loss: 1.2321e-04 - val_loss: 1.9801e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 557us/step - loss: 1.2087e-04 - val_loss: 1.9164e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 567us/step - loss: 1.1790e-04 - val_loss: 1.9242e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 553us/step - loss: 1.1497e-04 - val_loss: 1.9191e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 566us/step - loss: 1.1233e-04 - val_loss: 1.9017e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 562us/step - loss: 1.0980e-04 - val_loss: 1.8793e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 564us/step - loss: 1.0746e-04 - val_loss: 1.8956e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 544us/step - loss: 1.0438e-04 - val_loss: 1.8838e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 539us/step - loss: 1.0128e-04 - val_loss: 1.8565e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 550us/step - loss: 9.8214e-05 - val_loss: 1.9059e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 535us/step - loss: 9.5705e-05 - val_loss: 1.9056e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 525us/step - loss: 9.2685e-05 - val_loss: 1.8667e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 573us/step - loss: 8.9164e-05 - val_loss: 1.8470e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 556us/step - loss: 8.6414e-05 - val_loss: 1.8385e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 538us/step - loss: 8.3348e-05 - val_loss: 1.8375e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 140s 85ms/step - loss: 2.5068e-04 - val_loss: 2.3049e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 1.4002e-04 - val_loss: 1.9265e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 1.2366e-04 - val_loss: 1.9130e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 1.2134e-04 - val_loss: 1.9413e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 1.2025e-04 - val_loss: 1.9226e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 1.1881e-04 - val_loss: 1.9252e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 580us/step - loss: 1.1737e-04 - val_loss: 1.9130e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 1.1581e-04 - val_loss: 1.9300e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 1.1406e-04 - val_loss: 1.8948e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 1.1260e-04 - val_loss: 1.9014e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 607us/step - loss: 1.1071e-04 - val_loss: 1.9241e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 1.0826e-04 - val_loss: 1.8722e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 1.0549e-04 - val_loss: 1.8818e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 1.0223e-04 - val_loss: 1.9160e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 9.8710e-05 - val_loss: 1.8756e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 9.4311e-05 - val_loss: 1.8381e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 8.8846e-05 - val_loss: 1.8374e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 8.3521e-05 - val_loss: 1.8396e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 592us/step - loss: 7.7455e-05 - val_loss: 1.8609e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 7.2534e-05 - val_loss: 1.8885e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.9413e-05 - val_loss: 1.9067e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.8104e-05 - val_loss: 1.9315e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 584us/step - loss: 6.7287e-05 - val_loss: 1.9355e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.7641e-05 - val_loss: 1.9360e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 584us/step - loss: 6.6860e-05 - val_loss: 1.9432e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 145s 88ms/step - loss: 1.6868e-04 - val_loss: 1.8683e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 563us/step - loss: 1.1595e-04 - val_loss: 1.9899e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 610us/step - loss: 1.0471e-04 - val_loss: 1.8873e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 1.0083e-04 - val_loss: 1.9362e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 9.7247e-05 - val_loss: 1.8529e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 9.2622e-05 - val_loss: 1.8414e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 572us/step - loss: 8.7544e-05 - val_loss: 1.8356e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 8.2879e-05 - val_loss: 1.8384e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 7.6977e-05 - val_loss: 1.8673e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 7.3140e-05 - val_loss: 1.8454e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 592us/step - loss: 7.1077e-05 - val_loss: 1.8554e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 551us/step - loss: 6.9672e-05 - val_loss: 1.8712e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.9494e-05 - val_loss: 1.8877e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 580us/step - loss: 6.8458e-05 - val_loss: 1.8786e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 6.8269e-05 - val_loss: 1.8799e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 569us/step - loss: 6.8608e-05 - val_loss: 1.8817e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 549us/step - loss: 6.9054e-05 - val_loss: 1.8891e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 574us/step - loss: 6.8792e-05 - val_loss: 1.8856e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 574us/step - loss: 6.8069e-05 - val_loss: 1.8969e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 6.8702e-05 - val_loss: 1.8792e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 569us/step - loss: 6.7426e-05 - val_loss: 1.8869e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.8681e-05 - val_loss: 1.9224e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 563us/step - loss: 6.9951e-05 - val_loss: 1.8850e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 580us/step - loss: 6.8377e-05 - val_loss: 1.8878e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 575us/step - loss: 6.8055e-05 - val_loss: 1.8851e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 145s 88ms/step - loss: 1.9567e-04 - val_loss: 1.9646e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 1.3030e-04 - val_loss: 2.1253e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 1.1515e-04 - val_loss: 1.9718e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 1.0871e-04 - val_loss: 1.9234e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 1.0604e-04 - val_loss: 1.8674e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 9.9595e-05 - val_loss: 1.9389e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 9.4085e-05 - val_loss: 1.8866e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 8.7273e-05 - val_loss: 1.8408e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 7.9141e-05 - val_loss: 1.8450e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 7.3562e-05 - val_loss: 1.8556e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 7.0127e-05 - val_loss: 1.8644e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 6.9270e-05 - val_loss: 1.8811e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 578us/step - loss: 6.8288e-05 - val_loss: 1.8867e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.9774e-05 - val_loss: 1.9196e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.7897e-05 - val_loss: 1.9313e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 6.8552e-05 - val_loss: 1.9056e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.8782e-05 - val_loss: 1.8877e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.7852e-05 - val_loss: 1.8889e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.8366e-05 - val_loss: 1.9198e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.8459e-05 - val_loss: 1.8965e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 583us/step - loss: 6.8733e-05 - val_loss: 1.8909e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.8061e-05 - val_loss: 1.9120e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.7871e-05 - val_loss: 1.9276e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 6.8535e-05 - val_loss: 1.8969e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 6.9414e-05 - val_loss: 1.9349e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 150s 91ms/step - loss: 1.3876e-04 - val_loss: 1.8528e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 9.4452e-05 - val_loss: 1.9109e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 8.7264e-05 - val_loss: 1.8648e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 8.2936e-05 - val_loss: 1.8344e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 619us/step - loss: 7.8385e-05 - val_loss: 1.8600e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 612us/step - loss: 7.4231e-05 - val_loss: 1.8391e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 607us/step - loss: 7.2568e-05 - val_loss: 1.8521e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 6.9536e-05 - val_loss: 1.8964e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 618us/step - loss: 6.8794e-05 - val_loss: 1.9247e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 6.7627e-05 - val_loss: 1.8829e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.7284e-05 - val_loss: 1.8851e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 613us/step - loss: 6.7123e-05 - val_loss: 1.8894e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 613us/step - loss: 6.7044e-05 - val_loss: 1.8913e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 609us/step - loss: 6.7208e-05 - val_loss: 1.8923e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.6971e-05 - val_loss: 1.8924e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 613us/step - loss: 6.6971e-05 - val_loss: 1.9081e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 614us/step - loss: 6.7949e-05 - val_loss: 1.9023e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 612us/step - loss: 6.7494e-05 - val_loss: 1.8909e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.9564e-05 - val_loss: 1.8899e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.8299e-05 - val_loss: 1.9507e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 655us/step - loss: 6.8360e-05 - val_loss: 1.8931e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 6.6861e-05 - val_loss: 1.8946e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 652us/step - loss: 6.7073e-05 - val_loss: 1.9044e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.7702e-05 - val_loss: 1.8954e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.6498e-05 - val_loss: 1.9061e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 150s 92ms/step - loss: 2.0577e-04 - val_loss: 1.9732e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 472us/step - loss: 1.1665e-04 - val_loss: 1.9619e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 476us/step - loss: 1.0736e-04 - val_loss: 1.8602e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 9.9790e-05 - val_loss: 1.8639e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 620us/step - loss: 9.3918e-05 - val_loss: 1.8425e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - ETA: 0s - loss: 8.8920e-0 - 1s 529us/step - loss: 8.8436e-05 - val_loss: 1.8400e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 494us/step - loss: 8.1542e-05 - val_loss: 1.8427e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 520us/step - loss: 7.5783e-05 - val_loss: 1.8438e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 571us/step - loss: 7.1059e-05 - val_loss: 1.8536e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 492us/step - loss: 6.8098e-05 - val_loss: 1.8694e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 583us/step - loss: 6.6665e-05 - val_loss: 1.8805e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 652us/step - loss: 6.7632e-05 - val_loss: 1.9060e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 614us/step - loss: 7.0555e-05 - val_loss: 1.8953e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 505us/step - loss: 6.7813e-05 - val_loss: 1.8901e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 532us/step - loss: 6.6593e-05 - val_loss: 1.9324e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.7116e-05 - val_loss: 1.8897e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 533us/step - loss: 6.6775e-05 - val_loss: 1.9250e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 514us/step - loss: 6.6224e-05 - val_loss: 1.8964e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 501us/step - loss: 6.6241e-05 - val_loss: 1.9175e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 571us/step - loss: 6.6268e-05 - val_loss: 1.9080e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 6.7052e-05 - val_loss: 1.8944e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 534us/step - loss: 6.6328e-05 - val_loss: 1.8954e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 473us/step - loss: 6.5976e-05 - val_loss: 1.8962e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 456us/step - loss: 6.5725e-05 - val_loss: 1.8963e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 498us/step - loss: 6.6441e-05 - val_loss: 1.8979e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 160s 97ms/step - loss: 1.6484e-04 - val_loss: 1.8510e-04\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 512us/step - loss: 1.0497e-04 - val_loss: 2.0665e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 572us/step - loss: 9.7447e-05 - val_loss: 1.8677e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 548us/step - loss: 8.8883e-05 - val_loss: 1.8928e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 653us/step - loss: 8.3610e-05 - val_loss: 1.8740e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 685us/step - loss: 7.8035e-05 - val_loss: 1.8679e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 7.3263e-05 - val_loss: 1.8562e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 735us/step - loss: 6.9649e-05 - val_loss: 1.8756e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 686us/step - loss: 6.8971e-05 - val_loss: 1.9086e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 583us/step - loss: 6.7687e-05 - val_loss: 1.9066e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.7034e-05 - val_loss: 1.9116e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 661us/step - loss: 6.8914e-05 - val_loss: 1.9306e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 626us/step - loss: 6.6493e-05 - val_loss: 1.9178e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 650us/step - loss: 6.7045e-05 - val_loss: 1.9132e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 660us/step - loss: 6.6646e-05 - val_loss: 1.9108e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 661us/step - loss: 6.7192e-05 - val_loss: 1.9222e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 6.6902e-05 - val_loss: 1.9130e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 615us/step - loss: 6.6714e-05 - val_loss: 1.9133e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.7182e-05 - val_loss: 1.9253e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.6304e-05 - val_loss: 1.9122e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 6.7650e-05 - val_loss: 1.9302e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.8123e-05 - val_loss: 1.9831e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 637us/step - loss: 7.0270e-05 - val_loss: 1.9416e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 658us/step - loss: 7.0292e-05 - val_loss: 1.9647e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 6.8233e-05 - val_loss: 1.9558e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 149s 90ms/step - loss: 2.1070e-04 - val_loss: 1.8936e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 1.3244e-04 - val_loss: 2.1319e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 698us/step - loss: 1.1699e-04 - val_loss: 1.9284e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 735us/step - loss: 1.0864e-04 - val_loss: 1.8532e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 686us/step - loss: 9.9988e-05 - val_loss: 1.8474e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 688us/step - loss: 9.0832e-05 - val_loss: 1.8605e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 712us/step - loss: 8.1155e-05 - val_loss: 1.8369e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 745us/step - loss: 7.4658e-05 - val_loss: 1.9060e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 717us/step - loss: 6.9417e-05 - val_loss: 1.8834e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.7019e-05 - val_loss: 1.9078e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 6.6993e-05 - val_loss: 1.9056e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.6646e-05 - val_loss: 1.9148e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 686us/step - loss: 6.7445e-05 - val_loss: 1.9104e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 703us/step - loss: 6.6518e-05 - val_loss: 1.9512e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 742us/step - loss: 6.6890e-05 - val_loss: 1.9027e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 776us/step - loss: 6.7232e-05 - val_loss: 1.9153e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 738us/step - loss: 6.6650e-05 - val_loss: 1.9319e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 789us/step - loss: 6.6494e-05 - val_loss: 1.9077e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 733us/step - loss: 6.6284e-05 - val_loss: 1.9052e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 717us/step - loss: 6.6708e-05 - val_loss: 1.9104e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 770us/step - loss: 6.6194e-05 - val_loss: 1.9059e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 734us/step - loss: 6.6243e-05 - val_loss: 1.9190e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 743us/step - loss: 6.7222e-05 - val_loss: 1.9254e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 776us/step - loss: 6.6738e-05 - val_loss: 1.9112e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 744us/step - loss: 6.6161e-05 - val_loss: 1.9024e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 159s 97ms/step - loss: 2.5891e-04 - val_loss: 1.9271e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 470us/step - loss: 1.4201e-04 - val_loss: 2.1053e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 500us/step - loss: 1.2043e-04 - val_loss: 1.8732e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 454us/step - loss: 1.1103e-04 - val_loss: 1.8998e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 448us/step - loss: 1.0105e-04 - val_loss: 1.9127e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 479us/step - loss: 9.3007e-05 - val_loss: 1.9075e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 473us/step - loss: 8.5813e-05 - val_loss: 1.8649e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 453us/step - loss: 7.9123e-05 - val_loss: 1.8884e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 468us/step - loss: 7.5277e-05 - val_loss: 1.8685e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 455us/step - loss: 7.1103e-05 - val_loss: 1.8718e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 444us/step - loss: 6.9091e-05 - val_loss: 1.8923e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 485us/step - loss: 6.7867e-05 - val_loss: 1.9081e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 461us/step - loss: 6.6988e-05 - val_loss: 1.9171e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 462us/step - loss: 6.6882e-05 - val_loss: 1.9164e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 465us/step - loss: 6.7081e-05 - val_loss: 1.9182e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 509us/step - loss: 6.8066e-05 - val_loss: 1.9549e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 472us/step - loss: 6.6370e-05 - val_loss: 1.9355e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 449us/step - loss: 6.7369e-05 - val_loss: 1.9237e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 444us/step - loss: 6.7516e-05 - val_loss: 1.9196e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 455us/step - loss: 6.7619e-05 - val_loss: 1.9202e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 445us/step - loss: 6.6785e-05 - val_loss: 1.9181e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 459us/step - loss: 6.7703e-05 - val_loss: 1.9249e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 476us/step - loss: 6.6494e-05 - val_loss: 1.9226e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 466us/step - loss: 6.7105e-05 - val_loss: 1.9523e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 461us/step - loss: 6.6939e-05 - val_loss: 1.9189e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 154s 94ms/step - loss: 1.8920e-04 - val_loss: 2.0538e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 1.1328e-04 - val_loss: 1.9071e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 1.0559e-04 - val_loss: 1.8561e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 1.0005e-04 - val_loss: 1.8652e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 9.4479e-05 - val_loss: 1.8626e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 8.8128e-05 - val_loss: 1.8497e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 8.2457e-05 - val_loss: 1.8527e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 7.6860e-05 - val_loss: 1.8587e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 7.2517e-05 - val_loss: 1.9125e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.9832e-05 - val_loss: 1.8722e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.8676e-05 - val_loss: 1.9086e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 6.9308e-05 - val_loss: 1.9152e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.7846e-05 - val_loss: 1.9275e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 601us/step - loss: 6.7924e-05 - val_loss: 1.9132e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.6889e-05 - val_loss: 1.9122e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.7249e-05 - val_loss: 1.9106e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.6179e-05 - val_loss: 1.9121e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.6385e-05 - val_loss: 1.9213e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.6785e-05 - val_loss: 1.9097e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.7094e-05 - val_loss: 1.9112e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.7328e-05 - val_loss: 1.9073e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.6183e-05 - val_loss: 1.9171e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.6466e-05 - val_loss: 1.9319e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.9416e-05 - val_loss: 1.9662e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 603us/step - loss: 6.9484e-05 - val_loss: 1.9210e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 159s 97ms/step - loss: 1.7431e-04 - val_loss: 1.9513e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 574us/step - loss: 1.1106e-04 - val_loss: 1.9346e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 565us/step - loss: 9.8352e-05 - val_loss: 1.8829e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 551us/step - loss: 9.1054e-05 - val_loss: 1.8616e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 549us/step - loss: 8.3177e-05 - val_loss: 1.8527e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 561us/step - loss: 7.5475e-05 - val_loss: 1.8611e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 564us/step - loss: 7.0115e-05 - val_loss: 1.8885e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 558us/step - loss: 6.7507e-05 - val_loss: 1.9115e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 551us/step - loss: 6.6562e-05 - val_loss: 1.9390e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 573us/step - loss: 6.7694e-05 - val_loss: 1.9402e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 556us/step - loss: 6.7862e-05 - val_loss: 1.9183e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 568us/step - loss: 6.7417e-05 - val_loss: 1.9212e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 7.0439e-05 - val_loss: 1.9852e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 568us/step - loss: 6.7517e-05 - val_loss: 1.9221e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 573us/step - loss: 6.7721e-05 - val_loss: 1.9117e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.7338e-05 - val_loss: 1.9264e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 560us/step - loss: 6.9352e-05 - val_loss: 1.9674e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 577us/step - loss: 6.8117e-05 - val_loss: 1.9163e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 571us/step - loss: 6.6531e-05 - val_loss: 1.9161e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 6.7160e-05 - val_loss: 1.9825e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 573us/step - loss: 6.7365e-05 - val_loss: 1.9176e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 561us/step - loss: 6.8395e-05 - val_loss: 1.9247e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 6.6520e-05 - val_loss: 1.9180e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.6415e-05 - val_loss: 1.9185e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 573us/step - loss: 6.6866e-05 - val_loss: 1.9705e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 157s 95ms/step - loss: 1.8405e-04 - val_loss: 1.9331e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 637us/step - loss: 1.1190e-04 - val_loss: 1.8658e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 9.9471e-05 - val_loss: 1.8641e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 654us/step - loss: 9.0071e-05 - val_loss: 1.8443e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 650us/step - loss: 8.2421e-05 - val_loss: 1.8363e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 7.4478e-05 - val_loss: 1.8772e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.9172e-05 - val_loss: 1.8798e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 649us/step - loss: 6.8735e-05 - val_loss: 1.8958e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 6.7009e-05 - val_loss: 1.9030e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.7299e-05 - val_loss: 1.9070e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 6.8385e-05 - val_loss: 1.9124e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.8651e-05 - val_loss: 1.9133e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 6.7437e-05 - val_loss: 1.9175e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 651us/step - loss: 6.7910e-05 - val_loss: 1.9193e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 652us/step - loss: 6.9897e-05 - val_loss: 1.9012e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 6.8116e-05 - val_loss: 1.9133e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.9268e-05 - val_loss: 1.8977e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 646us/step - loss: 6.9533e-05 - val_loss: 1.9551e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 648us/step - loss: 6.8462e-05 - val_loss: 1.9095e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 6.9125e-05 - val_loss: 1.9960e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 6.9805e-05 - val_loss: 1.9047e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 6.8416e-05 - val_loss: 1.8969e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 645us/step - loss: 6.6722e-05 - val_loss: 1.9022e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 653us/step - loss: 6.6846e-05 - val_loss: 1.9152e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 6.6310e-05 - val_loss: 1.9054e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 166s 101ms/step - loss: 1.7861e-04 - val_loss: 1.8793e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 1.1865e-04 - val_loss: 1.9392e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 9.8508e-05 - val_loss: 1.8850e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 9.1171e-05 - val_loss: 1.8701e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 8.4331e-05 - val_loss: 1.8390e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 7.7693e-05 - val_loss: 1.8382e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 7.3537e-05 - val_loss: 1.8600e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.8901e-05 - val_loss: 1.8682e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 6.7589e-05 - val_loss: 1.9123e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.7686e-05 - val_loss: 1.8973e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 6.7319e-05 - val_loss: 1.9123e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.7181e-05 - val_loss: 1.9237e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.6329e-05 - val_loss: 1.9047e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 592us/step - loss: 6.6122e-05 - val_loss: 1.9407e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.6522e-05 - val_loss: 1.9050e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.6540e-05 - val_loss: 1.9098e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.7315e-05 - val_loss: 1.9207e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 607us/step - loss: 6.8566e-05 - val_loss: 1.9660e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.6890e-05 - val_loss: 1.9319e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 6.7614e-05 - val_loss: 1.9241e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 580us/step - loss: 6.6701e-05 - val_loss: 1.9051e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.5993e-05 - val_loss: 1.9038e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 600us/step - loss: 6.6825e-05 - val_loss: 1.9055e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.5621e-05 - val_loss: 1.9120e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 6.8078e-05 - val_loss: 1.9339e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 162s 98ms/step - loss: 1.4488e-04 - val_loss: 1.9303e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 9.3655e-05 - val_loss: 1.8326e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 8.6803e-05 - val_loss: 1.8524e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 8.1273e-05 - val_loss: 1.8418e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 646us/step - loss: 7.3529e-05 - val_loss: 1.8659e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.9356e-05 - val_loss: 1.8661e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.8165e-05 - val_loss: 1.8844e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.6665e-05 - val_loss: 1.8963e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.6575e-05 - val_loss: 1.9056e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.6631e-05 - val_loss: 1.9087e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.6814e-05 - val_loss: 1.9141e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.6826e-05 - val_loss: 1.9064e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.8419e-05 - val_loss: 1.9598e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 643us/step - loss: 7.0088e-05 - val_loss: 1.9048e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.9062e-05 - val_loss: 1.9058e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 6.7982e-05 - val_loss: 1.9419e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.7362e-05 - val_loss: 1.9113e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 6.7601e-05 - val_loss: 1.9175e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 6.5902e-05 - val_loss: 1.9259e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.7913e-05 - val_loss: 1.9249e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 643us/step - loss: 6.7714e-05 - val_loss: 1.9013e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.6452e-05 - val_loss: 1.9188e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 6.8065e-05 - val_loss: 1.9303e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.7847e-05 - val_loss: 1.9172e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 651us/step - loss: 6.6539e-05 - val_loss: 1.8964e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 170s 103ms/step - loss: 1.6961e-04 - val_loss: 2.0072e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 1.1124e-04 - val_loss: 1.8445e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 9.4791e-05 - val_loss: 1.8930e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 652us/step - loss: 8.8027e-05 - val_loss: 1.8567e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 7.9566e-05 - val_loss: 1.8412e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 646us/step - loss: 7.2535e-05 - val_loss: 1.8544e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 654us/step - loss: 6.9230e-05 - val_loss: 1.8655e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.7690e-05 - val_loss: 1.8789e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.7304e-05 - val_loss: 1.9098e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.7126e-05 - val_loss: 1.8886e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 6.7072e-05 - val_loss: 1.8847e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 612us/step - loss: 6.7350e-05 - val_loss: 1.8830e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 6.8709e-05 - val_loss: 1.8918e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 6.7214e-05 - val_loss: 1.8954e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 649us/step - loss: 6.7355e-05 - val_loss: 2.0005e-04\n",
      "Epoch 16/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 649us/step - loss: 6.9093e-05 - val_loss: 1.9024e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.6933e-05 - val_loss: 1.8952e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 646us/step - loss: 6.9027e-05 - val_loss: 1.8972e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 6.6444e-05 - val_loss: 1.8928e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 647us/step - loss: 6.6226e-05 - val_loss: 1.8970e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.6819e-05 - val_loss: 1.9008e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.7018e-05 - val_loss: 1.8976e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 646us/step - loss: 6.7240e-05 - val_loss: 1.9180e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.8481e-05 - val_loss: 1.8952e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 6.7752e-05 - val_loss: 1.8997e-04\n",
      "Train on 1644 samples, validate on 412 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 170s 104ms/step - loss: 1.5306e-04 - val_loss: 1.8430e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 617us/step - loss: 9.7073e-05 - val_loss: 1.8454e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 601us/step - loss: 8.7134e-05 - val_loss: 1.9014e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 7.8289e-05 - val_loss: 1.8967e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.9712e-05 - val_loss: 1.8669e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.7462e-05 - val_loss: 1.9016e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 605us/step - loss: 6.7123e-05 - val_loss: 1.9186e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.6249e-05 - val_loss: 1.9163e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.9572e-05 - val_loss: 1.9137e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.8141e-05 - val_loss: 1.8972e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 6.7607e-05 - val_loss: 1.8964e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 612us/step - loss: 7.1567e-05 - val_loss: 1.9077e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 606us/step - loss: 6.7552e-05 - val_loss: 1.9042e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.6069e-05 - val_loss: 1.9084e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 6.5664e-05 - val_loss: 1.9026e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 603us/step - loss: 6.6244e-05 - val_loss: 1.9050e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 611us/step - loss: 6.6364e-05 - val_loss: 1.9208e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 607us/step - loss: 6.7212e-05 - val_loss: 1.9432e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.6457e-05 - val_loss: 1.9104e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 605us/step - loss: 6.9260e-05 - val_loss: 1.9003e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.6821e-05 - val_loss: 1.9062e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 611us/step - loss: 6.5886e-05 - val_loss: 1.9054e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.6169e-05 - val_loss: 1.9108e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 610us/step - loss: 6.6188e-05 - val_loss: 1.9118e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 620us/step - loss: 6.7135e-05 - val_loss: 1.9311e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 176s 107ms/step - loss: 1.6806e-04 - val_loss: 2.3419e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 645us/step - loss: 1.1055e-04 - val_loss: 1.8624e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 1.0304e-04 - val_loss: 1.9234e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 626us/step - loss: 9.9232e-05 - val_loss: 1.8613e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 9.7729e-05 - val_loss: 1.8878e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 9.5496e-05 - val_loss: 1.8674e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 9.3366e-05 - val_loss: 1.8866e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 9.1332e-05 - val_loss: 1.8562e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 8.8795e-05 - val_loss: 1.8434e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 8.6218e-05 - val_loss: 1.8671e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 8.3792e-05 - val_loss: 1.8367e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 8.1393e-05 - val_loss: 1.8411e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 653us/step - loss: 7.8153e-05 - val_loss: 1.8537e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 7.6497e-05 - val_loss: 1.8844e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 7.3784e-05 - val_loss: 1.8520e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 7.1782e-05 - val_loss: 1.8533e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 7.0575e-05 - val_loss: 1.8592e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.9764e-05 - val_loss: 1.8645e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.9382e-05 - val_loss: 1.8702e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.8937e-05 - val_loss: 1.8739e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.8783e-05 - val_loss: 1.8755e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.8471e-05 - val_loss: 1.8842e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 7.0369e-05 - val_loss: 1.8804e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 6.8814e-05 - val_loss: 1.9320e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.8735e-05 - val_loss: 1.8851e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 171s 104ms/step - loss: 2.0245e-04 - val_loss: 2.3004e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 1.2287e-04 - val_loss: 1.8933e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 1.1677e-04 - val_loss: 1.9522e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 1.1574e-04 - val_loss: 1.9340e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 1.1408e-04 - val_loss: 1.9309e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 1.1191e-04 - val_loss: 1.9043e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 648us/step - loss: 1.0831e-04 - val_loss: 1.9010e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 1.0493e-04 - val_loss: 1.8803e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 9.9059e-05 - val_loss: 1.8672e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 645us/step - loss: 9.2578e-05 - val_loss: 1.8991e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 8.5304e-05 - val_loss: 1.8728e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 7.6323e-05 - val_loss: 1.9059e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 7.0373e-05 - val_loss: 1.9652e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.9709e-05 - val_loss: 1.9538e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 617us/step - loss: 7.1074e-05 - val_loss: 2.0190e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 7.0801e-05 - val_loss: 1.9861e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.9848e-05 - val_loss: 1.9717e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 626us/step - loss: 6.7938e-05 - val_loss: 1.9432e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.7709e-05 - val_loss: 1.9422e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.8314e-05 - val_loss: 1.9348e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.7258e-05 - val_loss: 1.9368e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.7788e-05 - val_loss: 1.9404e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.9678e-05 - val_loss: 1.9387e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 626us/step - loss: 6.8293e-05 - val_loss: 1.9499e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.8018e-05 - val_loss: 1.9328e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 175s 107ms/step - loss: 1.5328e-04 - val_loss: 1.9176e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 1.1417e-04 - val_loss: 1.8861e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 1.0207e-04 - val_loss: 1.8823e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 662us/step - loss: 9.7241e-05 - val_loss: 1.8959e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 9.1486e-05 - val_loss: 1.9593e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 8.7573e-05 - val_loss: 2.0552e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 8.5038e-05 - val_loss: 1.8461e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 7.8854e-05 - val_loss: 1.8546e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 7.1899e-05 - val_loss: 1.8698e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 665us/step - loss: 7.0310e-05 - val_loss: 1.9664e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 7.1776e-05 - val_loss: 1.9050e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 7.2234e-05 - val_loss: 1.9171e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 7.3043e-05 - val_loss: 1.9144e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 7.4939e-05 - val_loss: 1.9257e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 660us/step - loss: 6.9386e-05 - val_loss: 1.9085e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.7594e-05 - val_loss: 1.9152e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 6.8103e-05 - val_loss: 1.9203e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 6.7881e-05 - val_loss: 1.9376e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.8729e-05 - val_loss: 1.9938e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.9156e-05 - val_loss: 1.9260e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.7992e-05 - val_loss: 1.9324e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 6.7217e-05 - val_loss: 1.9141e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.6932e-05 - val_loss: 1.9174e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 685us/step - loss: 6.7328e-05 - val_loss: 1.9180e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.8965e-05 - val_loss: 1.9168e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 176s 107ms/step - loss: 1.8554e-04 - val_loss: 1.9875e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 1.2332e-04 - val_loss: 1.9915e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 1.0774e-04 - val_loss: 1.9261e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 1.0065e-04 - val_loss: 1.8942e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 9.4113e-05 - val_loss: 1.9400e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 8.8653e-05 - val_loss: 1.9133e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 7.9284e-05 - val_loss: 1.8603e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 7.3349e-05 - val_loss: 1.8873e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 7.0116e-05 - val_loss: 1.9303e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.7705e-05 - val_loss: 1.9354e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.8380e-05 - val_loss: 1.9492e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.8463e-05 - val_loss: 1.9461e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.7602e-05 - val_loss: 1.9808e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7976e-05 - val_loss: 1.9313e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.7788e-05 - val_loss: 1.9524e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.7689e-05 - val_loss: 1.9556e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.8077e-05 - val_loss: 1.9351e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.8770e-05 - val_loss: 1.9377e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7917e-05 - val_loss: 1.9319e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.7528e-05 - val_loss: 1.9348e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.7344e-05 - val_loss: 1.9389e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.8114e-05 - val_loss: 1.9566e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.7308e-05 - val_loss: 1.9430e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.8657e-05 - val_loss: 1.9264e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.9902e-05 - val_loss: 1.9226e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 182s 110ms/step - loss: 1.1156e-04 - val_loss: 1.8398e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 8.1253e-05 - val_loss: 1.8479e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 7.5490e-05 - val_loss: 1.8683e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 7.2262e-05 - val_loss: 1.8607e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 7.1748e-05 - val_loss: 1.8912e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.9152e-05 - val_loss: 1.8813e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.8756e-05 - val_loss: 1.8998e-04\n",
      "Epoch 8/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.9573e-05 - val_loss: 1.8992e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.8620e-05 - val_loss: 1.9005e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 634us/step - loss: 6.8636e-05 - val_loss: 1.8900e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 6.8056e-05 - val_loss: 1.8902e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.8208e-05 - val_loss: 1.9740e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 642us/step - loss: 6.8714e-05 - val_loss: 1.8966e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.8366e-05 - val_loss: 1.8999e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 6.8745e-05 - val_loss: 1.9066e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7903e-05 - val_loss: 1.8959e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 638us/step - loss: 6.9571e-05 - val_loss: 1.9005e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 635us/step - loss: 6.8090e-05 - val_loss: 1.8992e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.9024e-05 - val_loss: 1.9268e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.9438e-05 - val_loss: 1.8990e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 639us/step - loss: 6.8727e-05 - val_loss: 2.0024e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 6.9883e-05 - val_loss: 1.9018e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7438e-05 - val_loss: 1.8967e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.7708e-05 - val_loss: 1.9145e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.8734e-05 - val_loss: 1.9014e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 180s 110ms/step - loss: 1.5477e-04 - val_loss: 1.9972e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 601us/step - loss: 1.0283e-04 - val_loss: 1.8453e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 9.0230e-05 - val_loss: 1.8486e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 8.3039e-05 - val_loss: 1.8518e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 7.7216e-05 - val_loss: 1.8746e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 600us/step - loss: 7.2540e-05 - val_loss: 1.9221e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 610us/step - loss: 7.2546e-05 - val_loss: 1.9062e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 7.0952e-05 - val_loss: 1.9112e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 602us/step - loss: 6.8001e-05 - val_loss: 1.9516e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.7987e-05 - val_loss: 1.9351e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.7892e-05 - val_loss: 1.9408e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 601us/step - loss: 6.8409e-05 - val_loss: 1.9472e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 600us/step - loss: 6.7305e-05 - val_loss: 1.9314e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.8140e-05 - val_loss: 1.9363e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.8168e-05 - val_loss: 1.9888e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 6.8866e-05 - val_loss: 1.9302e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.8261e-05 - val_loss: 1.9304e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 604us/step - loss: 6.8739e-05 - val_loss: 1.9254e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 6.7946e-05 - val_loss: 1.9579e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.8136e-05 - val_loss: 1.9416e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 6.7051e-05 - val_loss: 1.9393e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 597us/step - loss: 6.7590e-05 - val_loss: 2.0108e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 7.1784e-05 - val_loss: 1.9375e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 6.8368e-05 - val_loss: 1.9177e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 6.7521e-05 - val_loss: 1.9389e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 182s 111ms/step - loss: 1.8641e-04 - val_loss: 1.8776e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 1.1239e-04 - val_loss: 1.9411e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 9.9991e-05 - val_loss: 1.9025e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 9.3530e-05 - val_loss: 1.8552e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 8.6548e-05 - val_loss: 1.8407e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 7.9682e-05 - val_loss: 1.8435e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 7.5060e-05 - val_loss: 1.9491e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 7.1624e-05 - val_loss: 1.8846e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 7.0208e-05 - val_loss: 1.9564e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 628us/step - loss: 6.9881e-05 - val_loss: 1.9014e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7447e-05 - val_loss: 1.9056e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 625us/step - loss: 6.8073e-05 - val_loss: 1.9156e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.8450e-05 - val_loss: 1.9079e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 630us/step - loss: 6.7672e-05 - val_loss: 1.9188e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.8940e-05 - val_loss: 1.9164e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 621us/step - loss: 6.7962e-05 - val_loss: 1.9269e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 636us/step - loss: 6.8075e-05 - val_loss: 1.9081e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 641us/step - loss: 6.8571e-05 - val_loss: 1.9451e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 640us/step - loss: 6.8277e-05 - val_loss: 1.9144e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.7412e-05 - val_loss: 1.9220e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 627us/step - loss: 6.7502e-05 - val_loss: 1.9129e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 629us/step - loss: 6.8524e-05 - val_loss: 1.9207e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 632us/step - loss: 6.8407e-05 - val_loss: 1.9099e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 631us/step - loss: 6.7849e-05 - val_loss: 1.9033e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 633us/step - loss: 6.7405e-05 - val_loss: 1.9194e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 186s 113ms/step - loss: 1.8815e-04 - val_loss: 1.9945e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 1.1409e-04 - val_loss: 1.9802e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 1.0036e-04 - val_loss: 1.9246e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 9.0198e-05 - val_loss: 1.8479e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 8.2226e-05 - val_loss: 1.8369e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 7.4652e-05 - val_loss: 1.9017e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 7.1774e-05 - val_loss: 1.8912e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 596us/step - loss: 7.1150e-05 - val_loss: 1.9560e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 590us/step - loss: 7.0781e-05 - val_loss: 1.8872e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 7.0396e-05 - val_loss: 1.9357e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 7.1574e-05 - val_loss: 1.9093e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.8551e-05 - val_loss: 1.8895e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 6.8174e-05 - val_loss: 1.9093e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.9102e-05 - val_loss: 1.8919e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 591us/step - loss: 6.8176e-05 - val_loss: 1.8955e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.7711e-05 - val_loss: 1.9122e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 598us/step - loss: 6.8131e-05 - val_loss: 1.8972e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 613us/step - loss: 6.7170e-05 - val_loss: 1.9006e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 594us/step - loss: 6.7531e-05 - val_loss: 1.9067e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 605us/step - loss: 6.8701e-05 - val_loss: 1.9173e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 607us/step - loss: 6.8612e-05 - val_loss: 1.9815e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 601us/step - loss: 6.8766e-05 - val_loss: 1.8941e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 600us/step - loss: 6.7964e-05 - val_loss: 1.9120e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 595us/step - loss: 6.7542e-05 - val_loss: 1.8963e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 589us/step - loss: 6.7239e-05 - val_loss: 1.8967e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 189s 115ms/step - loss: 2.0263e-04 - val_loss: 2.4012e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 673us/step - loss: 1.2143e-04 - val_loss: 1.8688e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 682us/step - loss: 1.1002e-04 - val_loss: 1.9255e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 1.0678e-04 - val_loss: 1.8845e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 1.0473e-04 - val_loss: 1.9020e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 671us/step - loss: 1.0214e-04 - val_loss: 1.8718e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 9.9521e-05 - val_loss: 1.8911e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 681us/step - loss: 9.6324e-05 - val_loss: 1.8756e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 9.1929e-05 - val_loss: 1.8783e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 8.7507e-05 - val_loss: 1.8653e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 665us/step - loss: 8.2661e-05 - val_loss: 1.8651e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 7.7952e-05 - val_loss: 1.8500e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 7.2422e-05 - val_loss: 1.8660e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.9866e-05 - val_loss: 1.9193e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 7.0012e-05 - val_loss: 1.9241e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.8613e-05 - val_loss: 1.9157e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 6.8449e-05 - val_loss: 1.9172e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 671us/step - loss: 6.8870e-05 - val_loss: 1.9234e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.8860e-05 - val_loss: 1.9100e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 6.8977e-05 - val_loss: 1.9049e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 686us/step - loss: 6.8619e-05 - val_loss: 1.9120e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.8307e-05 - val_loss: 1.9143e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 665us/step - loss: 6.8788e-05 - val_loss: 1.9285e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.8442e-05 - val_loss: 1.9127e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.8486e-05 - val_loss: 1.9188e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 190s 115ms/step - loss: 1.4056e-04 - val_loss: 1.8453e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 599us/step - loss: 9.2112e-05 - val_loss: 1.8433e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 8.1721e-05 - val_loss: 1.8424e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 588us/step - loss: 7.6329e-05 - val_loss: 1.8585e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 7.3367e-05 - val_loss: 1.8590e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 7.0806e-05 - val_loss: 1.8727e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.9075e-05 - val_loss: 1.8907e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 7.1358e-05 - val_loss: 1.9244e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 576us/step - loss: 7.1151e-05 - val_loss: 1.8973e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 574us/step - loss: 6.8965e-05 - val_loss: 1.9015e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.8677e-05 - val_loss: 1.9314e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.9346e-05 - val_loss: 1.8929e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.8595e-05 - val_loss: 1.8972e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 593us/step - loss: 6.8498e-05 - val_loss: 1.9075e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 581us/step - loss: 6.8107e-05 - val_loss: 1.9020e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.8471e-05 - val_loss: 1.9677e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 6.8446e-05 - val_loss: 1.9075e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 586us/step - loss: 6.7738e-05 - val_loss: 1.8986e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 583us/step - loss: 6.8361e-05 - val_loss: 1.9263e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 579us/step - loss: 6.7571e-05 - val_loss: 1.9332e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 7.0860e-05 - val_loss: 1.8991e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 583us/step - loss: 6.7977e-05 - val_loss: 1.9004e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 585us/step - loss: 7.0917e-05 - val_loss: 1.9366e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 587us/step - loss: 6.8608e-05 - val_loss: 1.9401e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 582us/step - loss: 6.8073e-05 - val_loss: 1.9048e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 193s 118ms/step - loss: 2.0349e-04 - val_loss: 2.0600e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 1.2362e-04 - val_loss: 1.9078e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 658us/step - loss: 1.0181e-04 - val_loss: 1.8729e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 8.8133e-05 - val_loss: 1.8580e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 659us/step - loss: 7.7120e-05 - val_loss: 1.8586e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.9964e-05 - val_loss: 1.9513e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 660us/step - loss: 6.8493e-05 - val_loss: 1.9431e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 661us/step - loss: 6.8944e-05 - val_loss: 2.0286e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 660us/step - loss: 6.9286e-05 - val_loss: 1.9235e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.9972e-05 - val_loss: 1.9322e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 663us/step - loss: 6.7560e-05 - val_loss: 1.9232e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 6.8762e-05 - val_loss: 1.9127e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 6.8697e-05 - val_loss: 1.9210e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 6.9136e-05 - val_loss: 1.9208e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 657us/step - loss: 6.8406e-05 - val_loss: 1.9479e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 671us/step - loss: 7.2013e-05 - val_loss: 1.9327e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 662us/step - loss: 6.9259e-05 - val_loss: 1.9027e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 656us/step - loss: 6.8288e-05 - val_loss: 1.9208e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.8875e-05 - val_loss: 1.9307e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 669us/step - loss: 6.8947e-05 - val_loss: 1.9134e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 663us/step - loss: 6.9793e-05 - val_loss: 1.9129e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 662us/step - loss: 6.7399e-05 - val_loss: 1.9186e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.8364e-05 - val_loss: 1.9318e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 656us/step - loss: 6.8311e-05 - val_loss: 1.9156e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 659us/step - loss: 6.7187e-05 - val_loss: 1.9148e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 193s 117ms/step - loss: 1.7131e-04 - val_loss: 1.9403e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 1.0438e-04 - val_loss: 1.8474e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 614us/step - loss: 9.4547e-05 - val_loss: 1.8525e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 612us/step - loss: 8.2731e-05 - val_loss: 1.8518e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 611us/step - loss: 7.3471e-05 - val_loss: 1.9247e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 619us/step - loss: 6.8378e-05 - val_loss: 1.9171e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 621us/step - loss: 6.7395e-05 - val_loss: 1.9338e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 609us/step - loss: 6.9309e-05 - val_loss: 1.9689e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 644us/step - loss: 6.8358e-05 - val_loss: 1.9166e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 621us/step - loss: 6.8509e-05 - val_loss: 1.9200e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 610us/step - loss: 6.8000e-05 - val_loss: 1.9368e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 624us/step - loss: 6.7736e-05 - val_loss: 1.9138e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 611us/step - loss: 6.9579e-05 - val_loss: 1.9687e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 614us/step - loss: 7.0549e-05 - val_loss: 1.9142e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 620us/step - loss: 7.2733e-05 - val_loss: 2.1314e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 619us/step - loss: 7.3016e-05 - val_loss: 1.9302e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 6.8604e-05 - val_loss: 1.9361e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 613us/step - loss: 6.7675e-05 - val_loss: 1.9118e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 615us/step - loss: 6.6512e-05 - val_loss: 1.9078e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 609us/step - loss: 6.8616e-05 - val_loss: 1.9054e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 6.8653e-05 - val_loss: 1.9088e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 622us/step - loss: 7.2687e-05 - val_loss: 1.9132e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 608us/step - loss: 6.7967e-05 - val_loss: 1.9014e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 616us/step - loss: 6.6449e-05 - val_loss: 1.9487e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 619us/step - loss: 6.6600e-05 - val_loss: 1.9188e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 195s 119ms/step - loss: 1.7251e-04 - val_loss: 1.8943e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 678us/step - loss: 1.0928e-04 - val_loss: 1.9303e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 9.8207e-05 - val_loss: 1.9031e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 663us/step - loss: 8.7821e-05 - val_loss: 1.8555e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 8.0528e-05 - val_loss: 1.8686e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 676us/step - loss: 7.5258e-05 - val_loss: 1.8595e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 7.1173e-05 - val_loss: 1.9431e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 7.1441e-05 - val_loss: 1.9100e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.8366e-05 - val_loss: 1.9121e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.9436e-05 - val_loss: 1.9170e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 682us/step - loss: 6.8364e-05 - val_loss: 1.9161e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 680us/step - loss: 6.7628e-05 - val_loss: 1.9174e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 688us/step - loss: 6.7897e-05 - val_loss: 1.9277e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.8409e-05 - val_loss: 1.9245e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 683us/step - loss: 6.8709e-05 - val_loss: 1.9233e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 7.0368e-05 - val_loss: 1.9142e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 6.9345e-05 - val_loss: 1.9415e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 682us/step - loss: 6.8176e-05 - val_loss: 1.9161e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 6.8345e-05 - val_loss: 1.9494e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.8049e-05 - val_loss: 1.9130e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.8127e-05 - val_loss: 1.9128e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 676us/step - loss: 6.8171e-05 - val_loss: 1.9585e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 6.8641e-05 - val_loss: 1.9111e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 682us/step - loss: 6.9889e-05 - val_loss: 1.9358e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 6.8258e-05 - val_loss: 1.9107e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 195s 119ms/step - loss: 1.8914e-04 - val_loss: 1.9966e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 715us/step - loss: 1.1003e-04 - val_loss: 1.8505e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 711us/step - loss: 9.3948e-05 - val_loss: 1.8612e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 712us/step - loss: 8.4802e-05 - val_loss: 1.8501e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 709us/step - loss: 7.7810e-05 - val_loss: 1.8489e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 709us/step - loss: 7.1893e-05 - val_loss: 1.8631e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 719us/step - loss: 7.0102e-05 - val_loss: 1.9769e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 708us/step - loss: 7.0463e-05 - val_loss: 1.9423e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 717us/step - loss: 7.1287e-05 - val_loss: 1.9118e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 714us/step - loss: 7.0141e-05 - val_loss: 1.8939e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 715us/step - loss: 6.8883e-05 - val_loss: 1.9180e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 717us/step - loss: 6.8965e-05 - val_loss: 1.9085e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 711us/step - loss: 6.8626e-05 - val_loss: 1.9290e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 712us/step - loss: 6.9267e-05 - val_loss: 1.9170e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 725us/step - loss: 6.9221e-05 - val_loss: 1.9043e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 709us/step - loss: 6.8025e-05 - val_loss: 1.9024e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 707us/step - loss: 6.8822e-05 - val_loss: 1.9257e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 715us/step - loss: 6.7736e-05 - val_loss: 1.9139e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 723us/step - loss: 6.8549e-05 - val_loss: 1.9116e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 723us/step - loss: 6.7296e-05 - val_loss: 1.9069e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 720us/step - loss: 6.7501e-05 - val_loss: 1.9022e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 714us/step - loss: 6.9625e-05 - val_loss: 1.9071e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 711us/step - loss: 6.8363e-05 - val_loss: 1.9017e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 708us/step - loss: 6.7756e-05 - val_loss: 1.8943e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 714us/step - loss: 6.7400e-05 - val_loss: 1.9042e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 201s 123ms/step - loss: 1.8572e-04 - val_loss: 1.9466e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 683us/step - loss: 1.0587e-04 - val_loss: 1.8497e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 685us/step - loss: 9.1848e-05 - val_loss: 1.8439e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 8.2139e-05 - val_loss: 1.8418e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 699us/step - loss: 7.4820e-05 - val_loss: 1.8544e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 7.3635e-05 - val_loss: 1.8770e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 6.8848e-05 - val_loss: 1.8961e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 6.7672e-05 - val_loss: 1.8998e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 678us/step - loss: 6.9488e-05 - val_loss: 1.8993e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 663us/step - loss: 6.9480e-05 - val_loss: 1.9011e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.7415e-05 - val_loss: 1.9074e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 7.0637e-05 - val_loss: 1.9645e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 686us/step - loss: 6.8361e-05 - val_loss: 1.9065e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 6.8080e-05 - val_loss: 1.9101e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 6.7816e-05 - val_loss: 1.9044e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.6962e-05 - val_loss: 1.9219e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 683us/step - loss: 6.7493e-05 - val_loss: 1.9355e-04\n",
      "Epoch 18/25\n",
      "1644/1644 [==============================] - 1s 681us/step - loss: 6.8783e-05 - val_loss: 1.9035e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 681us/step - loss: 6.8741e-05 - val_loss: 1.8964e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.8481e-05 - val_loss: 1.9121e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.7565e-05 - val_loss: 1.9126e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 6.7652e-05 - val_loss: 1.9371e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 675us/step - loss: 7.0509e-05 - val_loss: 1.9024e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 684us/step - loss: 6.8026e-05 - val_loss: 1.9361e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 674us/step - loss: 6.6111e-05 - val_loss: 1.9119e-04\n",
      "Train on 1644 samples, validate on 411 samples\n",
      "Epoch 1/25\n",
      "1644/1644 [==============================] - 200s 121ms/step - loss: 1.8001e-04 - val_loss: 1.9007e-04\n",
      "Epoch 2/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 1.0436e-04 - val_loss: 1.8565e-04\n",
      "Epoch 3/25\n",
      "1644/1644 [==============================] - 1s 679us/step - loss: 8.9615e-05 - val_loss: 1.8398e-04\n",
      "Epoch 4/25\n",
      "1644/1644 [==============================] - 1s 663us/step - loss: 7.7680e-05 - val_loss: 1.8987e-04\n",
      "Epoch 5/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 7.0999e-05 - val_loss: 1.8915e-04\n",
      "Epoch 6/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.8187e-05 - val_loss: 1.9373e-04\n",
      "Epoch 7/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.8178e-05 - val_loss: 1.9771e-04\n",
      "Epoch 8/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 7.0943e-05 - val_loss: 1.9061e-04\n",
      "Epoch 9/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.8521e-05 - val_loss: 1.9039e-04\n",
      "Epoch 10/25\n",
      "1644/1644 [==============================] - 1s 673us/step - loss: 6.8102e-05 - val_loss: 1.9027e-04\n",
      "Epoch 11/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.7472e-05 - val_loss: 1.9602e-04\n",
      "Epoch 12/25\n",
      "1644/1644 [==============================] - 1s 666us/step - loss: 6.7690e-05 - val_loss: 1.9080e-04\n",
      "Epoch 13/25\n",
      "1644/1644 [==============================] - 1s 677us/step - loss: 6.7472e-05 - val_loss: 1.9398e-04\n",
      "Epoch 14/25\n",
      "1644/1644 [==============================] - 1s 664us/step - loss: 6.8242e-05 - val_loss: 1.8995e-04\n",
      "Epoch 15/25\n",
      "1644/1644 [==============================] - 1s 676us/step - loss: 6.9072e-05 - val_loss: 1.9295e-04\n",
      "Epoch 16/25\n",
      "1644/1644 [==============================] - 1s 678us/step - loss: 6.8654e-05 - val_loss: 1.9099e-04\n",
      "Epoch 17/25\n",
      "1644/1644 [==============================] - 1s 662us/step - loss: 6.7937e-05 - val_loss: 1.9663e-04\n",
      "Epoch 18/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1644/1644 [==============================] - 1s 673us/step - loss: 7.0831e-05 - val_loss: 1.9558e-04\n",
      "Epoch 19/25\n",
      "1644/1644 [==============================] - 1s 670us/step - loss: 6.7719e-05 - val_loss: 1.9458e-04\n",
      "Epoch 20/25\n",
      "1644/1644 [==============================] - 1s 676us/step - loss: 6.7689e-05 - val_loss: 1.9010e-04\n",
      "Epoch 21/25\n",
      "1644/1644 [==============================] - 1s 668us/step - loss: 6.7566e-05 - val_loss: 1.9085e-04\n",
      "Epoch 22/25\n",
      "1644/1644 [==============================] - 1s 672us/step - loss: 6.6686e-05 - val_loss: 1.9297e-04\n",
      "Epoch 23/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.6710e-05 - val_loss: 1.9483e-04\n",
      "Epoch 24/25\n",
      "1644/1644 [==============================] - 1s 667us/step - loss: 6.7535e-05 - val_loss: 1.9049e-04\n",
      "Epoch 25/25\n",
      "1644/1644 [==============================] - 1s 676us/step - loss: 6.8511e-05 - val_loss: 1.9169e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 208s 127ms/step - loss: 3.8839e-04 - val_loss: 3.0831e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 1.8254e-04 - val_loss: 1.9795e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 863us/step - loss: 1.5307e-04 - val_loss: 1.9796e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 1.3630e-04 - val_loss: 1.9964e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 870us/step - loss: 1.2334e-04 - val_loss: 1.9231e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 1.1138e-04 - val_loss: 1.9153e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 1.0066e-04 - val_loss: 1.8956e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 861us/step - loss: 9.2213e-05 - val_loss: 1.8947e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 861us/step - loss: 8.4066e-05 - val_loss: 1.8720e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 7.7698e-05 - val_loss: 1.8803e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 868us/step - loss: 7.3464e-05 - val_loss: 1.8835e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 6.9246e-05 - val_loss: 1.8616e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 6.7139e-05 - val_loss: 1.8549e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 868us/step - loss: 6.6446e-05 - val_loss: 1.8708e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 864us/step - loss: 6.7053e-05 - val_loss: 1.8647e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 6.7066e-05 - val_loss: 1.8746e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 888us/step - loss: 6.6312e-05 - val_loss: 1.8698e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 865us/step - loss: 6.7297e-05 - val_loss: 1.8692e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 889us/step - loss: 6.6117e-05 - val_loss: 1.8751e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 865us/step - loss: 6.6383e-05 - val_loss: 1.8787e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 868us/step - loss: 6.6512e-05 - val_loss: 1.8871e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 6.6276e-05 - val_loss: 1.8727e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 869us/step - loss: 6.6379e-05 - val_loss: 1.8751e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 871us/step - loss: 6.5904e-05 - val_loss: 1.8799e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 875us/step - loss: 6.6044e-05 - val_loss: 1.8673e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 203s 124ms/step - loss: 1.8974e-04 - val_loss: 1.8758e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 1.1969e-04 - val_loss: 2.0137e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 1.0510e-04 - val_loss: 1.8731e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 1.0091e-04 - val_loss: 1.8668e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 870us/step - loss: 9.7560e-05 - val_loss: 1.8577e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 880us/step - loss: 9.3439e-05 - val_loss: 1.8699e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 874us/step - loss: 8.8922e-05 - val_loss: 1.8517e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 8.4556e-05 - val_loss: 1.8854e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 8.0545e-05 - val_loss: 1.8747e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 7.6487e-05 - val_loss: 1.8448e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 7.3590e-05 - val_loss: 1.8642e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 879us/step - loss: 7.1595e-05 - val_loss: 1.8646e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 6.8358e-05 - val_loss: 1.8827e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 869us/step - loss: 6.9754e-05 - val_loss: 1.8947e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 880us/step - loss: 6.9520e-05 - val_loss: 1.8910e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 871us/step - loss: 6.8137e-05 - val_loss: 1.9490e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 877us/step - loss: 6.8586e-05 - val_loss: 1.8972e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 874us/step - loss: 6.7621e-05 - val_loss: 1.8962e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 893us/step - loss: 6.7142e-05 - val_loss: 1.8944e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 870us/step - loss: 6.7437e-05 - val_loss: 1.9104e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 878us/step - loss: 6.7985e-05 - val_loss: 1.8915e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 888us/step - loss: 6.7282e-05 - val_loss: 1.8912e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 6.7127e-05 - val_loss: 1.9099e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 864us/step - loss: 6.7149e-05 - val_loss: 1.9044e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 883us/step - loss: 6.7023e-05 - val_loss: 1.8990e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 212s 130ms/step - loss: 1.4341e-04 - val_loss: 1.9922e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 933us/step - loss: 9.8604e-05 - val_loss: 1.8511e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 937us/step - loss: 8.8115e-05 - val_loss: 1.8433e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 8.2078e-05 - val_loss: 1.8431e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 935us/step - loss: 7.7827e-05 - val_loss: 1.8713e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 937us/step - loss: 7.3417e-05 - val_loss: 1.9049e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 938us/step - loss: 6.9302e-05 - val_loss: 1.8786e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 942us/step - loss: 6.9623e-05 - val_loss: 1.8940e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 942us/step - loss: 7.1043e-05 - val_loss: 1.9092e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 938us/step - loss: 6.7375e-05 - val_loss: 1.8956e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 6.6778e-05 - val_loss: 1.9238e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 942us/step - loss: 6.7552e-05 - val_loss: 1.8988e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.6609e-05 - val_loss: 1.9113e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 949us/step - loss: 6.6526e-05 - val_loss: 1.9122e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 950us/step - loss: 6.7270e-05 - val_loss: 1.8987e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 938us/step - loss: 6.7443e-05 - val_loss: 1.9034e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 932us/step - loss: 6.7146e-05 - val_loss: 1.9091e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 942us/step - loss: 6.6683e-05 - val_loss: 1.8939e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 933us/step - loss: 6.7172e-05 - val_loss: 1.9224e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 948us/step - loss: 6.7700e-05 - val_loss: 1.9251e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 936us/step - loss: 6.7402e-05 - val_loss: 1.9012e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 6.6488e-05 - val_loss: 1.8989e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 6.6930e-05 - val_loss: 1.8885e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 944us/step - loss: 6.6525e-05 - val_loss: 1.8972e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 946us/step - loss: 6.6869e-05 - val_loss: 1.8959e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 214s 130ms/step - loss: 1.4948e-04 - val_loss: 1.9590e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 893us/step - loss: 9.6777e-05 - val_loss: 1.8523e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 882us/step - loss: 8.6195e-05 - val_loss: 1.8390e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 883us/step - loss: 7.9331e-05 - val_loss: 1.8411e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 7.3398e-05 - val_loss: 1.8477e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 884us/step - loss: 6.9940e-05 - val_loss: 1.8744e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 887us/step - loss: 6.9004e-05 - val_loss: 1.8674e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 878us/step - loss: 6.8486e-05 - val_loss: 1.9034e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 891us/step - loss: 6.9437e-05 - val_loss: 1.9266e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 883us/step - loss: 6.9247e-05 - val_loss: 1.9454e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 7.2259e-05 - val_loss: 1.8767e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 882us/step - loss: 6.9951e-05 - val_loss: 1.8756e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 878us/step - loss: 6.8086e-05 - val_loss: 1.8699e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 884us/step - loss: 6.7267e-05 - val_loss: 1.8729e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 879us/step - loss: 6.8290e-05 - val_loss: 1.8956e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 6.8276e-05 - val_loss: 1.8767e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 887us/step - loss: 6.8756e-05 - val_loss: 1.8807e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 6.6863e-05 - val_loss: 1.8811e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 889us/step - loss: 6.7548e-05 - val_loss: 1.9004e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 882us/step - loss: 6.9204e-05 - val_loss: 1.8971e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 887us/step - loss: 6.9732e-05 - val_loss: 1.8753e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 879us/step - loss: 6.7622e-05 - val_loss: 1.8774e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 882us/step - loss: 6.7543e-05 - val_loss: 1.8709e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 882us/step - loss: 6.6510e-05 - val_loss: 1.8815e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 875us/step - loss: 6.6321e-05 - val_loss: 1.8773e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 213s 130ms/step - loss: 2.0154e-04 - val_loss: 2.4632e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 903us/step - loss: 1.1938e-04 - val_loss: 1.8767e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 904us/step - loss: 1.0993e-04 - val_loss: 1.9467e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 906us/step - loss: 1.0605e-04 - val_loss: 1.8885e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 903us/step - loss: 1.0262e-04 - val_loss: 1.9122e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 925us/step - loss: 9.9327e-05 - val_loss: 1.8926e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 907us/step - loss: 9.5296e-05 - val_loss: 1.9124e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 915us/step - loss: 9.0186e-05 - val_loss: 1.8796e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 911us/step - loss: 8.4110e-05 - val_loss: 1.8531e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 922us/step - loss: 7.7948e-05 - val_loss: 1.8512e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 909us/step - loss: 7.4602e-05 - val_loss: 1.8625e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 904us/step - loss: 7.0253e-05 - val_loss: 1.8798e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 6.9860e-05 - val_loss: 1.8964e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 904us/step - loss: 7.0274e-05 - val_loss: 1.8871e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 917us/step - loss: 7.0060e-05 - val_loss: 1.8845e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 7.0529e-05 - val_loss: 1.8859e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 6.9900e-05 - val_loss: 1.8821e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 905us/step - loss: 7.1095e-05 - val_loss: 1.8835e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 6.9591e-05 - val_loss: 1.9115e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 913us/step - loss: 6.9334e-05 - val_loss: 1.8844e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 909us/step - loss: 6.9441e-05 - val_loss: 1.8817e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 897us/step - loss: 6.9623e-05 - val_loss: 1.8828e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 906us/step - loss: 6.9441e-05 - val_loss: 1.8909e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 913us/step - loss: 7.0266e-05 - val_loss: 1.9202e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 911us/step - loss: 6.9981e-05 - val_loss: 1.8827e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 217s 132ms/step - loss: 2.0012e-04 - val_loss: 1.9447e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 1.2018e-04 - val_loss: 2.0321e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 868us/step - loss: 1.0475e-04 - val_loss: 1.8643e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 9.5974e-05 - val_loss: 1.8697e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 866us/step - loss: 8.8357e-05 - val_loss: 1.8740e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 8.1680e-05 - val_loss: 1.8539e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 867us/step - loss: 7.5540e-05 - val_loss: 1.8694e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 1s 875us/step - loss: 7.1853e-05 - val_loss: 1.8856e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 871us/step - loss: 7.0269e-05 - val_loss: 1.9430e-04\n",
      "Epoch 10/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1640/1640 [==============================] - 1s 876us/step - loss: 7.1771e-05 - val_loss: 1.9119e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 1s 870us/step - loss: 6.9684e-05 - val_loss: 1.8990e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 871us/step - loss: 6.9750e-05 - val_loss: 1.9190e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 884us/step - loss: 7.1359e-05 - val_loss: 1.9089e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 1s 877us/step - loss: 6.9856e-05 - val_loss: 1.9056e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 6.9360e-05 - val_loss: 1.9020e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 6.9342e-05 - val_loss: 1.9051e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 1s 874us/step - loss: 6.8929e-05 - val_loss: 1.9063e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 6.8673e-05 - val_loss: 1.9179e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 6.9432e-05 - val_loss: 1.9120e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 886us/step - loss: 7.0369e-05 - val_loss: 1.9918e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 872us/step - loss: 7.5804e-05 - val_loss: 1.9622e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 876us/step - loss: 7.0790e-05 - val_loss: 1.8912e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 873us/step - loss: 6.9040e-05 - val_loss: 1.8911e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 869us/step - loss: 6.9094e-05 - val_loss: 1.8993e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 868us/step - loss: 6.8654e-05 - val_loss: 1.9032e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 211s 129ms/step - loss: 2.3484e-04 - val_loss: 1.9876e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 1.3219e-04 - val_loss: 2.0668e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 1.1015e-04 - val_loss: 1.9179e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 9.9399e-05 - val_loss: 1.8845e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 8.6666e-05 - val_loss: 1.8558e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.6016e-05 - val_loss: 1.9016e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.0595e-05 - val_loss: 1.9095e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.1170e-05 - val_loss: 1.9371e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9601e-05 - val_loss: 1.9266e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9046e-05 - val_loss: 1.9054e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9497e-05 - val_loss: 1.9225e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8756e-05 - val_loss: 1.9086e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8892e-05 - val_loss: 1.9075e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.0403e-05 - val_loss: 1.9390e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.0221e-05 - val_loss: 1.8999e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8268e-05 - val_loss: 1.9465e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8850e-05 - val_loss: 1.9071e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9277e-05 - val_loss: 1.9281e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8196e-05 - val_loss: 1.8966e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9247e-05 - val_loss: 1.9439e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8340e-05 - val_loss: 1.9223e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8495e-05 - val_loss: 1.8953e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8325e-05 - val_loss: 1.8971e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7057e-05 - val_loss: 1.9171e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7657e-05 - val_loss: 1.8986e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 221s 135ms/step - loss: 1.7765e-04 - val_loss: 1.9927e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 944us/step - loss: 1.0867e-04 - val_loss: 1.8842e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 971us/step - loss: 9.3611e-05 - val_loss: 1.8481e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 955us/step - loss: 8.2184e-05 - val_loss: 1.8636e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 949us/step - loss: 7.5130e-05 - val_loss: 1.8618e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 961us/step - loss: 7.0903e-05 - val_loss: 1.8826e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 979us/step - loss: 7.0986e-05 - val_loss: 1.8914e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 976us/step - loss: 6.9987e-05 - val_loss: 1.8791e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 974us/step - loss: 6.9546e-05 - val_loss: 1.8833e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 943us/step - loss: 7.0144e-05 - val_loss: 1.9028e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 951us/step - loss: 6.8960e-05 - val_loss: 1.8784e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 944us/step - loss: 6.9705e-05 - val_loss: 1.8810e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 956us/step - loss: 6.9613e-05 - val_loss: 1.8786e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 956us/step - loss: 6.9459e-05 - val_loss: 1.8775e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 957us/step - loss: 6.8592e-05 - val_loss: 1.8815e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 957us/step - loss: 6.8790e-05 - val_loss: 1.8806e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 948us/step - loss: 6.8627e-05 - val_loss: 1.8902e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 956us/step - loss: 7.0172e-05 - val_loss: 1.8794e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 954us/step - loss: 7.0238e-05 - val_loss: 1.8746e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 953us/step - loss: 6.7899e-05 - val_loss: 1.8796e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 952us/step - loss: 6.7437e-05 - val_loss: 1.8786e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 950us/step - loss: 6.7451e-05 - val_loss: 1.9003e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 948us/step - loss: 7.0012e-05 - val_loss: 1.8990e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 948us/step - loss: 6.7775e-05 - val_loss: 1.9107e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 956us/step - loss: 6.9948e-05 - val_loss: 1.9467e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 221s 135ms/step - loss: 2.4899e-04 - val_loss: 2.1207e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 962us/step - loss: 1.3369e-04 - val_loss: 1.9830e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 962us/step - loss: 1.1553e-04 - val_loss: 1.8951e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 975us/step - loss: 1.0759e-04 - val_loss: 1.8929e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 966us/step - loss: 9.9306e-05 - val_loss: 1.9227e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 9.2982e-05 - val_loss: 1.8638e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 982us/step - loss: 8.4798e-05 - val_loss: 1.8635e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 976us/step - loss: 7.7853e-05 - val_loss: 1.8631e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 977us/step - loss: 7.3275e-05 - val_loss: 1.8738e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 980us/step - loss: 7.0352e-05 - val_loss: 1.8694e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 963us/step - loss: 6.9914e-05 - val_loss: 1.8804e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 6.9966e-05 - val_loss: 1.8991e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 965us/step - loss: 6.9580e-05 - val_loss: 1.8810e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 976us/step - loss: 6.9818e-05 - val_loss: 1.8887e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 6.9136e-05 - val_loss: 1.8795e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 995us/step - loss: 6.9266e-05 - val_loss: 1.8932e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.9952e-05 - val_loss: 1.8846e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 971us/step - loss: 6.9580e-05 - val_loss: 1.8846e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 967us/step - loss: 6.9392e-05 - val_loss: 1.8750e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 973us/step - loss: 6.9644e-05 - val_loss: 1.8994e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 973us/step - loss: 6.8469e-05 - val_loss: 1.8777e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 979us/step - loss: 6.8400e-05 - val_loss: 1.9184e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 975us/step - loss: 6.9213e-05 - val_loss: 1.8892e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 974us/step - loss: 6.8224e-05 - val_loss: 1.8895e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 968us/step - loss: 6.8621e-05 - val_loss: 1.8884e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 215s 131ms/step - loss: 1.7838e-04 - val_loss: 1.8909e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 1.0540e-04 - val_loss: 1.8829e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 922us/step - loss: 9.1462e-05 - val_loss: 1.8659e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 907us/step - loss: 8.0951e-05 - val_loss: 1.8980e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 905us/step - loss: 7.4414e-05 - val_loss: 1.9230e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 907us/step - loss: 7.0292e-05 - val_loss: 1.8747e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 6.8780e-05 - val_loss: 1.8790e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 919us/step - loss: 6.8358e-05 - val_loss: 1.8823e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 914us/step - loss: 6.8653e-05 - val_loss: 1.8844e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 1s 913us/step - loss: 6.8877e-05 - val_loss: 1.8975e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 926us/step - loss: 6.9050e-05 - val_loss: 1.9017e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 1s 913us/step - loss: 6.9247e-05 - val_loss: 1.9005e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 1s 909us/step - loss: 6.8406e-05 - val_loss: 1.8802e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 917us/step - loss: 6.8051e-05 - val_loss: 1.8833e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 925us/step - loss: 6.8221e-05 - val_loss: 1.8923e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 924us/step - loss: 6.8512e-05 - val_loss: 1.9444e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 919us/step - loss: 6.8463e-05 - val_loss: 1.8909e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 1s 914us/step - loss: 6.7782e-05 - val_loss: 1.8999e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 924us/step - loss: 6.7987e-05 - val_loss: 1.8855e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 6.7154e-05 - val_loss: 1.8864e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 1s 910us/step - loss: 6.8122e-05 - val_loss: 1.9393e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 910us/step - loss: 6.8712e-05 - val_loss: 1.9161e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 7.1932e-05 - val_loss: 1.8804e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 7.2230e-05 - val_loss: 1.9004e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 905us/step - loss: 6.7913e-05 - val_loss: 1.8809e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 233s 142ms/step - loss: 2.1103e-04 - val_loss: 2.0746e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 930us/step - loss: 1.1498e-04 - val_loss: 1.8537e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 9.4236e-05 - val_loss: 1.9173e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 8.2012e-05 - val_loss: 1.8911e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 920us/step - loss: 7.4230e-05 - val_loss: 1.9109e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 928us/step - loss: 6.9954e-05 - val_loss: 1.8979e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 6.8152e-05 - val_loss: 1.9094e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.8077e-05 - val_loss: 1.9129e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 923us/step - loss: 6.8576e-05 - val_loss: 1.9070e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.7965e-05 - val_loss: 1.9064e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.8402e-05 - val_loss: 1.9006e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 6.9314e-05 - val_loss: 1.9305e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 937us/step - loss: 6.8274e-05 - val_loss: 1.8939e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 928us/step - loss: 6.8008e-05 - val_loss: 1.9129e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 942us/step - loss: 6.8001e-05 - val_loss: 1.8968e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 926us/step - loss: 6.9996e-05 - val_loss: 2.0108e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 7.0749e-05 - val_loss: 1.8916e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.8778e-05 - val_loss: 1.9188e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 932us/step - loss: 6.9205e-05 - val_loss: 1.9002e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 933us/step - loss: 6.7225e-05 - val_loss: 1.9031e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 943us/step - loss: 6.7380e-05 - val_loss: 1.9420e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 939us/step - loss: 7.1037e-05 - val_loss: 1.9227e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 7.0473e-05 - val_loss: 1.8969e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 938us/step - loss: 6.7064e-05 - val_loss: 1.8968e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 930us/step - loss: 6.6613e-05 - val_loss: 1.9111e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 223s 136ms/step - loss: 1.9251e-04 - val_loss: 1.8923e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 1s 905us/step - loss: 1.0763e-04 - val_loss: 1.8723e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 1s 903us/step - loss: 8.9997e-05 - val_loss: 1.8902e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 1s 903us/step - loss: 7.9356e-05 - val_loss: 1.8681e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 1s 901us/step - loss: 7.3569e-05 - val_loss: 1.8978e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 7.2939e-05 - val_loss: 1.9048e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 915us/step - loss: 7.2219e-05 - val_loss: 1.9437e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 928us/step - loss: 7.3101e-05 - val_loss: 1.8986e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 7.2181e-05 - val_loss: 1.8844e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 944us/step - loss: 7.0752e-05 - val_loss: 1.8842e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 917us/step - loss: 6.9963e-05 - val_loss: 1.9358e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 915us/step - loss: 7.2142e-05 - val_loss: 1.9656e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 925us/step - loss: 7.1094e-05 - val_loss: 1.9011e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 923us/step - loss: 7.1362e-05 - val_loss: 1.9005e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 917us/step - loss: 6.9922e-05 - val_loss: 1.8771e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 1s 911us/step - loss: 6.9242e-05 - val_loss: 1.9028e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 937us/step - loss: 6.9577e-05 - val_loss: 1.8976e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 915us/step - loss: 6.8695e-05 - val_loss: 1.8951e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 1s 904us/step - loss: 6.8642e-05 - val_loss: 1.9563e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 1s 908us/step - loss: 7.1791e-05 - val_loss: 1.8876e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 919us/step - loss: 6.8178e-05 - val_loss: 1.8827e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 1s 912us/step - loss: 6.9844e-05 - val_loss: 1.9302e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 1s 907us/step - loss: 7.1905e-05 - val_loss: 1.9482e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 919us/step - loss: 6.7579e-05 - val_loss: 1.9035e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 1s 909us/step - loss: 6.7087e-05 - val_loss: 1.9389e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 233s 142ms/step - loss: 1.3839e-04 - val_loss: 1.8709e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 927us/step - loss: 8.9584e-05 - val_loss: 1.8607e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 7.5992e-05 - val_loss: 1.8520e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 932us/step - loss: 7.0237e-05 - val_loss: 1.9301e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 926us/step - loss: 6.9200e-05 - val_loss: 1.8744e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 923us/step - loss: 6.6983e-05 - val_loss: 1.9271e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 923us/step - loss: 6.8174e-05 - val_loss: 1.9002e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 940us/step - loss: 6.7451e-05 - val_loss: 1.9005e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 922us/step - loss: 6.6971e-05 - val_loss: 1.8844e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 6.6777e-05 - val_loss: 1.8925e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 940us/step - loss: 7.0458e-05 - val_loss: 1.9160e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 923us/step - loss: 6.9203e-05 - val_loss: 1.9487e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.8439e-05 - val_loss: 1.8866e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 934us/step - loss: 6.6904e-05 - val_loss: 1.9058e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 924us/step - loss: 6.7020e-05 - val_loss: 1.9101e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 931us/step - loss: 6.7886e-05 - val_loss: 1.9040e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 933us/step - loss: 6.6942e-05 - val_loss: 1.8876e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 929us/step - loss: 6.5983e-05 - val_loss: 1.8932e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 932us/step - loss: 6.7803e-05 - val_loss: 1.8961e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 926us/step - loss: 6.7030e-05 - val_loss: 1.9112e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 933us/step - loss: 6.7366e-05 - val_loss: 1.9301e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 924us/step - loss: 6.9082e-05 - val_loss: 1.9418e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 922us/step - loss: 6.8787e-05 - val_loss: 1.9069e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 983us/step - loss: 6.8434e-05 - val_loss: 1.9029e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 928us/step - loss: 6.5850e-05 - val_loss: 1.9161e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 229s 139ms/step - loss: 1.4557e-04 - val_loss: 2.0633e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 984us/step - loss: 8.7205e-05 - val_loss: 1.9248e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 7.9306e-05 - val_loss: 1.8979e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 978us/step - loss: 7.3702e-05 - val_loss: 1.8652e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 981us/step - loss: 6.9839e-05 - val_loss: 1.8920e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 7.0004e-05 - val_loss: 1.8847e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 975us/step - loss: 7.0069e-05 - val_loss: 1.9126e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 974us/step - loss: 6.9083e-05 - val_loss: 1.9021e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 977us/step - loss: 6.8614e-05 - val_loss: 1.8835e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 974us/step - loss: 6.9254e-05 - val_loss: 1.8811e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 975us/step - loss: 6.8290e-05 - val_loss: 1.9039e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.9323e-05 - val_loss: 1.9002e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 973us/step - loss: 6.8417e-05 - val_loss: 1.8860e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 984us/step - loss: 6.9063e-05 - val_loss: 1.8826e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 982us/step - loss: 6.7877e-05 - val_loss: 1.8865e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 978us/step - loss: 6.7788e-05 - val_loss: 1.9032e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.7462e-05 - val_loss: 1.9358e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 992us/step - loss: 7.0339e-05 - val_loss: 1.9176e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 977us/step - loss: 6.9392e-05 - val_loss: 1.9217e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 981us/step - loss: 6.7386e-05 - val_loss: 1.9057e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 994us/step - loss: 6.8287e-05 - val_loss: 1.8876e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 6.7075e-05 - val_loss: 1.9242e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 981us/step - loss: 6.8404e-05 - val_loss: 1.8825e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 988us/step - loss: 6.6859e-05 - val_loss: 1.9192e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 975us/step - loss: 6.6793e-05 - val_loss: 1.8836e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 234s 142ms/step - loss: 1.4699e-04 - val_loss: 2.1367e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 8.7932e-05 - val_loss: 1.9608e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.3394e-05 - val_loss: 1.9068e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.0265e-05 - val_loss: 1.8951e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.2726e-05 - val_loss: 1.9749e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.1943e-05 - val_loss: 1.9011e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.0412e-05 - val_loss: 1.9029e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.3178e-05 - val_loss: 1.9435e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9551e-05 - val_loss: 1.8855e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8368e-05 - val_loss: 1.8944e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8679e-05 - val_loss: 1.9018e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8333e-05 - val_loss: 1.8857e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8195e-05 - val_loss: 1.8912e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8985e-05 - val_loss: 1.9402e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9833e-05 - val_loss: 1.8863e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7670e-05 - val_loss: 1.9068e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7489e-05 - val_loss: 1.8891e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 7.1012e-05 - val_loss: 1.8892e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9560e-05 - val_loss: 1.8862e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7514e-05 - val_loss: 1.8831e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.8830e-05 - val_loss: 1.8927e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7348e-05 - val_loss: 1.8882e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.9002e-05 - val_loss: 1.8795e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.7263e-05 - val_loss: 1.9123e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 1ms/step - loss: 6.6837e-05 - val_loss: 1.9008e-04\n",
      "Train on 1640 samples, validate on 410 samples\n",
      "Epoch 1/25\n",
      "1640/1640 [==============================] - 239s 145ms/step - loss: 1.7789e-04 - val_loss: 1.9413e-04\n",
      "Epoch 2/25\n",
      "1640/1640 [==============================] - 2s 960us/step - loss: 1.0172e-04 - val_loss: 1.8611e-04\n",
      "Epoch 3/25\n",
      "1640/1640 [==============================] - 2s 967us/step - loss: 8.5064e-05 - val_loss: 1.9256e-04\n",
      "Epoch 4/25\n",
      "1640/1640 [==============================] - 2s 961us/step - loss: 7.4271e-05 - val_loss: 1.9131e-04\n",
      "Epoch 5/25\n",
      "1640/1640 [==============================] - 2s 974us/step - loss: 6.9990e-05 - val_loss: 1.9101e-04\n",
      "Epoch 6/25\n",
      "1640/1640 [==============================] - 2s 960us/step - loss: 7.0572e-05 - val_loss: 1.8964e-04\n",
      "Epoch 7/25\n",
      "1640/1640 [==============================] - 2s 965us/step - loss: 7.0986e-05 - val_loss: 1.8954e-04\n",
      "Epoch 8/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 7.0344e-05 - val_loss: 1.9344e-04\n",
      "Epoch 9/25\n",
      "1640/1640 [==============================] - 2s 968us/step - loss: 7.0664e-05 - val_loss: 1.9595e-04\n",
      "Epoch 10/25\n",
      "1640/1640 [==============================] - 2s 976us/step - loss: 7.2348e-05 - val_loss: 1.8944e-04\n",
      "Epoch 11/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.9185e-05 - val_loss: 1.8937e-04\n",
      "Epoch 12/25\n",
      "1640/1640 [==============================] - 2s 965us/step - loss: 6.8251e-05 - val_loss: 1.9236e-04\n",
      "Epoch 13/25\n",
      "1640/1640 [==============================] - 2s 972us/step - loss: 6.9153e-05 - val_loss: 1.8879e-04\n",
      "Epoch 14/25\n",
      "1640/1640 [==============================] - 2s 958us/step - loss: 6.7574e-05 - val_loss: 1.9020e-04\n",
      "Epoch 15/25\n",
      "1640/1640 [==============================] - 2s 962us/step - loss: 6.7856e-05 - val_loss: 1.9032e-04\n",
      "Epoch 16/25\n",
      "1640/1640 [==============================] - 2s 962us/step - loss: 6.7157e-05 - val_loss: 1.8922e-04\n",
      "Epoch 17/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 6.6676e-05 - val_loss: 1.9254e-04\n",
      "Epoch 18/25\n",
      "1640/1640 [==============================] - 2s 961us/step - loss: 6.7937e-05 - val_loss: 1.9012e-04\n",
      "Epoch 19/25\n",
      "1640/1640 [==============================] - 2s 961us/step - loss: 6.7531e-05 - val_loss: 1.8898e-04\n",
      "Epoch 20/25\n",
      "1640/1640 [==============================] - 2s 967us/step - loss: 6.9981e-05 - val_loss: 1.8862e-04\n",
      "Epoch 21/25\n",
      "1640/1640 [==============================] - 2s 969us/step - loss: 6.5747e-05 - val_loss: 1.9045e-04\n",
      "Epoch 22/25\n",
      "1640/1640 [==============================] - 2s 963us/step - loss: 6.7778e-05 - val_loss: 1.9157e-04\n",
      "Epoch 23/25\n",
      "1640/1640 [==============================] - 2s 965us/step - loss: 7.0720e-05 - val_loss: 2.1479e-04\n",
      "Epoch 24/25\n",
      "1640/1640 [==============================] - 2s 966us/step - loss: 7.7094e-05 - val_loss: 1.8723e-04\n",
      "Epoch 25/25\n",
      "1640/1640 [==============================] - 2s 966us/step - loss: 7.0702e-05 - val_loss: 1.8764e-04\n",
      "Test RMSE LSTM Cisco Systems, Inc. : 0.009313548591100087\n",
      "Test RMSE HAR Cisco Systems, Inc. : 0.009593212115069598\n",
      "Test MSE_VAR LSTM Cisco Systems, Inc. : 1.0703919098459207e-06\n",
      "Test MSE_VAR HAR Cisco Systems, Inc. : 1.0831427783545557e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "names=['AAPL.txt',GS.txt','EBAY.txt','CSCO.txt']\n",
    "prev_per = [1,2,3,4,5,10]\n",
    "FirstLayer = [5,15,25,50]\n",
    "SecondLayer = [1,5,15,25]\n",
    "n_epoch = [25]\n",
    "\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    \n",
    "    if name  == 'AAPL.txt':\n",
    "        long_name = 'Apple Inc.'\n",
    "        short_name = 'Apple'\n",
    "    elif name  == 'PG.txt':\n",
    "        long_name = 'The Procter & Gamble Company'\n",
    "        short_name = 'PG'\n",
    "    elif name  == 'CVX.txt':\n",
    "        long_name = 'CVS Health Corporation'\n",
    "        short_name = 'CVX'\n",
    "    elif name  == 'GS.txt':\n",
    "        long_name = 'The Goldman Sachs Group, Inc.'\n",
    "        short_name = 'GS'\n",
    "    elif name  == 'EBAY.txt':\n",
    "        long_name = 'eBay Inc.'\n",
    "        short_name = 'EBAY'\n",
    "    elif name  == 'CSCO.txt':\n",
    "        long_name = 'Cisco Systems, Inc.'\n",
    "        short_name = 'CSCO'\n",
    "\n",
    "    #Read the data\n",
    "    all_data = pd.read_csv(name, sep=\",\",parse_dates={'dt' : ['Date', 'Time']},infer_datetime_format=True)\n",
    "    #Select the columns\n",
    "    all_data.index = all_data['dt'] \n",
    "    all_data = all_data[['Close']]\n",
    "    #Add a new column. The log of the close price\n",
    "    all_data['Log_Close']=np.log(all_data['Close'])\n",
    "    #Substract the previous rows\n",
    "    all_data['Returns']=all_data.Log_Close.diff()\n",
    "    #Delete the first row\n",
    "    all_data = all_data.iloc[1:]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(all_data['Returns'])\n",
    "    plt.title('Returns of ' + long_name)\n",
    "    plt.show()\n",
    "    \n",
    "    all_data['Returns^2']=np.square(all_data['Returns'])\n",
    "    all_data_d=all_data.groupby(by=[all_data.index.year,all_data.index.month,all_data.index.day]).sum()\n",
    "    data_RV=pd.DataFrame()\n",
    "    data_RV['RVol_d']=np.sqrt(all_data_d['Returns^2'])\n",
    "    data_RV = data_RV[['RVol_d']]\n",
    "    data_RV.index.names=['Year','Month','Day']\n",
    "\n",
    "    data_RV['RV_w']=data_RV['RVol_d'].rolling(min_periods=1, window=5).mean()\n",
    "    data_RV['RV_m']=data_RV['RVol_d'].rolling(min_periods=1, window=22).mean()\n",
    "    data_RV=data_RV.iloc[22:]\n",
    "\n",
    "    data_RV['RVol_d+1']=data_RV.RVol_d.shift(-1)\n",
    "    data_RV = data_RV.iloc[:-1]\n",
    "    \n",
    "    data_RV_1=data_RV   \n",
    "    data_RV_1.index=pd.to_datetime(pd.DataFrame(data_RV_1.index.values.tolist(), columns=['year','month','day']))\n",
    "\n",
    "     \n",
    "    \n",
    "    plt.figure(figsize = (15,10))\n",
    "    plt.plot(data_RV_1['RVol_d'],label='_nolegend_')\n",
    "    plt.ylabel('RVol day', size=15)\n",
    "    plt.xlabel('Time', size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.title('Realized Volatility of ' + long_name)\n",
    "    plt.show()\n",
    "    \n",
    "    data=data_RV\n",
    "    data=pd.DataFrame(data)\n",
    "    data=data.values.reshape(data.shape[0],4)\n",
    "    \n",
    "    #Number of predicting periods\n",
    "    forw_per = 1\n",
    "    # Times to repeat the precition\n",
    "    num_per = int(len(data_RV)*0.25)\n",
    "    N_Per=[]\n",
    "    NL1=[]\n",
    "    NL2=[]\n",
    "    N_Epochs=[]\n",
    "    RMSE=[]\n",
    "    MSE_VAR=[]\n",
    "    Predictions=[]\n",
    "    Elapsed=[]\n",
    "    \n",
    "    for prev in prev_per:\n",
    "        div = len(data) - num_per*forw_per\n",
    "        data_test = data[div-prev:]\n",
    "        data_train=data[:div]\n",
    "\n",
    "        x_test,y_test = DataProcessing(data_test,prev,forw_per,forw_per)\n",
    "        y_test = np.array([list(a.ravel()) for a in y_test])\n",
    "\n",
    "        x,y = DataProcessing(data_train,prev,forw_per)\n",
    "        y = np.array([list(a.ravel()) for a in y])\n",
    "\n",
    "        x_train, x_val, y_train, y_val = train_test_split(x, y, train_size=0.8, test_size=0.2, shuffle=False)\n",
    "\n",
    "        for L1 in FirstLayer:\n",
    "            for L2 in SecondLayer:\n",
    "                for epoch in n_epoch:\n",
    "                    start = time.time()\n",
    "                    model = Sequential()\n",
    "                    model.add(LSTM(L1,input_shape=(prev,3), return_sequences=True))\n",
    "                    model.add(LSTM(L2,input_shape=(L1,3)))\n",
    "                    model.add(Dense(forw_per))\n",
    "                    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "                    history = model.fit(x_train,y_train, epochs=epoch, batch_size=100, \n",
    "                                        validation_data=(x_val, y_val))\n",
    "                    end = time.time()\n",
    "                    time_elapsed=end-start\n",
    "                    y_pred = model.predict(x_test)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    mse_var=mean_squared_error(np.square(y_test), np.square(y_pred))\n",
    "                    \n",
    "                    \n",
    "                    N_Per.append(prev)\n",
    "                    NL1.append(L1)\n",
    "                    NL2.append(L2)\n",
    "                    N_Epochs.append(epoch)\n",
    "                    Elapsed.append(time_elapsed)\n",
    "                    RMSE.append(rmse)\n",
    "                    MSE_VAR.append(mse_var)\n",
    "                    Predictions.append(y_pred)\n",
    "                    del history\n",
    "                    del model\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    Results=pd.DataFrame()\n",
    "    Results['Previous Periods']=N_Per\n",
    "    Results['Number Layers 1']=NL1\n",
    "    Results['Number Layers 2']=NL2\n",
    "    Results['Epochs']=N_Epochs\n",
    "    Results['Time elapsed']=Elapsed\n",
    "    Results['RMSE']=RMSE\n",
    "    Results['MSE_VAR']=MSE_VAR\n",
    "        \n",
    "    csv_name= 'Results_'+short_name + \".csv\"\n",
    "    \n",
    "    Results.to_csv(csv_name, sep=',',index=False)\n",
    "    \n",
    "    index_min_rmse = Results['RMSE'].argmin()\n",
    "    opt_rmse=Results.iloc[index_min_rmse,5]\n",
    "    opt_mse_var=Results.iloc[index_min_rmse,6]\n",
    "    opt_y_pred=Predictions[index_min_rmse]\n",
    "    \n",
    "    #HAR MODEL\n",
    "\n",
    "    x_HAR_train=data_RV.iloc[:-num_per,0:2]\n",
    "    y_HAR_train=data_RV.iloc[:-num_per,3]\n",
    "    x_HAR_test=data_RV.iloc[-num_per:,0:2]\n",
    "    y_HAR_test=data_RV.iloc[-num_per:,3]\n",
    "    \n",
    "    HAR_model=LinearRegression()\n",
    "    HAR_model.fit(x_HAR_train,y_HAR_train)\n",
    "    y_HAR_pred = HAR_model.predict(x_HAR_test)\n",
    "    rmse_HAR = np.sqrt(mean_squared_error(y_HAR_test, y_HAR_pred))\n",
    "    mse_var_HAR=mean_squared_error(np.square(y_HAR_test), np.square(y_HAR_pred))\n",
    "    print('Test RMSE LSTM ' + long_name+' :', opt_rmse)\n",
    "    print('Test RMSE HAR ' + long_name+' :', rmse_HAR)\n",
    "    print('Test MSE_VAR LSTM ' + long_name+' :', opt_mse_var)\n",
    "    print('Test MSE_VAR HAR ' + long_name+' :', mse_var_HAR)\n",
    "    \n",
    "    plt.figure(figsize = (15,10))\n",
    "    aa=[x for x in range(num_per)]\n",
    "    plt.plot(aa, y_test[:num_per], marker='.', label=\"actual\")\n",
    "    plt.plot(aa, opt_y_pred[:num_per], 'r', label=\"prediction LTSM\")\n",
    "    plt.plot(aa, y_HAR_pred[:num_per], 'y', label=\"prediction HAR\")\n",
    "    plt.ylabel('RVol day', size=15)\n",
    "    plt.xlabel('Time', size=15)\n",
    "    plt.legend(fontsize=15)\n",
    "    plt.title('Prediction of ' + long_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
